[
  {
    "objectID": "info/bibliografia.html",
    "href": "info/bibliografia.html",
    "title": "Bibliografia",
    "section": "",
    "text": "Abaixo, você encontra a bibliografia básica e complementar da disciplina.\n\nBásica\n\n\n\n\n\n\n\n \n\n\n\nTítulo\n\n\n\n\n\n\n\n\n\n\n\nPANG-NING, Tan; STEINBACH, Michael, KARPATNE, Anuj; KUMAR, Vipin. Introduction to data mining. 2. ed. New York: Pearson, 2019.\n\n\n\n\n\n\n\n\n\nHan, J.; Pei, J.; Tong, H. Data Mining: Concepts and Techniques. Morgan Kaufmann Publishers, 2023.\n\n\n\n\n\n\n\n\n\nNWANGANGA, Fred; CHAPPLE, Mike. Practical Machine Learning in R. Indianapolis, Indiana: John Wiley & Sons, 2020.\n\n\n\n\n\n\n\n\n\nAGGARWAL, Charu C. et al. Data mining: the textbook. New York: springer, 2015.\n\n\n\n\n\n\n\n\n\nHASTIE, T.; TIBSHIRANI, R; FRIEDMAN, J. The Elements of Statistical Learning: Data Mining, Inference and Prediction. 2. ed. New York, NY: Springer, 2009.\n\n\n\n\n\n\n\n\n\nDUNHAM, Margaret H. Data Mining: Introductory and Advanced Topics. Pearson, 2020.\n\n\n\n\n\n\nNenhum item correspondente\n\n\n\nComplementar\n\n\n\n\n\n\n \n\n\n\nTítulo\n\n\n\n\n\n\n\n\n\n\n\nCASTRO, Leandro N.; FERRARI, Daniel G. Introdução à mineração de dados: conceitos básicos, algoritmos e aplicações. São Paulo : Saraiva, 2016.\n\n\n\n\n\n\n\n\n\nBRAMER, Max. Principles of Data Mining. 4. ed. Springer, 2020.\n\n\n\n\n\n\n\n\n\nLAROSE, Daniel T.; LAROSE, Chantal D. . Discovering knowledge in data: an introduction to data mining. 2. ed. John Wiley & Sons, 2014.\n\n\n\n\n\n\nNenhum item correspondente",
    "crumbs": [
      "Informações da disciplina",
      "Bibliografia"
    ]
  },
  {
    "objectID": "info/softwares.html",
    "href": "info/softwares.html",
    "title": "Mineração de Dados",
    "section": "",
    "text": "Para acompanhar as atividades da disciplina, será necessário instalar os softwares listados abaixo. Todos são gratuitos e amplamente utilizados nas áreas de Estatística e Ciência de Dados:\n\n\n\nR é um ambiente computacional gratuito voltado para análises estatísticas e produção de visualizações gráficas. Link\n\n\n\nO RStudio consiste em um ambiente de desenvolvimento integrado (IDE) projetado para aumentar a produtividade no uso da linguagem R, oferecendo ferramentas especializadas para programação, depuração e visualização de dados. Link\n\n\n\nQuarto é um sistema de publicação técnico-científica de código aberto que integra análise computacional (Python, R, Julia) e produção de documentos dinâmicos em múltiplos formatos (HTML, PDF, Word). Combina escrita em Markdown com recursos avançados para equações, citações e visualizações reprodutíveis. Link",
    "crumbs": [
      "Informações da disciplina",
      "Softwares Necessários"
    ]
  },
  {
    "objectID": "info/softwares.html#softwares-necessários",
    "href": "info/softwares.html#softwares-necessários",
    "title": "Mineração de Dados",
    "section": "",
    "text": "Para acompanhar as atividades da disciplina, será necessário instalar os softwares listados abaixo. Todos são gratuitos e amplamente utilizados nas áreas de Estatística e Ciência de Dados:\n\n\n\nR é um ambiente computacional gratuito voltado para análises estatísticas e produção de visualizações gráficas. Link\n\n\n\nO RStudio consiste em um ambiente de desenvolvimento integrado (IDE) projetado para aumentar a produtividade no uso da linguagem R, oferecendo ferramentas especializadas para programação, depuração e visualização de dados. Link\n\n\n\nQuarto é um sistema de publicação técnico-científica de código aberto que integra análise computacional (Python, R, Julia) e produção de documentos dinâmicos em múltiplos formatos (HTML, PDF, Word). Combina escrita em Markdown com recursos avançados para equações, citações e visualizações reprodutíveis. Link",
    "crumbs": [
      "Informações da disciplina",
      "Softwares Necessários"
    ]
  },
  {
    "objectID": "info/ementa.html",
    "href": "info/ementa.html",
    "title": "Ementa e Objetivos",
    "section": "",
    "text": "Análise estatística em grandes bancos de dados. Tratamento de dados para processos de Data Mining. Principais funcionalidades, técnicas e algoritmos. Análise de associações. Classificação de dados. Árvores de decisão. Regressão Logística. Redes Neurais. Segmentação e Análise de Cluster. Estudo de casos.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "info/ementa.html#ementa",
    "href": "info/ementa.html#ementa",
    "title": "Ementa e Objetivos",
    "section": "",
    "text": "Análise estatística em grandes bancos de dados. Tratamento de dados para processos de Data Mining. Principais funcionalidades, técnicas e algoritmos. Análise de associações. Classificação de dados. Árvores de decisão. Regressão Logística. Redes Neurais. Segmentação e Análise de Cluster. Estudo de casos.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "info/ementa.html#objetivos",
    "href": "info/ementa.html#objetivos",
    "title": "Ementa e Objetivos",
    "section": "Objetivos",
    "text": "Objetivos\nCapacitar o aluno a compreender, aplicar e avaliar as principais técnicas e algoritmos de mineração de dados sob uma perspectiva estatística. Ao final da disciplina, o estudante deverá ser capaz de conduzir um projeto de extração de conhecimento a partir de dados, desde a preparação e análise exploratória até a construção, interpretação e validação de modelos preditivos e descritivos, comunicando os resultados de forma clara e objetiva.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "info/ementa.html#metodologia",
    "href": "info/ementa.html#metodologia",
    "title": "Ementa e Objetivos",
    "section": "Metodologia",
    "text": "Metodologia\nSerão ministradas aulas teóricas expositivas; utilizados recursos computacionais e visuais; aplicação de métodos em dados reais; solicitação de atividades extraclasse e realização de projetos.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "info/ementa.html#habilidades-e-competências",
    "href": "info/ementa.html#habilidades-e-competências",
    "title": "Ementa e Objetivos",
    "section": "Habilidades e Competências",
    "text": "Habilidades e Competências\nAo final da disciplina, espera-se que o(a) aluno(a) seja capaz de executar as rotinas essenciais de pré-processamento em grandes volumes de dados e a implementar os principais algoritmos de classificação, segmentação e associação para construir modelos preditivos e descritivos. O(A) aluno(a) também estará habilitado a avaliar criticamente a performance e a validade dos modelos gerados, bme como interpretar os resultados para extrair insights acionáveis e a comunicar suas conclusões de forma clara para diferentes públicos.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "info/ementa.html#avaliação",
    "href": "info/ementa.html#avaliação",
    "title": "Ementa e Objetivos",
    "section": "Avaliação",
    "text": "Avaliação\nSerá realizada uma avaliação contínua, com solicitação de atividades extraclasse e apresentações em sala de aula. Ao final da disciplina os alunos deverão apresentar um projeto final.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#objetivo-da-aula",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#objetivo-da-aula",
    "title": "Regressão Linear",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\n\nDistinguir Inferência de Predição e aplicar a Regressão Linear para modelar e prever uma variável contínua."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#panorama-geral-de-mineração-de-dados",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#panorama-geral-de-mineração-de-dados",
    "title": "Regressão Linear",
    "section": "Panorama Geral de Mineração de Dados",
    "text": "Panorama Geral de Mineração de Dados\nAnteriormente exploramos o mundo Não Supervisionado:\n\nObjetivo: Encontrar estrutura escondida nos dados (Ex: K-means).\nChave: Não tínhamos uma variável-resposta (Y).\n\nAgora entraremos no mundo Supervisionado:\n\nObjetivo: Prever um valor-alvo (Y) com base em outras variáveis (X).\nA Grande Divisão:\n\nRegressão: O Y é um número contínuo.\n\n*Exemplo:** Prever a nota do IDEB, o valor do aluguel, a mortalidade infantil.\n\nClassificação: O Y é uma categoria/rótulo.\n\nExemplo: Prever se um paciente tem COVID, se uma transação é fraude, se um aluno vai evadir o curso."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#problema-aluguel-de-bicicletas",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#problema-aluguel-de-bicicletas",
    "title": "Regressão Linear",
    "section": "Problema: Aluguel de Bicicletas",
    "text": "Problema: Aluguel de Bicicletas\nVamos usar a Regressão Linear para entender e prever o número de aluguéis de bicicleta (rentals) com base em condições climáticas.\n\nVariável resposta (Y): rentals (numérica → Regressão)\nVariáveis Preditoras (X): temperature, humidity, windspeed.\n\n\n# Pacotes\nlibrary(tidyverse)\nlibrary(tidymodels) # Para dividir dados e métricas\nlibrary(patchwork) # Para juntar gráficos\n\n# Carregando os dados\nbikes &lt;- read_csv(\"/home/sadraque/Documentos/UFS/Disciplinas/2025.2/mineracao de dados em estatistica/slides/08-regressao_linear/08-regressao_linear_exemplos/bikes.csv\", col_types = \"Dffffddddd\")"
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#regra-de-ouro-da-aprendizagem-supervisionada",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#regra-de-ouro-da-aprendizagem-supervisionada",
    "title": "Regressão Linear",
    "section": "Regra de Ouro da Aprendizagem Supervisionada",
    "text": "Regra de Ouro da Aprendizagem Supervisionada\nNunca avalie seu modelo com os mesmos dados que você usou para treiná-lo.\n\nOverfitting (Superajuste): Ocorre quando o modelo “decora” os dados de treino, mas não sabe generalizar para dados novos.\nAnalogia: É como um aluno que tira 10 na lista de exercícios (que ele decorou), mas tira 0 na prova (dados novos).\nQueremos um modelo que vá bem na prova, não que apenas decore a lista."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#solução-partição-treino-teste",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#solução-partição-treino-teste",
    "title": "Regressão Linear",
    "section": "Solução: Partição Treino-Teste",
    "text": "Solução: Partição Treino-Teste\nVamos dividir nossos dados aleatoriamente:\n\nDados de Treino (~80%): A “lista de exercícios”. Usaremos para construir e inferir o modelo.\nDados de Teste (~20%): A “prova surpresa”. Ficarão guardados e só serão usados uma única vez, no final, para avaliar a capacidade de predição do modelo."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#solução-partição-treino-teste-1",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#solução-partição-treino-teste-1",
    "title": "Regressão Linear",
    "section": "Solução: Partição Treino-Teste",
    "text": "Solução: Partição Treino-Teste\n\n# Fixando a semente para reprodutibilidade\nset.seed(123) \n\n# Criando a partição com 'tidymodels'\n# Usamos 'strata = rentals' para garantir que a distribuição de 'rentals' \n# seja similar nos dois conjuntos (importante!)\nbikes_split &lt;- initial_split(bikes, prop = 0.80, strata = rentals)\n\n# Extraindo os dataframes de treino e teste\nbikes_treino &lt;- training(bikes_split)\nbikes_teste  &lt;- testing(bikes_split)\n\n# Verificando os tamanhos\ndim(bikes_treino)\n\n[1] 583  10\n\ndim(bikes_teste)\n\n[1] 148  10"
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#a-abordagem-de-dois-mundos",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#a-abordagem-de-dois-mundos",
    "title": "Regressão Linear",
    "section": "A Abordagem de “Dois Mundos”",
    "text": "A Abordagem de “Dois Mundos”\nA regressão linear pode ser usada para responder duas perguntas distintas:\nMundo 1: INFERÊNCIA (O Estatístico Clássico)\n\nPergunta: Quais variáveis explicam os aluguéis?\nFerramentas: lm(), summary(), p-valores, \\(R^2\\), Análise de Resíduos.\nDados: bikes_treino\n\nMundo 2: PREDIÇÃO (O Cientista de Dados/ML)\n\nPergunta: Quão bem meu modelo prevê aluguéis em dias novos?\nFerramentas: predict(), RMSE, MAE.\nDados: bikes_teste"
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-inferência-explorando-as-relações",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-inferência-explorando-as-relações",
    "title": "Regressão Linear",
    "section": "Mundo 1: INFERÊNCIA (Explorando as Relações)",
    "text": "Mundo 1: INFERÊNCIA (Explorando as Relações)\nPrimeiro, vamos explorar a correlação apenas nos dados de treino.\n\n# Seus gráficos originais, agora aplicados aos dados de TREINO\np1 &lt;- ggplot(bikes_treino, aes(x = temperature, y = rentals)) +\n  geom_point(color = \"#22562a\", size = 2, alpha = .5) +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Temperatura vs. Aluguéis\")\n\np2 &lt;- ggplot(bikes_treino, aes(x = humidity, y = rentals)) +\n  geom_point(color = \"#27276d\", size = 2, alpha = .5) +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Umidade vs. Aluguéis\")\n\np3 &lt;- ggplot(bikes_treino, aes(x = windspeed, y = rentals)) +\n  geom_point(color = \"#741012\", size = 2, alpha = .5) +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Vento vs. Aluguéis\")\n\n(p1 + p2) / p3"
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-inferência-explorando-as-relações-1",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-inferência-explorando-as-relações-1",
    "title": "Regressão Linear",
    "section": "Mundo 1: INFERÊNCIA (Explorando as Relações)",
    "text": "Mundo 1: INFERÊNCIA (Explorando as Relações)\n\nInsight: O gráfico Vento vs. Aluguéis mostra uma nuvem de pontos aparentemente aleatória. Se olhássemos só para ele, diríamos que windspeed (vento) não tem relação com rentals (aluguéis)."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-ajustando-o-modelo-linear-múltiplo",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-ajustando-o-modelo-linear-múltiplo",
    "title": "Regressão Linear",
    "section": "Mundo 1: Ajustando o Modelo Linear Múltiplo",
    "text": "Mundo 1: Ajustando o Modelo Linear Múltiplo\nVamos ajustar nosso primeiro modelo de regresão linear múltipla usando a função lm() nos dados de treino.\n\\[\n  rentals = \\beta_0 + \\beta_1 temperature + \\beta_2 humidity + \\beta_3 windspeed + \\varepsilon\n\\]\n\n# Ajustando o modelo v1\nmodelo &lt;- lm(rentals ~ temperature + humidity + windspeed, \n                data = bikes_treino)\n\n\nO summary() é a principal ferramenta de inferência.\n\nsummary(modelo) # Mostrando o sumário"
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-interpretando-o-summary",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-interpretando-o-summary",
    "title": "Regressão Linear",
    "section": "Mundo 1: Interpretando o summary()",
    "text": "Mundo 1: Interpretando o summary()\n\n\n\nCall:\nlm(formula = rentals ~ temperature + humidity + windspeed, data = bikes_treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4545.5 -1108.7  -103.4  1076.1  3649.7 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2212.748    416.264   5.316 1.52e-07 ***\ntemperature    79.092      3.975  19.898  &lt; 2e-16 ***\nhumidity    -2626.091    433.640  -6.056 2.51e-09 ***\nwindspeed     -95.367     19.655  -4.852 1.57e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1450 on 579 degrees of freedom\nMultiple R-squared:  0.4406,    Adjusted R-squared:  0.4377 \nF-statistic:   152 on 3 and 579 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-interpretando-o-summary-1",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-interpretando-o-summary-1",
    "title": "Regressão Linear",
    "section": "Mundo 1: Interpretando o summary()",
    "text": "Mundo 1: Interpretando o summary()\n\nTeste F (p-valor global): &lt; 2.2e-16. O modelo como um todo é significativo (é melhor que um “chute” na média).\nTestes t (p-valores individuais):\n\ntemperature: Significativo (p-valor &lt; 0.0001)\nhumidity: Significativo (p-valor &lt; 0.0001)\nwindspeed: Significativo (p-valor &lt; 0.0001)\nSe houvesse variáveis não significativas, deveríamos removê-las do modelo e rodar novamente.\n\nMétricas de Ajuste:\n\n\\(R^2\\) Ajustado: 0.4377. Cerca de 43.77% da variabilidade dos aluguéis nos dados de treino é explicada pelo modelo."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-interpretando-o-summary-2",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-interpretando-o-summary-2",
    "title": "Regressão Linear",
    "section": "Mundo 1: Interpretando o summary()",
    "text": "Mundo 1: Interpretando o summary()\nInsight: Este é um exemplo clássico de variável de confusão ou supressão. Sozinho, o vento não parece importar. Mas depois de controlarmos o efeito da temperature e humidity, o efeito real do vento aparece: com temperatura e umidade constantes, ventos mais fortes diminuem os aluguéis (coeficiente de -95.4). Isso mostra por que a Regressão Múltipla é mais poderosa que correlações simples."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-diagnóstico-validando-as-suposições",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-diagnóstico-validando-as-suposições",
    "title": "Regressão Linear",
    "section": "Mundo 1: Diagnóstico (Validando as Suposições)",
    "text": "Mundo 1: Diagnóstico (Validando as Suposições)\nPara confiarmos nas nossas inferências (p-valores e intervalos de confiança), precisamos checar as suposições do modelo (análise de resíduos).\nObservamos os gráficos:\n\n**Resíduos vs. Valores Ajustados (Linearidade/Homocedasticidade):* A linha deve estar perto de zero e os pontos devem estar aleatórios.\nQ-Q Plot (Normalidade dos Resíduos): Os pontos devem seguir a linha.\nScale-Location: Similar ao 1 (variância deve parecer constante).\nResíduos vs. Alavancagem (Pontos Influentes): Nenhuma Distância de Cook &gt; 0.5 (sem pontos de grande influência)."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-diagnóstico-validando-as-suposições-1",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-1-diagnóstico-validando-as-suposições-1",
    "title": "Regressão Linear",
    "section": "Mundo 1: Diagnóstico (Validando as Suposições)",
    "text": "Mundo 1: Diagnóstico (Validando as Suposições)\n\n# Gráficos de diagnóstico do R base\npar(mfrow = c(2, 2), bg = \"#F5F5F5\", mar = c(4, 4, 2, 1))\nplot(modelo, pch = 20, col = \"#27276d\", cex = 1.5)\n\npar(mfrow = c(1, 1)) # Resetar layout\n\nConclusão do Mundo 1: O gráfico de resíduos vs. valores ajustados indica uma relação não linear entre os resíduos, violando a suposição de que os erros são independentes e aleatoriamente distribuídos. Podemos transofrmar a variável resposta ou usar um modelo diferente."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-2-predição-a-hora-da-verdade",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-2-predição-a-hora-da-verdade",
    "title": "Regressão Linear",
    "section": "Mundo 2: PREDIÇÃO (A Hora da Verdade)",
    "text": "Mundo 2: PREDIÇÃO (A Hora da Verdade)\nO modelo não é tão bom para explicar as relações entre as variáveis. Mas ele é bom para prever?\nVamos usar o modelo (treinado com bikes_treino) para fazer predições nos dados que ele nunca viu: bikes_teste.\n\n# Usando o modelo para prever nos dados de TESTE\npredicoes_teste &lt;- predict(modelo, newdata = bikes_teste)\n\n# Vamos juntar o valor real com o valor previsto (estimate)\nresultados_teste &lt;- bikes_teste |&gt; \n  select(rentals) |&gt; \n  mutate(.pred = predicoes_teste) # Adicionamos a coluna de predições"
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-2-as-métricas-de-predição-rmse-e-mae",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-2-as-métricas-de-predição-rmse-e-mae",
    "title": "Regressão Linear",
    "section": "Mundo 2: As Métricas de Predição (RMSE e MAE)",
    "text": "Mundo 2: As Métricas de Predição (RMSE e MAE)\n\nNão olhamos mais para \\(R^2\\) ou p-valor. Agora, medimos o erro da predição.\nUsamos o pacote yardstick (parte do tidymodels) para calcular as métricas no conjunto de teste.\n\nRMSE (Root Mean Squared Error): O erro médio, na mesma unidade (rentals). Ele penaliza erros grandes. Quanto menor, melhor.\nMAE (Mean Absolute Error): O erro médio absoluto. Mais fácil de interpretar. Quanto menor, melhor."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-2-as-métricas-de-predição-rmse-e-mae-1",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-2-as-métricas-de-predição-rmse-e-mae-1",
    "title": "Regressão Linear",
    "section": "Mundo 2: As Métricas de Predição (RMSE e MAE)",
    "text": "Mundo 2: As Métricas de Predição (RMSE e MAE)\n\n# Calculando RMSE\nrmse_val &lt;- yardstick::rmse(resultados_teste, truth = rentals, estimate = .pred)\nrmse_val\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       1338.\n\n# Calculando MAE\nmae_val &lt;- yardstick::mae(resultados_teste, truth = rentals, estimate = .pred)\nmae_val\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 mae     standard       1110.\n\n\nConclusão do Mundo 2: Em média, nosso modelo erra em ~1110 aluguéis (MAE) ao tentar prever os aluguéis de um dia novo. Considerando que os aluguéis variam de ~1000 a ~7500 (pelos gráficos), um erro de 1110 é substancial."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-2-visualizando-o-erro-de-predição",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-2-visualizando-o-erro-de-predição",
    "title": "Regressão Linear",
    "section": "Mundo 2: Visualizando o Erro de Predição",
    "text": "Mundo 2: Visualizando o Erro de Predição\nUm gráfico de Valor Real vs. Valor Previsto é a melhor forma de ver a performance.\nSe o modelo fosse perfeito, todos os pontos estariam dispostos em linha reta (Y = X).\n\nggplot(resultados_teste, aes(x = rentals, y = .pred)) +\n  geom_point(color = \"#27276d\", alpha = 0.7, size = 2) +\n  # A linha de predição perfeita (y=x)\n  geom_abline(color = \"red\", linetype = \"dashed\", linewidth = 1.5) +\n  labs(\n    title = \"Performance de Predição nos Dados de TESTE\",\n    x = \"Valor Real (Aluguéis)\",\n    y = \"Valor Previsto (Aluguéis)\"\n  ) +\n  theme_minimal(base_size = 18) +\n  # Força os eixos a terem a mesma escala para uma comparação justa\n  coord_fixed()"
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#mundo-2-visualizando-o-erro-de-predição-1",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#mundo-2-visualizando-o-erro-de-predição-1",
    "title": "Regressão Linear",
    "section": "Mundo 2: Visualizando o Erro de Predição",
    "text": "Mundo 2: Visualizando o Erro de Predição\n\nInsight: O modelo tende a superestimar dias com menos de 2000 alugueis e a subestimar dias com muitos aluguéis (pontos acima de 6000)."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#modelos-mais-avançados",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#modelos-mais-avançados",
    "title": "Regressão Linear",
    "section": "Modelos Mais Avançados",
    "text": "Modelos Mais Avançados\n\nQuando o modelo linear falha, devemos tentar transformar a variaǘel resposta ou entar outros modelos, como GAMs (Modelos Aditivos Generalizados) ou Árvores de Regressão (e Random Forest).\nNo caso de modelos para predição, usamos diversos modelos diferentes e ficamos com aquele que apresentar menor RMSE/MAE nos dados de teste."
  },
  {
    "objectID": "slides/08-regressao_linear/08-regressao_linear.html#inferência-vs.-predição",
    "href": "slides/08-regressao_linear/08-regressao_linear.html#inferência-vs.-predição",
    "title": "Regressão Linear",
    "section": "Inferência vs. Predição",
    "text": "Inferência vs. Predição\nA Regressão Linear pode servir a dois propósitos:\n\n\n\n\n\n\n\n\nCaracterística\nINFERÊNCIA\nPREDIÇÃO\n\n\n\n\nObjetivo\nExplicar, Entender Relações\nPrever, Generalizar\n\n\nMétricas\n\\(R^2\\), \\(R^2\\) Ajustado, p-valores, Teste F\nRMSE, MAE, MAPE\n\n\nDados usados\nTreino\nTeste\n\n\nPergunta\n“Meu modelo é válido e as variáveis são significativas?”\n“Meu modelo é preciso em dados novos?”\n\n\nRisco\nConfundir \\(R^2\\) alto com boa predição.\nOverfitting (se não usar o teste).\n\n\n\n\nUm bom cientista de dados domina ambos os mundos."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#objetivo-da-aula",
    "href": "slides/10-knn/10-knn.html#objetivo-da-aula",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\n\nCompreender a intuição e o funcionamento matemático do algoritmo k-NN para tarefas de Classificação e Regressão.\nAplicar técnicas essenciais de pré-processamento, com ênfase na normalização de dados numéricos e codificação de variáveis categóricas.\nCalcular manualmente a distância euclidiana para determinar a similaridade entre instâncias.\nAnalisar o impacto da escolha do hiperparâmetro \\(k\\) no tradeoff entre viés e variância (overfitting vs underfitting).\nAvaliar as vantagens e limitações do paradigma de “aprendizado preguiçoso” (lazy learning) em comparação a modelos ansiosos."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#classificadores-de-vizinhos-mais-próximos-nearest-neighbors",
    "href": "slides/10-knn/10-knn.html#classificadores-de-vizinhos-mais-próximos-nearest-neighbors",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Classificadores de vizinhos mais próximos (nearest neighbors)",
    "text": "Classificadores de vizinhos mais próximos (nearest neighbors)\n\nSão classificadores que atribuem rótulos a instâncias não rotuladas a partir da similaridade com exemplos rotulados.\nEsses classificadores buscam replicar a capacidade humana de extrair conclusões sobre situações atuais a partir de experiências passadas.\nExemplos de aplicações bem sucedidas:\n\nVisão computacional: reconhecimento de caracteres e reconhecimento facial em imagens estáticas e vídeos;\nSistemas de recomendação que preveem se uma pessoa irá gostar de um filme ou música;\nIdentificação de padrões em dados genéticos para detectar proteínas ou doenças específicas."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#o-algoritmo-k-nn",
    "href": "slides/10-knn/10-knn.html#o-algoritmo-k-nn",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "O algoritmo k-NN",
    "text": "O algoritmo k-NN\n\nO algoritmo k-NN utiliza informações sobre os \\(k\\) vizinhos mais próximos de um exemplo para classificar exemplos não rotulados.\nA letra \\(k\\) representa o número de vizinhos mais próximos que serão usados para a classificação de uma instância sem rótulo.\n\nDefinido \\(k\\), o algoritmo usa um conjunto de dados de treinamento classificados em várias categorias.\nPara cada instância não rotulada, o k-NN identifica as \\(k\\) instâncias mais similares nos dados de treinamento.\nÀ instância sem rótulo é atribuída a classe da maioria dos \\(k\\) vizinhos mais próximos."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#section",
    "href": "slides/10-knn/10-knn.html#section",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "",
    "text": "FONTE: NWANGANGA, Fred; CHAPPLE, Mike. Practical machine learning in R. John Wiley & Sons, 2020."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#vantagens-e-desvantagens",
    "href": "slides/10-knn/10-knn.html#vantagens-e-desvantagens",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Vantagens e desvantagens",
    "text": "Vantagens e desvantagens\n\n\n\n\n\n\nVantagens\n\n\n\nSimples e efetivo.\nNão faz suposições sobre a distribuição dos dados (não paramétrico).\nFase de treinamento rápida (apenas armazena os dados).\n\n\n\n\n\n\n\n\n\n\nDesvantagens\n\n\n\nNão produz um modelo explícito, limitando a interpretabilidade de como as características afetam a classe.\nRequer a seleção de um \\(k\\) apropriado.\nFase de classificação lenta (custosa computacionalmente).\nCaracterísticas nominais e dados ausentes exigem processamento adicional cuidadoso."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#encontrando-os-vizinhos-mais-próximos",
    "href": "slides/10-knn/10-knn.html#encontrando-os-vizinhos-mais-próximos",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Encontrando os vizinhos mais próximos",
    "text": "Encontrando os vizinhos mais próximos\n\nPara encontrar os vizinhos mais próximos de uma instância é preciso calcular a distância entre as instâncias.\nTradicionalmente, o algoritmo k-NN usa a distância euclidiana:\n\nSejam \\(p\\) e \\(q\\) duas instâncias com \\(n\\) atributos. Então a distância euclidiana entre \\(p\\) e \\(q\\) é dada por \\[\ndist(p,q) = \\sqrt{(p_1-q_1)^2 +(p_2-q_2)^2 + \\cdots + (p_n-q_n)^2}\n\\] em que \\(p_i\\) e \\(q_i\\), \\(i=1,\\ldots,n\\), representam os atributos associados às instâncias \\(p\\) e \\(q\\), respectivamente.\n\nOutras distâncias que podem ser usadas: distância de Hamming, distância de Manhattan (ou L1), distância Minkowski e distância de Mahalanobis."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#preparando-os-dados",
    "href": "slides/10-knn/10-knn.html#preparando-os-dados",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Preparando os dados",
    "text": "Preparando os dados\n\nObservação: antes do cálculo da distância euclidiana devemos normalizar os atributos, pois atributos com valores mais elevados tendem a ter um impacto desproporcional no cálculo de distância.\nPara o k-NN podemos usar a normalização min-max: \\[\nx_{novo} = \\frac{x - min(X)}{max(X)-min(X)}\n\\]\nou a transformação z-score: \\[\nx_{novo} = \\frac{x - média(X)}{DesvPad(X)}.\n\\]"
  },
  {
    "objectID": "slides/10-knn/10-knn.html#preparando-os-dados-variáveis-categóricas",
    "href": "slides/10-knn/10-knn.html#preparando-os-dados-variáveis-categóricas",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Preparando os dados (Variáveis Categóricas)",
    "text": "Preparando os dados (Variáveis Categóricas)\n\nSe o atributo é do tipo nominal, devemos transformá-lo.\nAtenção: Embora em regressão usemos \\(n-1\\) dummies, em algoritmos de distância (k-NN) é comum usar One-Hot Encoding (criar \\(n\\) variáveis) para manter a equidistância entre categorias.\nExemplo: se o atributo temperatura possui as categorias quente, médio e frio:\n\n\n\n\\[\nquente = \\begin{cases}\n  1 & \\text{se } x = \\text{ quente}\\\\\n  0 & \\text{caso contrário}\n\\end{cases}\n\\] \\[\nfrio = \\begin{cases}\n  1 & \\text{se } x = \\text{ frio}\\\\\n  0 & \\text{caso contrário}\n\\end{cases}\n\\]\n\n\\[\nmédio = \\begin{cases}\n  1 & \\text{se } x = \\text{ médio}\\\\\n  0 & \\text{caso contrário}\n\\end{cases}\n\\]\n\n\nComo a dummy possui apenas os valores 0 e 1, os valores caem na mesma escala da transformação min-max."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#exemplo",
    "href": "slides/10-knn/10-knn.html#exemplo",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Exemplo",
    "text": "Exemplo\nConsidere os dados de treinamento abaixo. Calcule a distância euclidiana para um novo paciente com 45 anos e colesterol de 225 (após normalizar).\n\n\n\n\n\nPaciente\nIdade\nColesterol\nDoença\n\n\n\n\n1\n45\n297\nF\n\n\n2\n41\n172\nV\n\n\n3\n46\n202\nV\n\n\n4\n48\n193\nV\n\n\n5\n46\n243\nF\n\n\n\n\n\n\n\nPaciente\nIdade\nColesterol\nDoença\n\n\n\n\n6\n48\n256\nV\n\n\n7\n49\n212\nV\n\n\n8\n41\n289\nV\n\n\n9\n49\n271\nF\n\n\n10\n43\n315\nF\n\n\n\n\n\nAtividade: Ordene os dados de treino da menor distância para a maior distância do novo paciente e classifique usando \\(k=3\\)."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#determinando-k-apropriado",
    "href": "slides/10-knn/10-knn.html#determinando-k-apropriado",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Determinando \\(k\\) apropriado",
    "text": "Determinando \\(k\\) apropriado\n\nA decisão de quantos vizinhos usar determina a generalização do modelo (Tradeoff Viés-Variância).\n\n\\(k\\) pequeno: Baixo viés, alta variância. O modelo é sensível a ruídos (Overfitting).\n\\(k\\) grande: Alto viés, baixa variância. O modelo é muito simples e ignora padrões locais (Underfitting).\n\nO valor escolhido para \\(k\\) em classificação binária deve ser preferencialmente ímpar para evitar empates.\nUma forma de determinar \\(k\\) é testar diversos valores com os dados de validação e escolher aquele com menor erro."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#por-que-o-algoritmo-k-nn-é-preguiçoso",
    "href": "slides/10-knn/10-knn.html#por-que-o-algoritmo-k-nn-é-preguiçoso",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Por que o algoritmo k-NN é preguiçoso?",
    "text": "Por que o algoritmo k-NN é preguiçoso?\n\nAlgoritmos de classificação baseados em métodos de vizinho mais próximo são considerados algoritmos de aprendizado preguiçoso (lazy learning).\nUm aprendiz preguiçoso não está realmente “aprendendo” um modelo matemático durante o treino; ele apenas armazena os dados.\nO processamento real acontece apenas na hora da classificação (inferência).\nO aprendizado preguiçoso também é conhecido como aprendizado baseado em instâncias ou aprendizado por repetição."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#e-a-regressão-k-nn",
    "href": "slides/10-knn/10-knn.html#e-a-regressão-k-nn",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "E a Regressão k-NN?",
    "text": "E a Regressão k-NN?\n\nEm problemas de regressão, a estimativa é numérica. Pode-se usar a média simples ou a média ponderada (preferível).\nA média ponderada pelo inverso da distância dá mais importância aos vizinhos muito próximos: \\[\n\\widehat{y}_{nova} = \\frac{\\sum_{i=1}^k w_i \\cdot y_i}{\\sum_{i=1}^k w_i}\n\\] em que:\n\n\\(y_i\\) é o valor da variável resposta do vizinho \\(i\\);\n\\(w_i = \\frac{1}{distancia(x_{novo}, x_i)}\\) é o peso."
  },
  {
    "objectID": "slides/10-knn/10-knn.html#escolha-de-k-na-regressão-k-nn",
    "href": "slides/10-knn/10-knn.html#escolha-de-k-na-regressão-k-nn",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Escolha de \\(k\\) na Regressão k-NN",
    "text": "Escolha de \\(k\\) na Regressão k-NN\n\nO valor de \\(k\\) é escolhido como aquele que produz menor erro nos dados de validação. Métricas comuns:\n\nErro médio absoluto (MAE):\n\\[MAE(y,\\widehat{y}) = \\frac{1}{n}\\sum\\limits_{i=1}^n|y_i-\\widehat{y}_i|\\]\nErro quadrático médio (MSE): \\[MSE(y,\\widehat{y}) = \\frac{1}{n}\\sum\\limits_{i=1}^n (y_i-\\widehat{y}_i)^2\\]"
  },
  {
    "objectID": "slides/10-knn/10-knn.html#escolha-de-k-na-regressão-k-nn-1",
    "href": "slides/10-knn/10-knn.html#escolha-de-k-na-regressão-k-nn-1",
    "title": "K-Nearest Neighbors (k-NN)",
    "section": "Escolha de \\(k\\) na Regressão k-NN",
    "text": "Escolha de \\(k\\) na Regressão k-NN\n\nRaiz do erro quadrático médio (RMSE): \\[RMSE(y,\\widehat{y}) = \\sqrt{\\frac{1}{n}\\sum\\limits_{i=1}^n (y_i-\\widehat{y}_i)^2}\\]"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#objetivo-da-aula",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#objetivo-da-aula",
    "title": "Pré-Processamento de Dados",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\n\nDominar o pipeline de pré-processamento de dados"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#por-que-pré-processar-os-dados",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#por-que-pré-processar-os-dados",
    "title": "Pré-Processamento de Dados",
    "section": "Por que Pré-Processar os Dados",
    "text": "Por que Pré-Processar os Dados\n\nA qualidade de um modelo depende completamente da qualidade dos dados que utilizamos para construí-lo.\nFacilmente encontramos em bases de dados:\n\nRuído (noisy): Valores errados ou impossíveis (ex: um paciente com IDADE = 200 anos).\nInconsistência (inconsistency): A mesma informação registrada de formas diferentes (ex: MUNICIPIO = “Aracaju”, “Aracajú”).\nHeterogeneidade (heterogeneity): Dados de múltiplas fontes, com formatos e chaves diferentes (ex: o código o município do Censo Escolar e do SIM usando padrões diferentes – 6 ou 7 dígitos).\nDados faltantes (Missing): O famoso NA."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#por-que-pré-processar-os-dados-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#por-que-pré-processar-os-dados-1",
    "title": "Pré-Processamento de Dados",
    "section": "Por que Pré-Processar os Dados",
    "text": "Por que Pré-Processar os Dados\n\nO objetivo do pré-processamento de dados é transformar dados brutos e “sujos” em um conjunto de dados limpo, coeso e de alta qualidade que seja apropriado para a mineração.\n\n\n\nAntes de aplicar qualquer técnica de limpeza, transformação ou integração, precisamos fazer um diagnóstico. A primeira e mais fundamental etapa desse diagnóstico é entender a natureza dos nossos dados.\nPrecisamos identificar os tipos de atributos (ou variáveis) que temos."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-dados-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-dados-1",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Dados",
    "text": "Tipos de Dados\nTodo conjunto de dados é composto por duas partes fundamentais, assim como uma planilha:\n\nObjetos de Dados (as Linhas): Representam a entidade que estamos observando.\n\nTambém chamados de: amostras, instâncias, casos ou tuplas (em bancos de dados).\nExemplos: um paciente, um cliente, um município, um domicílio.\n\nAtributos (as Colunas): Representam a característica ou propriedade que descreve o objeto.\n\nTambém chamados de: dimensões, features (em Machine Learning) ou variáveis (nosso termo preferido em Estatística).\nExemplos: IDADE, SEXO, POPULACAO_2022, IDH_M.\n\nClassificar os tipos de atributos, define quais técnicas estatísticas e de mineração podemos usar. Vejamos as classificações."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Atributos",
    "text": "Tipos de Atributos\nNominal\n\nA ordem não importa.\nExemplos: ocupacao(estatístico, médico, professor…), COD_MUNICIPIO_IBGE (ex: “2800308” = Aracaju).\nUm atributo nominal pode usar números (como COD_MUN_IBGE ou ID_cliente), mas operações matemáticas são sem sentido.\n\nNão podemos calcular a “média” dos códigos de município.\nA única medida de tendência central válida é a Moda (o valor mais frequente)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-1",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Atributos",
    "text": "Tipos de Atributos\nBinário (booleano)\n\nÉ um atributo nominal com apenas dois estados).\nExemplos: OBITO (1=Sim, 0=Não), FUMANTE (1=Sim, 0=Não).\nSubtipos Importantes:\n\nSimétrico: Ambos os estados têm o mesmo “peso”. Ex: SEXO (M/F).\nAssimétrico: Um estado é mais “raro” ou “importante”. Ex: TESTE_COVID (Positivo=1, Negativo=0). Por convenção, o “1” é o resultado de maior interesse."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-2",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Atributos",
    "text": "Tipos de Atributos\nOrdinal\n\nOs valores têm uma ordem ou ranking significativo, mas a magnitude (distância) entre eles é desconhecida.\nSabemos que Grande &gt; Médio &gt; Pequeno, mas não o quanto “Grande” é maior que “Médio”.\nExemplos: ESCOLARIDADE (Analfabeto &lt; Fundamental &lt; Médio &lt; Superior), SATISFACAO_ATENDIMENTO: (Muito Ruim, Ruim, Neutro, Bom, Muito Bom).\nEstatísticas Válidas: Moda e Mediana. A Média ainda não faz sentido."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-3",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-3",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Atributos",
    "text": "Tipos de Atributos\nQuantitativo (Numérico)\nSão quantidades mensuráveis (números inteiros ou reais) onde as operações matemáticas (média, desvio padrão) fazem sentido. Há dois tipos:\n\nIntervalar (Interval-Scaled): Tem ordem e as “distâncias” (intervalos) são iguais. O zero é apenas um ponto na escala, não significa ausência. Exemplos:\n\nTemperatura (°C / °F): 0°C não é “ausência de temperatura”. Não podemos dizer que 20°C é “o dobro do calor” de 10°C.\nDatas (Ano): O “Ano 0” não foi o começo do tempo.\n\n\n\nOperações: Média, Mediana, Moda, Diferenças (20°C – 10°C = 10°C)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-4",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-4",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Atributos",
    "text": "Tipos de Atributos\nQuantitativo (Numérico)\n\nRacional (Ratio-Scaled): Tem ordem, distâncias iguais E POSSUI UM “ZERO VERDADEIRO”. O Zero (0) significa a ausência total da medida.\n\nVL_TOTAL_INTERNACAO (R$ 0,00 é ausência de custo).\nIDADE, PESO, ALTURA.\nRENDA_MENSAL, N_DE_FILHOS.\n\n\n\nOperações: Todas! Média, Mediana, Moda, Diferenças e Razões (R$ 100 é exatamente o dobro de R$ 50)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#a-visão-do-machine-learning",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#a-visão-do-machine-learning",
    "title": "Pré-Processamento de Dados",
    "section": "A Visão do Machine Learning",
    "text": "A Visão do Machine Learning\nMuitas vezes, os algoritmos e softwares (como R e Python) simplificam a classificação em dois grandes grupos, que não são exatamente iguais aos anteriores, mas os englobam.\n\nAtributo DISCRETO: Possui um conjunto de valores finito ou infinito contável (geralmente inteiros). Engloba:\n\nNominal (ex: RACA_COR)\nBinário (ex: OBITO)\nOrdinal (ex: ESCOLARIDADE)\nNuméricos Inteiros (ex: N_DE_FILHOS, DIAS_DE_INTERNACAO)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#a-visão-do-machine-learning-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#a-visão-do-machine-learning-1",
    "title": "Pré-Processamento de Dados",
    "section": "A Visão do Machine Learning",
    "text": "A Visão do Machine Learning\n\nAtributo CONTÍNUO: Possui um número infinito de valores “não contáveis” dentro de um intervalo (números reais, floating-point). Engloba atributos numéricos (Intervalares ou Racionais) que são medidos com casas decimais:\n\nPESO (ex: 75,32 kg)\nTAXA_MORTALIDADE_INFANTIL (ex: 12.4 por 1000)\nVL_MEDICAMENTO (ex: R$ 150,75)"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#pré-processamento-de-dados-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#pré-processamento-de-dados-1",
    "title": "Pré-Processamento de Dados",
    "section": "Pré-Processamento de Dados",
    "text": "Pré-Processamento de Dados\n\nDados de entrada incorretos ou de baixa qualidade resultam inevitavelmente em saídas incorretas ou de baixa qualidade.\nSe não for tomado o devido cuidado em lidar adequadamente com questões de qualidade de dados antes de treinar um modelo, a saída do modelo será não confiável, enganadora ou simplesmente incorreta.\n\nObjetivo: Arrumar os dados para iniciar uma análise de boa qualidade. Questões que temos que lidar:\n\nTratamento de Inconsistências\nValores Ausentes (Missing Values)\nRuído (Noise)\nIntegração de Dados (Data Integration)\nTransformação de Dados (Data Transformation)\nRedução de Dados (Data Reduction)\n\n\nVejamos detalhes de cada fase."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tratamento-de-inconsistências-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tratamento-de-inconsistências-1",
    "title": "Pré-Processamento de Dados",
    "section": "1. Tratamento de Inconsistências",
    "text": "1. Tratamento de Inconsistências\n\nOcorre quando o mesmo dado é registrado de formas diferentes (sintaxe) ou quando um valor viola uma regra lógica (semântica).\nComo identificar?\n\nPara categorias: Fazer uma tabela de frequência para avaliar se há registros com sintaxe diferente (ex: municipio com respostas “Aracaju” e “Aracajú”).\nPara numéricos: Obter mínimo, máximo e Boxplots para ver se há valores fora do possível (ex: idade_da_mae = 5 anos).\n\nO que fazer:\n\nPadronização de categorias: Agrupar sinônimos ou erros de digitação em um único rótulo padrão (ex: “Aracajú”, “AJU”, “Aracaju” → “Aracaju”).\nValidação de regras: Transformar valores inválidos em NAs."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-nas-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-nas-1",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values, NAs)",
    "text": "2. Valores Ausentes (Missing Values, NAs)\nUm NA pode ocorrer por 2 fatores principais:\n\nErro Aleatório:\n\nO digitador esqueceu; o paciente/cliente não quis informar.\nAção: Imputação.\n\nErro Estrutural / “Não Aplicável”:\n\nEx (DATASUS): DATA_OBITO está NA (porque o paciente está vivo).\nEx (CadÚnico): NOME_ESCOLA_FILHO está NA (porque a família não tem filhos).\nAção: Não imputar! O NA aqui é informação. Talvez criar uma categoria “Não Aplicável”.\n\n\nMoral: Sempre leia o Dicionário de Dados!"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values)",
    "text": "2. Valores Ausentes (Missing Values)\nAo lidarmos com NAs, algumas estratégias costumam ser utilizadas:\n\nRemover a linha inteira se ela tiver algum NA;\nSubstituir por uma constante;\nSubstituir por uma medida de tendência central;\nSubstituir pelo valor mais provável."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-1",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values)",
    "text": "2. Valores Ausentes (Missing Values)\na. Remover a linha inteira se ela tiver algum NA\n\nRemover a linha inteira apenas se o NA ocorreu por acaso e se a perda for menor que 5% dos dados.\nProblema:\n\nPerda de Informação: Se o NA estava só em RACA_COR, jogamos fora IDADE, SEXO, MUNICIPIO e o desfecho (a label).\nViés de Seleção (PERIGO!): E se os dados não estiverem faltando ao acaso?\n\nExemplo: Se só os mais ricos não responderam a renda e você remove os mais ricos da sua análise, o seu modelo se torna enviesado."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-2",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values)",
    "text": "2. Valores Ausentes (Missing Values)\nb. Substituir por uma constante\n\nNA em RENDA → 0\nNA em RACA_COR → \"Desconhecido\" ou \"99\"\nProblema:\n\nO algoritmo pode erroneamente achar que “os NAs formam um conceito interessante”.\nO modelo aprende que “Renda = 0” é um forte preditor, quando na verdade ele só significa “dado faltante”.\nIsso distorce a distribuição dos dados (ex: cria um pico falso no “0”)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-3",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-3",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values)",
    "text": "2. Valores Ausentes (Missing Values)\nc. Substituir por uma medida de tendência central\nSubstitui o NA pela medida “do meio” da distribuição daquele atributo. * A Regra de Ouro: * Média: Usar se a distribuição for simétrica (ex: IDADE, se for normal). * Mediana: Usar se a distribuição for assimétrica (ex: RENDA). * Vantagem: É rápido e preserva a média/mediana geral. * Desvantagem: Ignora as relações entre variáveis e “achata” a variância (subestima a variabilidade real)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-4",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-4",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values)",
    "text": "2. Valores Ausentes (Missing Values)\nd. Substituir pelo valor mais provável\nEsta é a abordagem moderna e preferida na maioria dos casos. Trata o valor ausente como um problema de predição.\n\nConceito: Usamos os outros atributos (X1, X2, X3) para prever o valor faltante (Y_na).\nComo?\n\nRegressão: Para prever RENDA (numérico) usando IDADE e ESCOLARIDADE.\nÁrvore de Decisão / k-NN: Para prever RACA_COR (categórico) usando MUNICIPIO e RENDA.\nNo R: Pacotes como recipes (Tidymodels) ou mice fazem isso.\n\nVantagem: Usa a maior parte da informação dos dados presentes e preserva as relações entre os atributos."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-1",
    "title": "Pré-Processamento de Dados",
    "section": "3. Ruído (Noise)",
    "text": "3. Ruído (Noise)\nRuído é um erro aleatório ou variância em uma variável medida.\n\nNão é um NA, mas um valor que parece “deslocado”.\nExemplo (SIH/DATASUS):\n\nUma internação por apendicite (VL_TOTAL) com custo de R$ 1,50.\nUma internação com custo de R$ 5.000.000,00 (enquanto a média é R$ 2.000,00).\n\nObjetivo: “Suavizar” (smooth) esses dados para remover a variação aleatória sem perder o sinal verdadeiro."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-2",
    "title": "Pré-Processamento de Dados",
    "section": "3. Ruído (Noise)",
    "text": "3. Ruído (Noise)\nTécnica 1: Binning (Agrupamento ou Discretização)\nBinning é uma técnica de suavização local (olha a “vizinhança”).\nO Processo (Ex: VALOR_INTERNACAO):\n\nOrdenar os dados: [4, 8, 15, 21, 21, 24, 25, 28, 34]\nParticionar em “Bins” (Baldes):\n\nEx: Bins de frequência igual (tamanho 3)\nBin 1: [4, 8, 15]\nBin 2: [21, 21, 24]\nBin 3: [25, 28, 34]\n\nSubstituir (Suavizar): Aplicar uma regra ao bin."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-3",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-3",
    "title": "Pré-Processamento de Dados",
    "section": "3. Ruído (Noise)",
    "text": "3. Ruído (Noise)\nTipos de Suavização por Binning\nUsando o exemplo (Bin 1: [4, 8, 15]):\n1. Suavização pela MÉDIA: * O que faz: Substitui todos os valores pela média do bin. * Ex: Média(4, 8, 15) = 9 * Resultado: [9, 9, 9]\n2. Suavização pela MEDIANA: (Muito recomendado!) * O que faz:** Substitui todos pela mediana do bin (robusto a outliers!). * Ex: Mediana(4, 8, 15) = 8 * Resultado: [8, 8, 8]\n3. Suavização pelos LIMITES: * O que faz: Substitui cada valor pelo limite (min/max) mais próximo. * Ex: [4, 8, 15] -&gt; [4, 4, 15] (8 está mais perto de 4 do que de 15)"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-4",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-4",
    "title": "Pré-Processamento de Dados",
    "section": "3. Ruído (Noise)",
    "text": "3. Ruído (Noise)\nTécnica 2 e 3: Regressão e Análise de Outliers\nO Binning não é a única forma de suavizar dados.\nRegressão: Ajusta os dados a uma função (ex: uma linha de regressão linear). * Como suaviza? O “ruído” é a variação aleatória (o erro, \\(\\epsilon\\)) ao redor da linha. O valor “suavizado” é o valor predito pela linha.\nAnálise de Outliers (via Clustering): Agrupa dados similares (clusters). * Como suaviza? Valores que caem fora dos clusters podem ser considerados outliers (ruído)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-1",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nÉ o processo de combinar dados de múltiplas fontes.\nO Desafio: Os dados nunca vêm de uma única fonte limpa. * Queremos cruzar Taxas de Mortalidade (SIM/DATASUS)… * … com Indicadores Socioeconômicos (Censo/IBGE)… * … com Dados de Escolaridade (CadÚnico)… * … para cada Município de Sergipe.\nTemos quatro grandes desafios ao fazer isso. Vejamos."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-2",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nDesafio 1: O Problema da Identificação da Entidade\nComo o computador sabe que ‘Aracaju’ é ‘Aracaju’?\n\nDefinição: Como parear entidades do mundo real (pacientes, municípios, clientes) que estão em bases diferentes?\nEx: id_cliente (Base A) vs. numero_cliente (Base B).\n\nExemplo: * Base IBGE (Censo): O código de Aracaju é CD_MUN_IBGE = “2800308” (7 dígitos). * Base DATASUS (SIH): O código de Aracaju é CD_MUN_DATASUS = “280030” (6 dígitos). * Solução: Não dá para juntar direto! Precisamos transformar CD_MUN_IBGE para criar uma chave compatível com CD_MUN_DATASUS."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-3",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-3",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nDesafio 2: Conflito de Valores\nOk, conseguimos fazer o join() pelo código do município. Agora o problema é outro: os valores não “falam” a mesma língua.\nCausas (do Texto):\n\nDiferença de Escala/Unidade: (O mais comum!)\n\nBase A (IBGE): RENDA em “Salários Mínimos”.\nBase B (CadÚnico): RENDA_PER_CAPITA em “Reais (R$)”.\nBase C (World Bank): GDP em “Dólares (USD)”.\n\nDiferença de Abstração:\n\nBase A (SIH): VL_TOTAL_INTERNACAO (nível do paciente).\nBase B (CNES): ORCAMENTO_ANUAL_HOSPITAL (nível da unidade).\n\nDiferença de Semântica:\n\nBase A: INDICE_ESCOLARIDADE (População &gt; 18 anos).\nBase B: INDICE_ESCOLARIDADE (População &gt; 25 anos)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-4",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-4",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nDesafio 3: Redundância (“Informação Repetida”)\nUm atributo que pode ser “derivado” de outros.\n\nExemplo:\n\nVocê baixa uma tabela que tem as colunas:\nPOP_TOTAL\nPOP_URBANA\nPOP_RURAL\n\nProblema: POP_TOTAL é redundante (é POP_URBANA + POP_RURAL).\nPor que é ruim?\n\nAumenta a dimensionalidade (Maldição da Dimensionalidade).\nViola premissas de alguns modelos (ex: Multicolinearidade em Regressão).\nDá peso duplicado a uma mesma informação em algoritmos de distância (K-means)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-5",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-5",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nComo Detectar Redundância? Com Estatística!\nPara Atributos NUMÉRICOS (ex: POP_TOTAL vs POP_URBANA): * Coeficiente de Correlação (Pearson) * cor(dados$pop_total, dados$pop_urbana) * Se \\(r\\) for muito alto (ex: &gt; 0.9), há forte suspeita de redundância. * Covariância\nPara Atributos NOMINAIS (Categóricos): * Teste \\(\\chi^2\\) (Qui-Quadrado) * chisq.test(table(dados$var1, dados$var2)) * Mede a independência. Se \\(p\\)-valor for baixo (ex: &lt; 0.05), as variáveis são dependentes, o que pode indicar redundância (ex: COD_MUNICIPIO e NOME_MUNICIPIO são 100% dependentes)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-6",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-6",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nDesafio 4: Duplicação de linhas\nA mesma entidade (linha) aparece mais de uma vez.\n\nExemplo: O mesmo cliente (\"João da Silva\") aparece duas vezes na tabela de compras, uma com endereço “Rua A” e outra com “Rua B” (pois ele se mudou e a base não foi atualizada corretamente).\nExemplo:\n\nRecord Linkage (Ligação de Registros)\nA paciente MARIA JOSE DA SILVA (do CadÚnico) é a mesma paciente M J SILVA (do SINAN/Dengue)?\n\nProblema: Gera inconsistências e superestima contagens.\nSolução: Requer técnicas avançadas (ex: fuzzy matching) para encontrar duplicatas “prováveis” e consolidá-las. (Isso dá um ótimo TCC com o Prof. Sadraque!)"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-1",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\n\nFrequentemente é preciso modificar a estrutura ou características dos dados para formas “apropriadas para a mineração”.\nAlgumas técnicas usadas são:\n\nNormalização Z-score;\nNormalização Min-Max;\nTransformação logarítmica;\nDiscretização;\nCodificação de variáveis dummy."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-2",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\na. Normalização Z-score\n\nConhecida como normalização z-score ou normalização de média zero.\nEsta abordagem resulta em valores com média 0 e variância 1.\nA variável normalizada \\(v'\\) é dada por \\[ v' = \\frac{v-\\overline{v}}{\\sigma_v}, \\] em que \\(v\\) é a variável original, \\(\\overline{v}\\) é a média da variável \\(v\\) e \\(\\sigma_v\\) é o desvio padrão da variável \\(v\\).\n\nQuem Precisa Disso?\n\nK-Means (Clusterização), K-Nearest Neighbors (K-NN) (Classificação), SVM (Classificação), Redes Neurais, PCA (Redução de Dimensionalidade).\n\nBasicamente, qualquer algoritmo baseado em distância!"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-3",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-3",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\nb. Normalização Min-Max\n\nMapeia linearmente os valores para um novo intervalo, geralmente [0, 1], usando: \\[\nv'_{i} = \\frac{v_i - \\min_A}{\\max_A - \\min_A} \\times (\\text{novo_max} - \\text{novo_min}) + \\text{novo_min}\n\\] (Para [0, 1], os dois últimos termos desaparecem).\n\nExemplo (RENDA):\n\n\\(v = 700\\), \\(\\min = 200\\), \\(\\max = 2000\\)\n\\(v' = (700 - 200) / (2000 - 200) = 500 / 1800 = 0.277\\)\nVantagem: Preserva as relações lineares.\nDesvantagem: Extremamente sensível a outliers! Um único valor de Renda de R$ 50.000 (um erro) “espremeria” todos os outros dados perto de 0."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-4",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-4",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\nAtenção!!!\nNUNCA ajuste seus parâmetros de normalização (min/max ou z-score) usando os dados de TREINO E TESTE juntos!\nIsto é um vazamento de dados (data leakage). Você estaria “contando” ao seu modelo de treino sobre a distribuição do futuro (teste).\nO Processo Correto (Pipeline):\n\nDivida os dados: Treino e Teste.\nCalcule os parâmetros (ex: mean(), sd()) APENAS no conjunto de Treino.\nAplique esses mesmos parâmetros em ambos (Treino e Teste).\nNo R (Tidymodels), o recipe() + step_normalize() faz isso automaticamente!"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-5",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-5",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\nc. Transformação logarítmica\n\nAs transformações anteriores são boas quando os dados são simétricos.\nA transformação logarítmica é mais adequada para distribuições assimétricas e dados com valores que variam amplamente em magnitude.\nA transformação é \\[ v' = \\log(v). \\]"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-6",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-6",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\nd. Discretização\n\nA discretização consiste em transformar variáveis contínuas em categóricas.\nAlguns algoritmos exigem que a variável independente seja binária ou tenha um número limitado de valores distintos.\nEsse processo pode ser feito usando a suavização com médias de intervalo ou suavização com limites de intervalo.\nOutra forma comum é a dicotomização.\n\nExemplo: Os valores \\(\\{4,8, 9,15, 21, 21, 24, 25, 26, 28, 29,34\\}\\) seriam dicotomizados usando \\(20\\) como valor de corte, ficando \\(\\{0, 0, 0, 0,1,1,1,1,1,1,1,1\\}\\)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-7",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-7",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\ne. Codificação de variáveis dummy\n\nUma variável dummy é uma dicotomização de uma variável contínua.\nEla é muito usada em algoritmos que exigem que os atributos independentes sejam numéricos (como regressão ou k-NN) e como uma forma de representar dados ausentes.\nSuponha que temos a variável abaixo:\n\n\n\n\nEscolaridade\nCódigo\n\n\n\n\nEnsino Fundamental\n1\n\n\nEnsino Médio\n2\n\n\nEnsino Superior\n3"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-8",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-8",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\ne. Codificação de variáveis dummy\n\nUsando uma variável dummy completa, temos:\n\n\n\n\nEscolaridade\nEnsino Médio\nEnsino Superior\n\n\n\n\nEnsino Fundamental\n0\n0\n\n\nEnsino Médio\n1\n0\n\n\nEnsino Superior\n0\n1\n\n\n\n\nAgora, ao invés de uma variável, temos \\(2\\) variáveis dummies.\nEm geral, o número de variáveis dummies criadas é \\(n-1\\), em que \\(n\\) é o número de categorias da variável original.\nEm geral, a categoria que não virou dummy é porque ela é, de alguma forma, menos importante para o estudo."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#redução-de-dados-data-reduction-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#redução-de-dados-data-reduction-1",
    "title": "Pré-Processamento de Dados",
    "section": "6. Redução de Dados (Data Reduction)",
    "text": "6. Redução de Dados (Data Reduction)\nO Objetivo: Reduzir o número de colunas (\\(k\\)) de \\(d\\) para \\(k\\) (onde \\(k &lt; d\\)), preservando o máximo de “sinal” e removendo “ruído”.\nTrês Estratégias Principais:\n\nProjeção Linear (PCA - Principal Components Analysis):\n\nO que faz: Combina atributos correlacionados para criar novos eixos (Componentes Principais) que capturam o máximo de variância dos dados.\nResultado: Um novo dataset (ex: \\(k=5\\)) onde cada coluna é uma combinação linear das originais (ex: \\(d=50\\))."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#redução-de-dados-data-reduction-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#redução-de-dados-data-reduction-2",
    "title": "Pré-Processamento de Dados",
    "section": "6. Redução de Dados (Data Reduction)",
    "text": "6. Redução de Dados (Data Reduction)\n\nSeleção de Atributos (Attribute Subset Selection):\n\nO que faz: Remove atributos irrelevantes ou redundantes. Não cria novas colunas.\nComo: Métodos greedy (Heurísticos) como Forward Selection (adiciona o melhor) ou Backward Elimination (remove o pior).\nResultado: Um subconjunto do dataset original (ex: \\(k=10\\) das \\(d=50\\) colunas originais).\n\nMapeamento Não Linear (ex: t-SNE, Kernel PCA):\n\nO que faz: (Para quando o PCA falha). Mapeia os dados de alta dimensão para baixa dimensão (ex: \\(k=2\\) ou \\(k=3\\)) preservando a estrutura de vizinhança (proximidade).\nResultado: Essencial para visualizar clusters complexos que são “emaranhados” nos dados originais."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#objetivo-da-aula",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#objetivo-da-aula",
    "title": "Introdução ao Quarto",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\nAprender a criar, editar e renderizar documentos Quarto no RStudio, integrando\n\ntexto;\ncódigo;\ntabelas;\nsaídas do R;\ngráficos;\nreferências."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#estrutura-da-aula",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#estrutura-da-aula",
    "title": "Introdução ao Quarto",
    "section": "Estrutura da Aula",
    "text": "Estrutura da Aula\n\nO que é o Quarto?\nQuando e como usaremos o Quarto no RStudio\nEstrutura de um documento .qmd\nYAML e principais chaves\nTexto e formatação (Markdown)\nBlocos de código (R)\nRenderização e formatos de saída\nDicas, dúvidas e referências"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#o-que-é-o-quarto",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#o-que-é-o-quarto",
    "title": "Introdução ao Quarto",
    "section": "O que é o Quarto?",
    "text": "O que é o Quarto?\nQuarto é uma plataforma unificada para criar documentos, apresentações e sites combinando texto, código (em R, Python, Julia ou Bash) e suas saídas.\n\nSubstitui o R Markdown\nIntegra código, texto e resultados no mesmo arquivo\nPode gerar HTML, PDF, Word, slides, sites e livros\nÉ o padrão atual para comunicação científica com RStudio."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#pré-requisitos",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#pré-requisitos",
    "title": "Introdução ao Quarto",
    "section": "Pré-requisitos",
    "text": "Pré-requisitos\nAntes de começar, você precisa ter instalado:\n  \n\n\nAlternativa: use o Posit Cloud (https://posit.cloud/) para criar e renderizar documentos na nuvem."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#começando",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#começando",
    "title": "Introdução ao Quarto",
    "section": "Começando",
    "text": "Começando\nPrimeiro crie um projeto.\n\nFonte: https://rladies-sp.org/"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#começando-1",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#começando-1",
    "title": "Introdução ao Quarto",
    "section": "Começando",
    "text": "Começando\nO arquivo quarto editável tem extensão .qmd. Para renderizá-lo clique em render ou utilize o atalho do teclado CTRL + SHIFT + K.\n\nFonte: https://rladies-sp.org/"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#estrutura-de-um-arquivo-.qmd",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#estrutura-de-um-arquivo-.qmd",
    "title": "Introdução ao Quarto",
    "section": "Estrutura de um arquivo .qmd",
    "text": "Estrutura de um arquivo .qmd\nUm arquivo .qmd é dividido em três partes:\n\nCabeçalho (YAML) — define o formatação do documento, título, autor, data e outros detalhes.\nCorpo (Markdown) — texto, títulos, listas, tabelas, imagens.\nBlocos de código (Code chunks) — código executável em R, Python, Julia e outras linguagens."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#yaml-yet-another-markup-language",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#yaml-yet-another-markup-language",
    "title": "Introdução ao Quarto",
    "section": "YAML (Yet Another Markup Language)",
    "text": "YAML (Yet Another Markup Language)\nO YAML fica no início do documento e define as configurações básicas. Exemplo:\n---\ntitle: \"Relatório Anual\"\nauthor: \"Equipe de Estatística\"\ndate: today\nlang: pt\nformat: html\n---\n\nDica: Tudo entre --- e --- é parte do YAML e deve ser escrito com atenção à indentação."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#yaml-yet-another-markup-language-1",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#yaml-yet-another-markup-language-1",
    "title": "Introdução ao Quarto",
    "section": "YAML (Yet Another Markup Language)",
    "text": "YAML (Yet Another Markup Language)\nEm YAML, os elementos são chamados de pares chave-valor. Algumas chaves são:\n\ntitle: título do documento.\nauthor: nome do(a) autor(a). Pode ser mais de um(a).\ndate: Define a data do documento. Exemplos: \"13-03-2025\", today.\nlang: Define o idioma do documento. Exemplos: pt, en.\nformat: tipo de arquivo de saída.\n\nMais detalhes: quarto.org/docs/authoring/front-matter.html"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código",
    "title": "Introdução ao Quarto",
    "section": "Blocos de código",
    "text": "Blocos de código\nBlocos de código são onde você executa o R (ou outra linguagem). Começam com três crases e o nome da linguagem. Exemplo:\n```{r}\n#| echo: false\n#| eval: true\nhead(airquality)\n```"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código-1",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código-1",
    "title": "Introdução ao Quarto",
    "section": "Blocos de código",
    "text": "Blocos de código\nAlgumas das principais opções são:\n\n#| echo: controla se o código é exibido no documento.\n#| eval: determina se o código é executado e a saída apresentada.\n#| warning: controla a exibição de mensagens de aviso geradas pelo código.\n#| error: determina se os erros devem ser incluídos na saída.\n#| label: rótulo dado para fazer referência. Uma vez definido um rótulo, você pode referenciá-lo usando (@nome_do_rotulo).\n#| fig-cap: adiciona uma legenda a gráficos gerados pelo código."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código-2",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código-2",
    "title": "Introdução ao Quarto",
    "section": "Blocos de código",
    "text": "Blocos de código\n```{r}\n#| echo: false\n#| eval: true\n#| fig-align: center\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) +\n  geom_point() +\n  geom_smooth(method = \"loess\") +\n  labs(x = \"Temperatura (°F)\", y = \"Ozônio (ppb)\") +\n  theme_minimal()\n```"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#formatação-de-texto",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#formatação-de-texto",
    "title": "Introdução ao Quarto",
    "section": "Formatação de texto",
    "text": "Formatação de texto\n\n\n\nSintaxe\nSaída\n\n\n\n\n*itálico*\nitálico\n\n\n**negrito**\nnegrito\n\n\n***itálico negrito***\nitálico negrito\n\n\nsobrescrito^2^\nsobrescrito2\n\n\nsubscrito~2~\nsubscrito2\n\n\n~~riscado~~\nriscado\n\n\n`código literal`\ncódigo literal"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#seções",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#seções",
    "title": "Introdução ao Quarto",
    "section": "Seções",
    "text": "Seções\nUma seção e as subseções são definidas pela quantidade de #. O limite são seis níveis. Exemplos:\n\n\n\n\n\n\n\nSintaxe\nSaída\n\n\n\n\n# Seção 1\nSeção 1\n\n\n## Subseção 1\nSubseção 1\n\n\n### Subsubseção 1\nSubsubseção 1"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#links-e-imagens",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#links-e-imagens",
    "title": "Introdução ao Quarto",
    "section": "Links e imagens",
    "text": "Links e imagens\n\n&lt;https://quarto.org&gt; produz: https://quarto.org\n[Quarto](https://quarto.org) produz: Quarto\n\n\n\n![](quarto.jpg) produz:"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#lista-sem-ordem",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#lista-sem-ordem",
    "title": "Introdução ao Quarto",
    "section": "Lista sem ordem",
    "text": "Lista sem ordem\n\n\nSintaxe\n\n* Item\n\n    + subitem 1\n\n    + subitem 2\n\n        - subsubitem 1\n\nSaída\n\nLista sem ordem\n\nsubitem 1\nsubitem 2\n\nsubsubitem 1"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#lista-ordenada",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#lista-ordenada",
    "title": "Introdução ao Quarto",
    "section": "Lista ordenada",
    "text": "Lista ordenada\n\n\nSintaxe\n\n1. Item 1\n\n2. Item 2\n\n    i) subitem 1\n    \n         A.  subsubitem 1\n\nSaída\n\nItem 1\nItem 2\n\nsubitem 1\n\nsubsubitem 1"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#tabelas",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#tabelas",
    "title": "Introdução ao Quarto",
    "section": "Tabelas",
    "text": "Tabelas\n| Direita | Esquerda | Padrão | Centralizada |\n|--------:|:---------|--------|:------------:|\n|     12  |      12  |   12   |          12  |\n|    123  |      123 |  123   |         123  |\n|      1  |        1 |    1   |           1  |\n\nproduz:\n\n\n\n\nDireita\nEsquerda\nPadrão\nCentralizada\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#equações",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#equações",
    "title": "Introdução ao Quarto",
    "section": "Equações",
    "text": "Equações\n\nPara fórmulas e símbolos matemáticos embutidos no texto use $.\nPara fórmulas e símbolos matemáticos destacados use $$.\n\n\n\n$X \\sim N(\\mu,\\sigma^2)$ \\(~\\) produz: \\(~~ X \\sim N(\\mu,\\sigma^2)\\)\n$$ f(x) = \\frac{a}{b} e^{-x} $$ \\(~\\) produz \\[ f(x) = \\frac{a}{b} e^{-x} \\]"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#citação",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#citação",
    "title": "Introdução ao Quarto",
    "section": "Citação",
    "text": "Citação\n\nInforme o arquivo com as referências no YAML:\n\n---\ntitle: Título\nbibliography: referencias.bib\ncsl: abnt.csl\n---\n\nFormato padrão: Chicago Manual of Style com autor e data.\nVocê pode especificar uma formatação personalizada usando o CSL (Citation Style Language) nos repositórios\n\nhttps://github.com/citation-style-language/styles ou\nhttps://www.zotero.org/styles"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#citação-1",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#citação-1",
    "title": "Introdução ao Quarto",
    "section": "Citação",
    "text": "Citação\n\n@Wickham2023 \\(~\\) produz \\(~\\) (autor, ano):\n\nWICKHAM; ÇETINKAYA-RUNDEL; GROLEMUND (2023)\n\n[@Wickham2023] \\(~\\) produz \\(~\\) autor (ano):\n\n(WICKHAM; ÇETINKAYA-RUNDEL; GROLEMUND, 2023)\n\n\n\n\nO arquivo csl com a formatação da ABNT pode ser encontrada em https://www.zotero.org/styles/universidade-federal-de-sergipe-departamento-de-engenharia-de-producao-abnt"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#referências",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#referências",
    "title": "Introdução ao Quarto",
    "section": "Referências",
    "text": "Referências\n\n\n\n\nWICKHAM, H.; ÇETINKAYA-RUNDEL, M.; GROLEMUND, G. R for data science: Import, tidy, transform, visualize, and model data. 2nd. ed. Sebastopol, CA: O’Reilly, 2023."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#objetivo-da-aula",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#objetivo-da-aula",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\n\nAprender a manipular grandes bases de dados no R.\nConhecer os pacotes duckdb e DBI.\nFazer consultas usando a linguagem SQL dentro do R."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-muro-da-memória-ram",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-muro-da-memória-ram",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "O Muro da Memória RAM",
    "text": "O Muro da Memória RAM\n\nO R é, por natureza, uma ferramenta in-memory. É comum usarmos o comando: meus_dados &lt;- read.csv(\"arquivo_grande.csv\").\nProblema: O que acontece se arquivo_grande.csv tem 50 GB e seu notebook tem 16 GB de RAM?\n\nO R tenta alocar 50 GB de espaço na RAM.\nO sistema operacional tenta compensar usando swap (disco), o que torna o processo astronomicamente lento.\nNa maioria dos casos, a sessão do R simplesmente trava ou é morta pelo sistema.\n\nSolução: Em vez de trazer os dados para o R, nós lemos e processamos os dados diretamente no disco, e trazemos para a RAM apenas o resultado final (que geralmente é pequeno).\n\nIsso é chamado de processamento Out-of-Core (ou On-Disk).\nPodemos usar os pacotes duckdb e DBI para fazê-lo."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-duckdb",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-duckdb",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "O Pacote duckdb",
    "text": "O Pacote duckdb\n\nFunciona como seu assistente inteligente para dados grandes.\nImagine que seus dados são uma biblioteca gigante:\n\nMétodo tradicional: Trazer todos os livros para sua mesa (RAM).\nCom DuckDB: Pedir ao bibliotecário que consulte os livros nas estantes (disco) e traga apenas a resposta."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-duckdb-1",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-duckdb-1",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "O Pacote duckdb",
    "text": "O Pacote duckdb\n\nÉ um sistema de gerenciamento de banco de dados (SGBD) analítico, in-process e colunar. Ou seja:\n\nAnalítico (OLAP): Otimizado para consultas complexas, agregações e filtros (ex: GROUP BY, SUM, AVG).\nIn-Process: Não é um servidor (como PostgreSQL ou MySQL). Ele roda dentro da sua sessão R. Não há instalação, configuração ou gerenciamento de servidor. Apenas install.packages(\"duckdb\") e pronto.\nColunar: Esta é a chave. Bancos de dados tradicionais armazenam dados por linha. O duckdb armazena por coluna.\n\nSe sua consulta é SELECT VARIAVEL1, COUNT(*) ..., ele lê apenas a coluna VARIAVEL1 do disco, ignorando todas as outras (nome, data, etc.). Isso resulta em uma velocidade maior.\nduckdb implementa uma versão muito abrangente e moderna do padrão SQL (Structured Query Language)."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-dbi",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-dbi",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "O Pacote DBI",
    "text": "O Pacote DBI\n\nDBI (Database Interface) é um pacote que fornece uma camada de abstração universal para comunicação com bancos de dados no R.\nEle define um conjunto de funções consistentes:\n\ndbConnect(): para iniciar a conexão.\ndbGetQuery(): para enviar uma consulta e receber os dados de volta.\ndbDisconnect(): para encerrar a conexão.\n\nPor que usá-lo?\n\nConsistência: Você usa as mesmas funções DBI para falar com duckdb, RPostgres, RMariaDB, RSQLite, etc.\nPortabilidade: Seu código R não muda. Se amanhã você decidir migrar seu processo do duckdb (local) para um PostgreSQL (servidor), você só precisa alterar a linha do dbConnect()."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#como-o-sql-se-encaixa",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#como-o-sql-se-encaixa",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Como o SQL se encaixa?",
    "text": "Como o SQL se encaixa?\n\nO DBI permite que o R fale com o duckdb, e a língua que eles usam é o SQL (Structured Query Language).\nEm vez de usar comandos do pacte dplyr (como filter, group_by, summarise) que operam em data.frames na memória, nós escrevemos uma string de consulta SQL (ex: SELECT ... FROM ... WHERE ...)\nNós passamos essa string para o DBI (ex: dbGetQuery(…)).\nO DBI entrega a string ao duckdb.\nO duckdb interpreta o SQL, otimiza a consulta, executa a operação diretamente no arquivo em disco, e retorna apenas o data.frame resultante para o R."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uso",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uso",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Estrutura Geral de Uso",
    "text": "Estrutura Geral de Uso\nEste é o esquema de 5 passos para qualquer análise out-of-core com duckdb:\n\n# 1. Carregar as bibliotecas na sessão\nlibrary(DBI)\nlibrary(duckdb)\n\n# 2. Criar a conexão com o banco de dados (para salvar as consultas)\n\n# Opção A: Em memória (rápido, mas volátil)\n#con &lt;- dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\n\n# Opção B: Persistente (recomendado)\ncon &lt;- dbConnect(duckdb::duckdb(),\n                 dbdir = \"meu_banco_analitico.duckdb\")\n\n# 3. Informar ao duckdb onde estão os dados\n# Isso NÃO carrega o CSV. Apenas cria um \"ponteiro\" para ele.\nduckdb_register(con, \"meus_dados\", \"arquivo_grande.csv\")"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uso-1",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uso-1",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Estrutura Geral de Uso",
    "text": "Estrutura Geral de Uso\nEste é o esquema de 5 passos para qualquer análise out-of-core com duckdb:\n\n# 4. Fazer consultas ao banco usando SQL\nresultado &lt;- dbGetQuery(con, \"SELECT COUNT(*) FROM meus_dados\")\n\n# 5. Encerrar a conexão e liberar os recursos\ndbDisconnect(con, shutdown = TRUE)\n\n\n\nComo as cosultas usam SQL, vamos fazer uma breve explicação sobre o uso da linguagem."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uma-consulta-sql",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uma-consulta-sql",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Estrutura Geral de uma Consulta SQL",
    "text": "Estrutura Geral de uma Consulta SQL\nUma consulta SQL é como uma frase que descreve os dados que você deseja. A ordem de escrita é quase sempre esta:\n\nSELECT coluna1, FUNCAO(coluna2) AS novo_nome\nFROM nome_da_tabela\nWHERE condicao_de_filtro (ex: ano = 2023)\nGROUP BY coluna_de_agrupamento (ex: coluna1)\nORDER BY coluna_de_ordenacao (ex: novo_nome) DESC\nLIMIT 10"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-instrução-select",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-instrução-select",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "A instrução SELECT",
    "text": "A instrução SELECT\n\nEspecifica as colunas que você quer ver no resultado final.\nSempre vem acompanhada de FROM, que especifica de qual tabela os dados devem ser lidos.\n\nSintaxe:\n\nSELECT coluna1, coluna2, ...\nFROM nome_tabela\n\n\ncoluna1, coluna2, ... são as colunas das tabelas que você quer selecionar.\nnome_tabela representa o nome da tabela que contém os dados.\n\nExemplo: Suponha que temos uma tabela clientes e queremos selecionar todas as colunas.\n\nSELECT *\nFROM clientes"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-cláusula-where",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-cláusula-where",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "A cláusula WHERE",
    "text": "A cláusula WHERE\n\nSeleciona linhas que atendem a uma condição.\n\nSintaxe:\n\nSELECT coluna1, coluna2, ...\nFROM nome_tabela\nWHERE condição\n\nExemplos:\n\n\n\nSELECT *\nFROM clientes\nWHERE idade=30\n\n\n\nSELECT *\nFROM clientes\nWHERE idade&gt;24"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-cláusula-where-1",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-cláusula-where-1",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "A cláusula WHERE",
    "text": "A cláusula WHERE\nWHERE aceita alguns operadores:\n\n\n\n\n\n\n\n\n\nOperador\nDescrição\nOperador\nDescrição\n\n\n\n\n=\nIgual\n&lt;&gt; ou !=\nDiferente\n\n\n&gt;\nMaior que\n&lt;\nMenor que\n\n\n&gt;=\nMaior ou igual\n&lt;=\nMenor ou igual\n\n\nBETWEEN\nEntre um intervalo\nLIKE\nBusca por um padrão\n\n\nIN\nPara especificar múltiplos valores possíveis para uma coluna\n\n\n\n\n\nExemplo:\n\nSELECT *\nFROM clientes\nWHERE Idade BETWEEN 20 AND 30"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-instrução-group-by",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-instrução-group-by",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "A instrução GROUP BY",
    "text": "A instrução GROUP BY\n\nAgrupa linhas com mesmo valor.\nGeralmente é usada com funções de agregação (COUNT(), MAX(), MIN(), SUM(), AVG()) para agrupar os resultados de uma ou mais colunas.\nMuito usada em conjunto com ORDER BY, para ordenação dos resultados.\n\nSintaxe:\n\nSELECT nomes_das_colunas\nFROM nome_tabela\nWHERE condição\nGROUP BY nomes_das_colunas\nORDER BY nomes_das_colunas\n\nExemplo:\n\nSELECT COUNT(ID_cliente), estado\nFROM clientes\nGROUP BY estado\nORDER BY COUNT(ID_cliente) DESC"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-2",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-2",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo",
    "text": "Exemplo\nVamos usar o banco de dados sobre mortes ocorridas no Brasil em 2024 disponíveis no Sistema de Informação sobre Mortalidade (SIM), desenvolvido pelo Ministério da Saúde. Os dados estão disponíveis em: https://opendatasus.saude.gov.br/dataset/sim.\n\nVamos usar o conjunto de dados DO24OPEN.csv (óbitos ocorridos em 2024) e as variáveis:\n\nCODMUNOCOR: Código relativo ao município onde ocorreu o óbito\nCAUSABAS: Causa básica da declaração de óbito\n\nTambém vamos usar uma tabela do IBGE com os códigos e nomes dos municípios obtida em https://www.ibge.gov.br/explica/codigos-dos-municipios.php.\n\nUsaremos o arquivo RELATORIO_DTB_BRASIL_2024_MUNICIPIOS.xls."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-preparação-do-ambiente",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-preparação-do-ambiente",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo: Preparação do ambiente",
    "text": "Exemplo: Preparação do ambiente\n\n# 0. Instalando os pacotes (apenas uma vez)\n# install.packages(c(\"DBI\", \"duckdb\"))\n\n# 1. Carregando pacotes.\nlibrary(duckdb)\nlibrary(DBI)\n\n# 2. Especificando onde serão armazenadas as consultas.\n# Isso prepara o \"motor\" do duckdb para receber comandos\ncon &lt;- dbConnect(    # 'con' vai armazenar o objeto da conexão\n  duckdb::duckdb(),  # Especifica DuckDB como SGBD\n  dbdir = \":memory:\" # as consultas serão salvas na memória\n                     # e depois apagadas ao finalizar\n  #dbdir = \"sim_obitos.duckdb\" # cria uma arquivo p/ armazenar\n                               # os resultados da consulta\n)\n\n# 3. Definindo o caminho para o arquivo gigante\n# para não precisarmos escrever em toda consulta\ncaminho &lt;- \"/home/sadraque/Documentos/UFS/Disciplinas/2025.2/mineracao de dados em estatistica/slides/04-processamento_out-of-core/DO24OPEN.csv\""
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-1-contagem-total-de-linhas",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-1-contagem-total-de-linhas",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 1: Contagem total de linhas",
    "text": "Exemplo 1: Contagem total de linhas\nVamos contar quantas linhas há na tabela de dados.\n\n# Criando a consulta SQL\n# SELECT COUNT(*): \"Selecione a contagem de todas as linhas\"\n# FROM '%s' será substituído pelo caminho do arquivo\nconsult &lt;- sprintf(\"SELECT COUNT(*) AS total\n                           FROM '%s'\", caminho)\n\n# Enviando a consulta e pegando o resultado.\n# O duckdb vai ler o arquivo (sem carregá-lo) e retornar\n# apenas o resultado.\ntotal_linhas &lt;- dbGetQuery(con, consult)\ntotal_linhas\n\n    total\n1 1426346"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-2-agregando-por-município",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-2-agregando-por-município",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 2: Agregando por Município",
    "text": "Exemplo 2: Agregando por Município\nVamos contar o número de óbitos por código do município (CODMUNOCOR).\n\n# Montar a consulta SQL\nconsult &lt;- sprintf(\"SELECT CODMUNOCOR, COUNT(*) AS total_obitos\n                      FROM '%s'\n                      GROUP BY CODMUNOCOR\n                      ORDER BY total_obitos DESC\",\n                     caminho)\n\n\n# Enviar a consulta e pegar o resultado\nobitos_por_municipio &lt;- dbGetQuery(con, consult)\n\n# Ver as primeiras 4 linhas do resultado\nhead(obitos_por_municipio, n = 4L)\n\n  CODMUNOCOR total_obitos\n1     355030        89208\n2     330455        61443\n3     310620        23340\n4     261160        22146"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 3: Adicionando filtragem",
    "text": "Exemplo 3: Adicionando filtragem\nVamos consultar o número de óbitos por causas externas.\n\n# Criar a consulta SQL\n# CODMUNOCOR: Codigo do município onde ocorreu o óbito.\n# CAUSABAS: 'V01' a 'V99' são os códigos da CID-10 para\n#           acidentes de transporte.\nconsult &lt;- sprintf(\"SELECT CODMUNOCOR,\n                           COUNT(CAUSABAS) AS obitos_acidentes\n                    FROM '%s'\n                    WHERE CAUSABAS BETWEEN 'V01' AND 'V99'\n                    GROUP BY CODMUNOCOR\n                    ORDER BY obitos_acidentes DESC\",\n                   caminho)\nobitos_acidentes_mun &lt;- dbGetQuery(con, consult)\nhead(obitos_acidentes_mun, n = 4L) # primeiras 4 linhas\n\n  CODMUNOCOR obitos_acidentes\n1     130260              380\n2     520870              367\n3     261160              347\n4     355030              281"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-1",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-1",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 3: Adicionando filtragem",
    "text": "Exemplo 3: Adicionando filtragem\n\nOs códigos do SIM vêm sem os nomes dos municípios.\nPrecisamos cruzar com a tabela do IBGE para saber os nomes dos municípios.\n\n\nlibrary(tidyverse)\n\ntab_cod_ibge &lt;- readxl::read_excel(\n  \"/home/sadraque/Documentos/UFS/Disciplinas/2025.2/mineracao de dados em estatistica/slides/04-processamento_out-of-core/RELATORIO_DTB_BRASIL_2024_MUNICIPIOS.xls\",\n  skip = 6,  # Pula as 6 primeiras linhas\n  col_names = TRUE  # Usa a 7ª linha como nome das variáveis (default)\n) |&gt;\n  # Limpar nomes das colunas\n  janitor::clean_names()"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-2",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-2",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 3: Adicionando filtragem",
    "text": "Exemplo 3: Adicionando filtragem\n\ntab_cod_ibge &lt;- tab_cod_ibge |&gt;\n  # Cria código de 6 dígitos removendo o dígito verificador\n  mutate(codigo_6digitos = str_sub(codigo_municipio_completo,\n                                   1, -2)) |&gt;\n  # Converte para numérico\n  mutate(codigo_6digitos = as.numeric(codigo_6digitos)) |&gt;\n  # Seleciona e renomeia colunas finais\n  select(codigo = codigo_6digitos,\n         municipio = nome_municipio,\n         UF = nome_uf)"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-3",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-3",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 3: Adicionando filtragem",
    "text": "Exemplo 3: Adicionando filtragem\n\n# juntando o número de acidentes e os nomes dos municípios\nobitos_acidentes_nome_municipios &lt;- tab_cod_ibge |&gt;\n  left_join(obitos_acidentes_mun,\n            by = c(\"codigo\" = \"CODMUNOCOR\"))  |&gt;\n  arrange(desc(obitos_acidentes)) # ordem decrescente\nhead(obitos_acidentes_nome_municipios)\n\n# A tibble: 6 × 4\n  codigo municipio UF               obitos_acidentes\n   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                       &lt;dbl&gt;\n1 130260 Manaus    Amazonas                      380\n2 520870 Goiânia   Goiás                         367\n3 261160 Recife    Pernambuco                    347\n4 355030 São Paulo São Paulo                     281\n5 530010 Brasília  Distrito Federal              271\n6 211130 São Luís  Maranhão                      269\n\n# Encerrando a conexão\ndbDisconnect(con, shutdown = TRUE)"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exercícios",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exercícios",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exercícios",
    "text": "Exercícios\n\nFaça um histograma das idades das pessoas que vieram a óbito em 2024 em todo o país (note que primeiro você precisa fazer uma consulta na base de dados).\nFaça um gráfico de barras contando os óbitos por sexo para cada estado do país."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#conclusão-e-revisão",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#conclusão-e-revisão",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Conclusão e Revisão",
    "text": "Conclusão e Revisão\n\nProblema: A RAM é limitada; dados massivos não cabem nela.\nSolução: Processamento Out-of-Core (On-Disk).\nFerramentas:\n\nduckdb: Motor que faz o trabalho pesado no disco.\nDBI: Interface que o R usa para se comunicar.\nSQL: A linguagem que usamos para descrever o que queremos.\n\nFluxo: dbConnect -&gt; duckdb_register -&gt; dbGetQuery (com SQL) -&gt; dbDisconnect.\nVerbos SQL:\n\n\n\n\nSELECT (o quê)\nFROM (de onde)\nWHERE (filtro de linha)\n\n\n\nGROUP BY (agregar)\nORDER BY (ordenar)"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#section",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#section",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "",
    "text": "Mais sobre a estrutura de SQL você pode encontrar em https://www.w3schools.com/sql/."
  },
  {
    "objectID": "aulas/07-regras_de_associacao.html",
    "href": "aulas/07-regras_de_associacao.html",
    "title": "Conteúdo 7",
    "section": "",
    "text": "Esta aula detalha o método das Regras de Associação, uma técnica essencial da Mineração de Dados focada na Análise de Cesta de Mercado para descobrir quais produtos os clientes tendem a comprar em conjunto. O material explica as três métricas cruciais — Suporte (frequência), Confiança (precisão condicional) e Lift (interesse real) — que são usadas para filtrar padrões acionáveis em meio a um vasto número de combinações. Além disso, a apresentação diferencia os principais algoritmos de busca por padrões frequentes, o clássico Apriori e o mais eficiente FP-Growth, preparando o leitor para aplicar esses conhecimentos na otimização de leiautes de lojas, campanhas de marketing e gestão de inventário.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 2: Métodos Não Supervisionados",
      "7- Regras de Associação"
    ]
  },
  {
    "objectID": "aulas/07-regras_de_associacao.html#regras-de-associação",
    "href": "aulas/07-regras_de_associacao.html#regras-de-associação",
    "title": "Conteúdo 7",
    "section": "",
    "text": "Esta aula detalha o método das Regras de Associação, uma técnica essencial da Mineração de Dados focada na Análise de Cesta de Mercado para descobrir quais produtos os clientes tendem a comprar em conjunto. O material explica as três métricas cruciais — Suporte (frequência), Confiança (precisão condicional) e Lift (interesse real) — que são usadas para filtrar padrões acionáveis em meio a um vasto número de combinações. Além disso, a apresentação diferencia os principais algoritmos de busca por padrões frequentes, o clássico Apriori e o mais eficiente FP-Growth, preparando o leitor para aplicar esses conhecimentos na otimização de leiautes de lojas, campanhas de marketing e gestão de inventário.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 2: Métodos Não Supervisionados",
      "7- Regras de Associação"
    ]
  },
  {
    "objectID": "aulas/07-regras_de_associacao.html#aplicações",
    "href": "aulas/07-regras_de_associacao.html#aplicações",
    "title": "Conteúdo 7",
    "section": "Aplicações",
    "text": "Aplicações\nOs arquivos contendo os códigos em R e os dados podem ser baixados aqui.",
    "crumbs": [
      "Aulas",
      "Parte 2: Métodos Não Supervisionados",
      "7- Regras de Associação"
    ]
  },
  {
    "objectID": "aulas/07-regras_de_associacao.html#projeto-4-regras-de-associação-no-sim",
    "href": "aulas/07-regras_de_associacao.html#projeto-4-regras-de-associação-no-sim",
    "title": "Conteúdo 7",
    "section": "Projeto 4 – Regras de Associação no SIM",
    "text": "Projeto 4 – Regras de Associação no SIM\nVocê é um(a) Analista de Mineração de Dados em Saúde Pública. O time de Vigilância Epidemiológica solicitou a identificação de padrões de coocorrência de risco na mortalidade, usando o Sistema de Informações sobre Mortalidade (SIM). Você deve aplicar o algoritmo Apriori sobre os dados de mortes ocorridas no Brasil em 2024 disponíveis em https://opendatasus.saude.gov.br/dataset/sim. O projeto é INDIVIDUAL.\nPrazo: Próxima aula.\nTarefa: Acesse https://opendatasus.saude.gov.br/dataset/sim. Baixe os dados de 2024 e escolha 1 (um) Estado (UF) para sua análise. Em seguida, escolha 1 (um) dos nove projetos listados abaixo, que já define o foco da sua análise. O objetivo é aplicar o Apriori para gerar regras de associação válidas, interpretáveis e com implicações para a saúde pública.\n\nMini Projetos para escolher\nP1. Associação de Múltiplas Causas (Linha A-D) e Perfil de Vulnerabilidade em Óbitos por Insuficiência Cardíaca\n\nProblema: Quais comorbidades e características sociodemográficas frequentemente coocorrem e precedem o óbito por Insuficiência Cardíaca (I50) em um estado brasileiro?\nVariáveis: Códigos da LINHAA a LINHAD (múltiplas causas), IDADE (em faixas), ESC2010, ASSISTMED, LOCOCOR.\nApriori: Gerar regras buscando Confiança, Suporte e Lift superiores a 1.\nAnálise: Interpretar regras que tenham códigos de DCNT como antecedentes e a Insuficiência Cardíaca como consequente.\n\nP2. Associação entre Local de Ocorrência, Assistência e Causas Básicas Sensíveis à Atenção Primária\n\nProblema: Quais combinações de fatores (local de óbito não-hospitalar e falta de assistência) estão mais fortemente associadas a óbitos por Causas Sensíveis à Atenção Primária (CSAP), indicando lacunas no cuidado básico?\nVariáveis: CAUSABAS (agrupada por CSAP), LOCOCOR (Domicílio, Outros), ASSISTMED (Não/Sim), IDADE (faixas).\nApriori: Busca por regras que tenham uma combinação de LOCOCOR (não hospitalar) e ASSISTMED (não) no antecedente, e a CSAP no consequente.\nAvaliação: Análise das regras com alto Lift, que indicam que a coocorrência de desassistência e óbito por CSAP é muito maior que o esperado.\n\nP3. Regras de Associação entre Perfil Ocupacional, Escolaridade e Óbitos por Causas Externas\n\nProblema: Quais são as combinações mais fortes entre a ocupação (OCUP), o nível de escolaridade (ESC2010) e a ocorrência de óbitos por tipos específicos de Causas Externas (V01-Y98), como acidentes de trabalho?\nVariáveis: OCUP (agrupada), ESC2010, ACIDTRAB (Sim/Não), CAUSABAS (agrupada por tipo de violência/acidente).\nApriori: Focar em regras com alto Lift onde a OCUP e a ESC2010 são antecedentes.\n\nP4. Associação entre Raça/Cor, Escolaridade e Mortalidade Materna Evitável\n\nProblema: Que combinações de fatores de vulnerabilidade (RACACOR e ESCMAEAGR1) estão fortemente associadas a óbitos de mulheres em idade fértil (10-49 anos) por causas relacionadas à gestação, parto ou puerpério (CAUSAMAT)?\nVariáveis: CAUSAMAT (agrupada), RACACOR, ESCMAEAGR1 (escolaridade da mãe), ASSISTMED.Ajustar o Suporte e a Confiança para eventos raros.\nApriori: Focar em regras com RACACOR no antecedente e a causa materna como consequente.\nAnálise: Comparar a Confiança de regras para diferentes grupos de RACACOR.\n\nP5. Associação de Óbitos por Doenças Respiratórias (J00-J99) com Fatores Ambientais e Sazonais\n\nProblema: Quais combinações de características sociodemográficas e de evento (idade, sexo, LOCOCOR) mais se associam a óbitos por doenças respiratórias (CAUSABAS J00-J99) nos meses de maior incidência (inverno/chuvosos)?\nVariáveis: CAUSABAS (agrupada: Pneumonia, Asma, DPOC), IDADE (faixas), SEXO, LOCOCOR, MÊS DO ÓBITO (criada a partir de DTOBITO).\nApriori: Executar com foco em regras que incluam a variável sazonal (Mês) no antecedente.\nAvaliação: Filtrar as regras com o maior Lift nos meses de pico (ex: Junho, Julho).\n\nP6. Associação de Acidentes de Trânsito (V01-V89) com Idade, Sexo e Tipo de Veículo/Vítima\n\nProblema: Quais são os padrões de vítimas (idade, sexo, tipo de óbito) mais frequentemente associados a acidentes de trânsito em um determinado estado?\nVariáveis: IDADE (faixas), SEXO, CAUSABAS (agrupada por tipo de vítima: Pedestre, Ciclista, Motociclista, Ocupante de Carro).\nApriori: Busca por regras que tenham um dos tipos de vítima como consequente.\nRelatório: Focar no Lift para destacar os grupos de risco que mais se sobressaem em relação à distribuição esperada.\n\nP7. Associações entre Nível de Escolaridade e Óbitos por Condições Crônicas Específicas (Diabetes Mellitus)\n\nProblema: Que regras de associação mostram a relação entre a falta de escolaridade e o óbito por complicações do Diabetes (E10-E14), comparado a outros fatores de risco?\nVariáveis: ESC2010, RACACOR, IDADE (faixas), LINHAC (complicações associadas, ex: Insuficiência Renal).\nApriori: Focar em regras onde a ESC2010 ou RACACOR são o antecedente e a complicação (Linha A-D) ou a causa básica (Diabetes) é o consequente.\n\nP8. Associação de Câncer (C00-C97) com Fatores Sociodemográficos e Local de Ocorrência\n\nProblema: Que combinações de fatores (tipo de câncer, idade, escolaridade, local de óbito) estão fortemente associadas em óbitos por câncer em um estado?\nVariáveis: CAUSABAS (agrupada por tipo de câncer - Mama, Próstata, Pulmão), IDADE (faixas), ESC2010, LOCOCOR (Hospital, Domicílio).\nApriori: Focar em regras onde o LOCOCOR é o antecedente/consequente.\n\nP9. Associação de Óbitos de Populações Indígenas/Ignoradas com Fatores de Evento (Associação Mínima)\n\nProblema: Quais são os padrões mínimos de óbito (causa, local, assistência) associados à classificação de RACACOR=Indígena ou RACACOR=Ignorada, sinalizando desafios específicos de saúde e registro?\nVariáveis: RACACOR (Indígena/Ignorada), CAUSABAS (agrupada), LOCOCOR, ASSISTMED, ATESTANTE (Agrupada: Médico, IML, Policial).\nApriori: Definir um Suporte muito baixo devido à raridade da população indígena e o foco nas variáveis de registro.\nAvaliação: Analisar o Lift para encontrar associações surpreendentes.\n\n\n\nEntrega: Relatório de Mineração de Regras\nVocê deverá produzir um Relatório Executivo no formato PDF, gerado através de um documento Quarto (.qmd). Este relatório é destinado aos gestores da saúde pública do estado escolhido e deve priorizar a comunicação clara dos insights descobertos.\nO relatório deve seguir a seguinte estrutura formal, com os códigos e saídas do R movidos para o final, na seção de Anexos. Ele deve conter:\n\nContextualização e Objetivo\n\nEsta seção deve apresentar:\n\nO projeto escolhido.\nMencionar o Estado foco da análise.\nApresentar a relevância da mineração de regras de associação para o problema específico da UF. Explicar, em termos gerenciais, por que o método Apriori é a ferramenta ideal para descobrir combinações inesperadas de fatores que levam ao óbito neste contexto (extraído da seção ‘Por Que Faz Sentido’ do projeto).\n\n\nPrincipais Padrões de Risco Descobertos\n\nEsta seção é o cerne do relatório e deve apresentar os achados mais importantes da mineração.\n\nRegras de Alto Impacto:\n\nApresentação clara das 5 (cinco) regras de associação com o MAIOR LIFT encontradas. Cada regra deve ser listada em linguagem de gestor (evitando notação formal \\(\\{X, Y\\} \\implies \\{Z\\}\\) inicialmente, e usando-a apenas no Anexo)\nExemplo: Em vez de \\(\\{\\text{ESC2010=0, IDADE (80+)}\\} \\implies \\{\\text{LOCOCOR=Domicílio}\\}\\), use: “Indivíduos com mais de 80 anos e sem escolaridade apresentam uma alta associação com óbitos ocorridos em domicílio.”\n\nInterpretação Gerencial:\n\nUma interpretação descritiva e aprofundada das três regras mais fortes (maior Lift). Focar no significado da Confiança (qual a probabilidade de o consequente ocorrer dado o antecedente) e do Lift (o quão incomum ou forte é essa associação).\n\n\n\nImplicações para a Vigilância e Ação Social\n\n\nRelevância para a Vigilância Epidemiológica:\n\nUma breve discussão sobre o impacto social e de saúde pública da regra mais significativa. Como este padrão descoberto pode informar ou modificar uma política de intervenção (ex: campanhas de saúde direcionadas, alocação de recursos, treinamento de equipes básicas).\n\n\n\nAnexos Metodológicos e Detalhes Técnicos\n\nEsta seção deve conter todos os elementos técnicos para garantir a reprodutibilidade científica do estudo, sem poluir a leitura do gestor.\n\nAnexo A\n\nA saída da função summary() aplicada ao objeto de regras resultante no R (para mostrar o número total de regras geradas e a distribuição de Suporte, Confiança e Lift).\n\nAnexo B\n\nScript R completo e comentado utilizado no projeto.\nO código deve incluir a leitura dos dados, o filtro por UF, o pré-processamento/discretização das variáveis-chave e a criação do objeto transactions (arules).\nA especificação clara dos parâmetros Suporte Mínimo e Confiança Mínima utilizados no Apriori.\nO código utilizado para a apresentação das regras com o MAIOR LIFT.\n\n\nO envio final deve ser realizado pelo SIGAA.",
    "crumbs": [
      "Aulas",
      "Parte 2: Métodos Não Supervisionados",
      "7- Regras de Associação"
    ]
  },
  {
    "objectID": "aulas/09-regressao_logistica.html",
    "href": "aulas/09-regressao_logistica.html",
    "title": "Conteúdo 9",
    "section": "",
    "text": "Neste material, realizamos a transição fundamental da regressão linear para a classificação probabilística. Você aprenderá a modelar eventos binários utilizando a Regressão Logística, dominando desde a matemática da função sigmoide e a interpretação do Odds Ratio até as métricas cruciais de validação em Mineração de Dados, como a Matriz de Confusão e a Curva ROC/AUC. Essencial para quem busca construir modelos preditivos de risco, fraude e diagnóstico.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 3: Métodos Supervisionados",
      "9- Regressão Logística"
    ]
  },
  {
    "objectID": "aulas/09-regressao_logistica.html#regressão-logística",
    "href": "aulas/09-regressao_logistica.html#regressão-logística",
    "title": "Conteúdo 9",
    "section": "",
    "text": "Neste material, realizamos a transição fundamental da regressão linear para a classificação probabilística. Você aprenderá a modelar eventos binários utilizando a Regressão Logística, dominando desde a matemática da função sigmoide e a interpretação do Odds Ratio até as métricas cruciais de validação em Mineração de Dados, como a Matriz de Confusão e a Curva ROC/AUC. Essencial para quem busca construir modelos preditivos de risco, fraude e diagnóstico.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 3: Métodos Supervisionados",
      "9- Regressão Logística"
    ]
  },
  {
    "objectID": "aulas/09-regressao_logistica.html#aplicações",
    "href": "aulas/09-regressao_logistica.html#aplicações",
    "title": "Conteúdo 9",
    "section": "Aplicações",
    "text": "Aplicações\nOs arquivos contendo exemplos com códigos em R e os dados podem ser baixados aqui.",
    "crumbs": [
      "Aulas",
      "Parte 3: Métodos Supervisionados",
      "9- Regressão Logística"
    ]
  },
  {
    "objectID": "aulas/10-knn.html",
    "href": "aulas/10-knn.html",
    "title": "Conteúdo 10",
    "section": "",
    "text": "Neste material de aula, abordamos o algoritmo k-Nearest Neighbors (k-NN), explorando tanto sua aplicação em classificação quanto em regressão. Os slides detalham a intuição por trás do método baseado em instâncias (lazy learning), a importância crítica do pré-processamento de dados (normalização e tratamento de variáveis categóricas) e o cálculo de distâncias. Além disso, discute-se o impacto da escolha do hiperparâmetro \\(k\\) no equilíbrio entre viés e variância.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 3: Métodos Supervisionados",
      "10- $k$-Nearest Neighbors"
    ]
  },
  {
    "objectID": "aulas/10-knn.html#k-nearest-neighbors",
    "href": "aulas/10-knn.html#k-nearest-neighbors",
    "title": "Conteúdo 10",
    "section": "",
    "text": "Neste material de aula, abordamos o algoritmo k-Nearest Neighbors (k-NN), explorando tanto sua aplicação em classificação quanto em regressão. Os slides detalham a intuição por trás do método baseado em instâncias (lazy learning), a importância crítica do pré-processamento de dados (normalização e tratamento de variáveis categóricas) e o cálculo de distâncias. Além disso, discute-se o impacto da escolha do hiperparâmetro \\(k\\) no equilíbrio entre viés e variância.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 3: Métodos Supervisionados",
      "10- $k$-Nearest Neighbors"
    ]
  },
  {
    "objectID": "aulas/10-knn.html#aplicações",
    "href": "aulas/10-knn.html#aplicações",
    "title": "Conteúdo 10",
    "section": "Aplicações",
    "text": "Aplicações\nOs arquivos contendo um exemplo com códigos em R e os dados podem ser baixados aqui.",
    "crumbs": [
      "Aulas",
      "Parte 3: Métodos Supervisionados",
      "10- $k$-Nearest Neighbors"
    ]
  },
  {
    "objectID": "aulas/04-processamento_out-of-core.html",
    "href": "aulas/04-processamento_out-of-core.html",
    "title": "Conteúdo 4",
    "section": "",
    "text": "Nesta aula, enfrentamos o desafio de analisar dados que excedem a memória RAM do computador, introduzindo o paradigma de processamento Out-of-Core no R. Exploramos a arquitetura dessa solução, compreendendo o papel do pacote duckdb como o motor analítico in-process e do pacote DBI como a interface de conexão universal. Aprendemos a estrutura fundamental da linguagem SQL para realizar consultas diretamente no disco, focando nos comandos SELECT, FROM, WHERE, GROUP BY e ORDER BY. A aula demonstra, com exemplos práticos usando dados do DATASUS, como agregar e filtrar milhões de registros instantaneamente, trazendo para o R apenas o resultado consolidado. Este é um passo essencial para escalar análises, garantir a performance em datasets massivos e superar as limitações do processamento in-memory tradicional.\nDados que iremos usar:\n\nMortes ocorridas no Brasil em 2024 disponíveis no Sistema de Informação sobre Mortalidade (SIM): https://opendatasus.saude.gov.br/dataset/sim\nTabela de Códigos de Municípios do IBGE: https://www.ibge.gov.br/explica/codigos-dos-municipios.php\n\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "4- Processamento *Out-of-Core*"
    ]
  },
  {
    "objectID": "aulas/04-processamento_out-of-core.html#processamento-out-of-core-com-duckdb-e-dbi-no-r",
    "href": "aulas/04-processamento_out-of-core.html#processamento-out-of-core-com-duckdb-e-dbi-no-r",
    "title": "Conteúdo 4",
    "section": "",
    "text": "Nesta aula, enfrentamos o desafio de analisar dados que excedem a memória RAM do computador, introduzindo o paradigma de processamento Out-of-Core no R. Exploramos a arquitetura dessa solução, compreendendo o papel do pacote duckdb como o motor analítico in-process e do pacote DBI como a interface de conexão universal. Aprendemos a estrutura fundamental da linguagem SQL para realizar consultas diretamente no disco, focando nos comandos SELECT, FROM, WHERE, GROUP BY e ORDER BY. A aula demonstra, com exemplos práticos usando dados do DATASUS, como agregar e filtrar milhões de registros instantaneamente, trazendo para o R apenas o resultado consolidado. Este é um passo essencial para escalar análises, garantir a performance em datasets massivos e superar as limitações do processamento in-memory tradicional.\nDados que iremos usar:\n\nMortes ocorridas no Brasil em 2024 disponíveis no Sistema de Informação sobre Mortalidade (SIM): https://opendatasus.saude.gov.br/dataset/sim\nTabela de Códigos de Municípios do IBGE: https://www.ibge.gov.br/explica/codigos-dos-municipios.php\n\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "4- Processamento *Out-of-Core*"
    ]
  },
  {
    "objectID": "aulas/04-processamento_out-of-core.html#projeto-1-preparação-de-datasets-para-análise-de-risco",
    "href": "aulas/04-processamento_out-of-core.html#projeto-1-preparação-de-datasets-para-análise-de-risco",
    "title": "Conteúdo 4",
    "section": "Projeto 1 – Preparação de Datasets para Análise de Risco",
    "text": "Projeto 1 – Preparação de Datasets para Análise de Risco\nVocê é um(a) Engenheiro(a) de Dados. O time de Cientistas de Dados solicitou um dataset filtrado do SCR.data. Vocês devem usar duckdb para consultar arquivos CSV brutos, fazer a filtragem necessária usando SQL, e entregar um dataframe leve no R. O projeto é INDIVIDUAL.\nPrazo: Próxima aula.\nTarefa: Acesse https://dadosabertos.bcb.gov.br/dataset/scr_data, baixe os dados de 2025 e selecione o conjunto de dados (arquivo CSV) do mês mais recente disponível.\nEm seguida, escolha 1 Estado (UF) e 1 das duas opções de projeto abaixo.\nO objetivo de ambas as opções é escrever uma consulta SQL que leia o CSV e filtre os dados. A consulta deve usar WHERE para selecionar apenas as linhas que correspondam à UF escolhida E ao tipo de cliente ('PF' ou 'PJ').\nOpção 1: Extração de Micro-Segmentos de Risco (Pessoa Física)\n\nObjetivo: Preparar o dataset de clientes Pessoa Física (PF) para uma futura análise de risco e segmentação.\nFiltro Requerido: cliente = 'PF' (além da UF escolhida).\n\nOpção 2: Extração de Risco Setorial (Pessoa Jurídica)\n\nObjetivo: Preparar o dataset de clientes Pessoa Jurídica (PJ) para uma futura análise de risco dos diferentes setores da economia (CNAE).\nFiltro Requerido: cliente = 'PJ' (além da UF escolhida).\n\nEntrega: Produza um relatório em pdf gerado em Quarto que contenha:\n\nQual das 2 opções foi escolhida e qual a UF (Estado) selecionada.\nO script R completo e comentado no documento Quarto. Nesta tarefa, o código SQL dentro do R é a parte principal do trabalho.\nA saída da consulta no R. Você deve usar as funções glimpse() e summary() no dataframe resultante para provar que os filtros foram aplicados corretamente.\nO envio deve ser realizado pelo SIGAA.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "4- Processamento *Out-of-Core*"
    ]
  },
  {
    "objectID": "aulas/05-pre-processamento_de_dados.html",
    "href": "aulas/05-pre-processamento_de_dados.html",
    "title": "Conteúdo 5",
    "section": "",
    "text": "O pilar fundamental de qualquer modelo de mineração é a qualidade dos seus dados, reconhecendo o princípio de que entradas de baixa qualidade geram resultados de baixa qualidade (Garbage In, Garbage Out). Esta aula explora os desafios comuns encontrados em dados brutos — como ruído, inconsistências, dados faltantes e heterogeneidade — e introduz o pipeline de pré-processamento como um fluxo de trabalho estruturado para diagnosticar e remediar esses problemas. O processo se inicia pela base, com a classificação correta dos tipos de atributos (nominais, ordinais, intervalares e racionais) para definir as operações válidas. A partir daí, o pipeline detalha as etapas essenciais de tratamento de inconsistências (padronização e validação), estratégias para valores ausentes (da remoção simples à imputação preditiva), suavização de ruído (usando técnicas como binning), superação dos desafios da integração de dados (conflitos, redundância e identificação de entidades), aplicação de métodos de transformação (normalização Z-score, Min-Max, dummy coding) e o uso de técnicas de redução de dados (como PCA e seleção de atributos). Dominar este pipeline é um passo indispensável para garantir que os algoritmos de machine learning operem com máxima eficiência e que os resultados da análise sejam confiáveis, precisos e robustos.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "5- Pré-Processamento de Dados"
    ]
  },
  {
    "objectID": "aulas/05-pre-processamento_de_dados.html#pré-processamento-de-dados",
    "href": "aulas/05-pre-processamento_de_dados.html#pré-processamento-de-dados",
    "title": "Conteúdo 5",
    "section": "",
    "text": "O pilar fundamental de qualquer modelo de mineração é a qualidade dos seus dados, reconhecendo o princípio de que entradas de baixa qualidade geram resultados de baixa qualidade (Garbage In, Garbage Out). Esta aula explora os desafios comuns encontrados em dados brutos — como ruído, inconsistências, dados faltantes e heterogeneidade — e introduz o pipeline de pré-processamento como um fluxo de trabalho estruturado para diagnosticar e remediar esses problemas. O processo se inicia pela base, com a classificação correta dos tipos de atributos (nominais, ordinais, intervalares e racionais) para definir as operações válidas. A partir daí, o pipeline detalha as etapas essenciais de tratamento de inconsistências (padronização e validação), estratégias para valores ausentes (da remoção simples à imputação preditiva), suavização de ruído (usando técnicas como binning), superação dos desafios da integração de dados (conflitos, redundância e identificação de entidades), aplicação de métodos de transformação (normalização Z-score, Min-Max, dummy coding) e o uso de técnicas de redução de dados (como PCA e seleção de atributos). Dominar este pipeline é um passo indispensável para garantir que os algoritmos de machine learning operem com máxima eficiência e que os resultados da análise sejam confiáveis, precisos e robustos.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "5- Pré-Processamento de Dados"
    ]
  },
  {
    "objectID": "aulas/05-pre-processamento_de_dados.html#aplicações",
    "href": "aulas/05-pre-processamento_de_dados.html#aplicações",
    "title": "Conteúdo 5",
    "section": "Aplicações",
    "text": "Aplicações\nExemplo 1: Como exemplo de aplicação iremos usar os mesmos dados da aula anterior, em que usamos dados do Sistema de Informação sobre Mortalidade (SIM) e do IBGE. O código R pode ser baixado aqui. Os dados estão disponíveis em:\n\nMortes ocorridas no Brasil em 2024 disponíveis no Sistema de Informação sobre Mortalidade (SIM): https://opendatasus.saude.gov.br/dataset/sim\nEstimativas de população residente por município de 2024: http://sidra.ibge.gov.br/tabela/6579\n\nExemplo 2: Também temos outro código em R para outro pr-é-processamento de dados. O arquivo com o código R e os dados podem ser baixados aqui.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "5- Pré-Processamento de Dados"
    ]
  },
  {
    "objectID": "aulas/05-pre-processamento_de_dados.html#projeto-2-pré-processamento-de-dados-para-modelagem-de-risco",
    "href": "aulas/05-pre-processamento_de_dados.html#projeto-2-pré-processamento-de-dados-para-modelagem-de-risco",
    "title": "Conteúdo 5",
    "section": "Projeto 2 – Pré-Processamento de Dados para Modelagem de Risco",
    "text": "Projeto 2 – Pré-Processamento de Dados para Modelagem de Risco\nVocê agora atua como Cientista de Dados Júnior no mesmo time do Projeto 1. Seu trabalho começa onde o Projeto 1 terminou: com o dataframe filtrado do SCR.data.\nO objetivo desta etapa é limpar, padronizar, transformar os dados para prepará-los para modelagem estatística ou machine learning. O projeto é INDIVIDUAL.\nPrazo: Próxima aula.\nTarefa: Você deve reutilizar exatamente o dataframe final obtido no Projeto 1 (com PF ou PJ e UF filtrados). Caso tenha cometido algum erro no Projeto 1, você pode corrigi-lo agora – mas deve declarar isso no relatório. O foco agora é limpeza e preparação, não precisa colocar o que já foi feito no Projeto 1.\nFaça o pré-processamento dos dados que você organizou no Projeto 1. O dataframe resultante deve passar por no mínimo uma dessas etapas de pré-processamento, sendo obrigatória a etapa de Normalização:\n\nTratamento de valores ausentes usando imputação ou remoção\nCriação de variáveis derivadas log-transform, dummies, faixas etárias, grupos de risco, etc.\nDetecção de outliers, não precisa removê-los\nPadronização de nomes/renomeação de colunas se necessário\nChecagem de qualidade porcentagem de NAs por coluna\nNormalização/padronização z-score (obrigatório)\n\nEntrega: Produza um relatório em pdf gerado em Quarto que contenha:\n\nO script R completo e comentado no documento Quarto.\nAs saídas do R.\nDocumentação do dicionário de variáveis da tabela obtida (dataframe) com nome, tipo de variável e descrição.\nO envio deve ser realizado pelo SIGAA.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "5- Pré-Processamento de Dados"
    ]
  },
  {
    "objectID": "aulas/08-regressao_linear.html",
    "href": "aulas/08-regressao_linear.html",
    "title": "Conteúdo 8",
    "section": "",
    "text": "Nesta aula, entramos no universo da Aprendizagem Supervisionada explorando a Regressão Linear sob duas óticas fundamentais: a Inferência, focada em explicar relações estatísticas e significância de variáveis, e a Predição, voltada para a capacidade de generalização do modelo em dados inéditos.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 3: Métodos Supervisionados",
      "8- Regressão Linear"
    ]
  },
  {
    "objectID": "aulas/08-regressao_linear.html#regressão-linear",
    "href": "aulas/08-regressao_linear.html#regressão-linear",
    "title": "Conteúdo 8",
    "section": "",
    "text": "Nesta aula, entramos no universo da Aprendizagem Supervisionada explorando a Regressão Linear sob duas óticas fundamentais: a Inferência, focada em explicar relações estatísticas e significância de variáveis, e a Predição, voltada para a capacidade de generalização do modelo em dados inéditos.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 3: Métodos Supervisionados",
      "8- Regressão Linear"
    ]
  },
  {
    "objectID": "aulas/08-regressao_linear.html#aplicações",
    "href": "aulas/08-regressao_linear.html#aplicações",
    "title": "Conteúdo 8",
    "section": "Aplicações",
    "text": "Aplicações\nOs arquivos contendo exemplos com códigos em R e os dados podem ser baixados aqui.",
    "crumbs": [
      "Aulas",
      "Parte 3: Métodos Supervisionados",
      "8- Regressão Linear"
    ]
  },
  {
    "objectID": "aulas/01-Apresentacao_da_disciplina.html",
    "href": "aulas/01-Apresentacao_da_disciplina.html",
    "title": "Conteúdo 1",
    "section": "",
    "text": "Sejam bem-vindos(as) à disciplina Mineração de Dados em Estatística!\nNesta primeira aula, abrimos oficialmente nossa jornada pelo fascinante universo da descoberta de conhecimento em bases de dados. Apresentamos os objetivos da disciplina, o formato das avaliações, os canais de comunicação e o portfólio de projetos que guiará nosso semestre. Em seguida, mergulhamos nos fundamentos da mineração de dados, explorando o processo KDD (Knowledge Discovery in Databases), a hierarquia entre dados, informação e conhecimento, e a conexão entre Estatística, Aprendizado de Máquina e Inteligência Artificial. Essa introdução marca o início de uma trilha que combina teoria, prática e análise crítica para transformar dados em decisões inteligentes.\nSlides:\n\n\n Versão html \n\n\n Versão pdf \n\n\nVídeo da aula:",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "1- Apresentação da Disciplina"
    ]
  },
  {
    "objectID": "aulas/01-Apresentacao_da_disciplina.html#apresentação-da-disciplina-e-introdução-à-mineração-de-dados",
    "href": "aulas/01-Apresentacao_da_disciplina.html#apresentação-da-disciplina-e-introdução-à-mineração-de-dados",
    "title": "Conteúdo 1",
    "section": "",
    "text": "Sejam bem-vindos(as) à disciplina Mineração de Dados em Estatística!\nNesta primeira aula, abrimos oficialmente nossa jornada pelo fascinante universo da descoberta de conhecimento em bases de dados. Apresentamos os objetivos da disciplina, o formato das avaliações, os canais de comunicação e o portfólio de projetos que guiará nosso semestre. Em seguida, mergulhamos nos fundamentos da mineração de dados, explorando o processo KDD (Knowledge Discovery in Databases), a hierarquia entre dados, informação e conhecimento, e a conexão entre Estatística, Aprendizado de Máquina e Inteligência Artificial. Essa introdução marca o início de uma trilha que combina teoria, prática e análise crítica para transformar dados em decisões inteligentes.\nSlides:\n\n\n Versão html \n\n\n Versão pdf \n\n\nVídeo da aula:",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "1- Apresentação da Disciplina"
    ]
  },
  {
    "objectID": "aulas/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html",
    "href": "aulas/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html",
    "title": "Conteúdo 6",
    "section": "",
    "text": "Esta aula oferece um guia prático sobre algoritmos de clusterização particionada, com foco em como selecionar o método correto com base na natureza dos seus dados. Partindo do clássico K-Means para dados numéricos, exploramos suas limitações (como a sensibilidade a outliers) e introduz alternativas robustas como o K-Medians e o K-Medoids (PAM). A lógica é então expandida para lidar com dados puramente categóricos, através do K-Modes e da Distância de Hamming, e para dados mistos complexos, onde compara as abordagens do K-Prototypes e a flexível combinação da Distância de Gower com K-Medoids. Abordamos também a questão essencial de como determinar o número ideal de clusters (k) utilizando técnicas de validação populares, como o Método do Cotovelo (WCSS), a Silhueta Média e a Estatística Gap.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 2: Métodos Não Supervisionados",
      "6- Agrupamento com K-Means e Métodos Relacionados"
    ]
  },
  {
    "objectID": "aulas/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#agrupamento-com-k-means-e-métodos-relacionados",
    "href": "aulas/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#agrupamento-com-k-means-e-métodos-relacionados",
    "title": "Conteúdo 6",
    "section": "",
    "text": "Esta aula oferece um guia prático sobre algoritmos de clusterização particionada, com foco em como selecionar o método correto com base na natureza dos seus dados. Partindo do clássico K-Means para dados numéricos, exploramos suas limitações (como a sensibilidade a outliers) e introduz alternativas robustas como o K-Medians e o K-Medoids (PAM). A lógica é então expandida para lidar com dados puramente categóricos, através do K-Modes e da Distância de Hamming, e para dados mistos complexos, onde compara as abordagens do K-Prototypes e a flexível combinação da Distância de Gower com K-Medoids. Abordamos também a questão essencial de como determinar o número ideal de clusters (k) utilizando técnicas de validação populares, como o Método do Cotovelo (WCSS), a Silhueta Média e a Estatística Gap.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 2: Métodos Não Supervisionados",
      "6- Agrupamento com K-Means e Métodos Relacionados"
    ]
  },
  {
    "objectID": "aulas/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#aplicações",
    "href": "aulas/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#aplicações",
    "title": "Conteúdo 6",
    "section": "Aplicações",
    "text": "Aplicações\nA aplicaçãos dos métodos no R usam diferentes bases de dados. Os arquivos contendo os códigos e os dados podem ser baixados aqui.",
    "crumbs": [
      "Aulas",
      "Parte 2: Métodos Não Supervisionados",
      "6- Agrupamento com K-Means e Métodos Relacionados"
    ]
  },
  {
    "objectID": "aulas/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#projeto-3-segmentação-de-clientes-e-análise-de-risco",
    "href": "aulas/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#projeto-3-segmentação-de-clientes-e-análise-de-risco",
    "title": "Conteúdo 6",
    "section": "Projeto 3 – Segmentação de Clientes e Análise de Risco",
    "text": "Projeto 3 – Segmentação de Clientes e Análise de Risco\nVocê continua atuando como Cientista de Dados Júnior. No Projeto 2, você finalizou a etapa de pré-processamento dos dados do SCR, resultando em um dataframe limpo, transformado e com as variáveis numéricas padronizadas (z-score).\nAgora queremos que você realize a próxima fase: a segmentação não supervisionada desses clientes.\nProblema de Negócio (A Solicitação do “Banco”): Não podemos tratar todos os clientes de crédito da mesma forma. Precisamos que você use técnicas de data science para “descobrir” os grupos (clusters) naturais que existem em no portfólio que você está usando. Queremos saber:\n\nQuantos perfis de clientes realmente temos?\nQuais são as características que definem cada perfil? (Ex: ‘Jovens de alto risco’, ‘Empresas estáveis de baixa alavancagem’, ‘Clientes em dia, mas com crédito imobiliário’?)\nCom base nesses perfis, que ação estratégica podemos tomar para cada um?”\n\nTarefa: Utilizando o dataframe final padronizado do Projeto 2, seu trabalho é realizar uma análise de clusterização. O projeto é INDIVIDUAL.\nPrazo: Próxima aula.\nEntrega: Você deve produzir um Relatório de Segmentação de Clientes em PDF (gerado via Quarto). Este relatório deve ser escrito em linguagem de negócios, como se fosse ser lido por um gerente de risco de crédito que não é um especialista em estatística.\n\nO código R completo e comentado deve ser incluído ao final do documento, em um Apêndice.\n\n\nEstrutura Obrigatória do Relatório\nSeu documento Quarto deve seguir esta estrutura para ser considerado profissional:\n\nSumário Executivo\n\nResponda diretamente à solicitação do “banco”.\nEx: “Nossa análise do portfólio de crédito revelou a existência de [K] perfis de clientes distintos. Os grupos mais relevantes são [Nome do Cluster 1, ex: ‘Risco Emergente’] e [Nome do Cluster 2, ex: ‘Conservadores de Baixa Dívida’]. Recomendamos ações imediatas de monitoramento para o Cluster 1 e foco em vendas de novos produtos para o Cluster 2. Os detalhes da análise seguem.”\n\nIntrodução e Objetivo\n\nBreve descrição do problema de negócio (a necessidade de segmentar clientes) e o objetivo do projeto (usar clusterização para encontrar perfis acionáveis).\n\nMetodologia de Segmentação\n\n3.1. Fonte de Dados: Descreva brevemente os dados de entrada (ex: “O dataframe padronizado do Projeto 2, contendo [N] observações e [P] variáveis selecionadas…”).\n3.2. Justificativa do Algoritmo (Ponto-Chave): Aqui, você deve usar o conteúdo da nossa aula. Analise a natureza do seu dataframe do Projeto 2.\n\nEle é 100% numérico?\nEle é 100% categórico?\nEle é Misto (com variáveis numéricas padronizadas e variáveis categóricas/dummies)?\nOs dados possuem muitos outliers?\nCom base nessa resposta, justifique sua escolha do método de clusterização.\nEx: “Como nossos dados contêm uma mistura de variáveis numéricas (ex: vencido_padronizado, idade_padronizada) e categóricas (ex: porte_empresa, uf), o uso de K-Means (apenas numérico) ou K-Modes (apenas categórico) é inadequado. Portanto, optamos pelo K-Prototypes, um algoritmo híbrido que lida nativamente com ambos os tipos de dados, combinando a Distância Euclidiana (para os dados já padronizados) e a Distância de Hamming.”\n\n3.3. Definição do Número de Grupos (k): Apresente o(s) gráfico(s) (Método do Cotovelo e/ou Silhueta) que você usou para escolher o número k de clusters.\n\nJustifique a escolha (ex: “O Método da Silhueta Média atingiu seu pico em k=4, indicando que esta é a separação mais coesa e distinta…”).\n\n\nResultados: Os Perfis de Clientes (Personas)\n\nEsta é a parte principal do relatório.\nPara cada um dos k clusters, crie uma “persona” ou perfil.\nDê um nome acionável a cada cluster (ex: “Cluster 1: Os Inadimplentes Recentes”, “Cluster 2: Os Super-Endividados”, “Cluster 3: O Cliente Padrão”).\nApresente uma tabela ou gráficos que mostrem as médias (para numéricos) e as modas (para categóricos) de cada cluster (como fizemos no exercício do K-Prototypes).\n\nRecomendações Estratégicas\n\nPara cada “persona” que você criou, sugira uma ação de negócio que o banco pode tomar.\nEx. Cluster 1 (‘Inadimplentes Recentes’): “Ação: Encaminhar imediatamente para a esteira de renegociação/cobrança. Não oferecer novos produtos de crédito.”\nEx. Cluster 2 (‘Cliente Padrão’): “Ação: Focar em cross-sell. Oferecer seguros, consórcios ou financiamento imobiliário. Baixo risco, alto potencial de engajamento.”\n\nApêndice: Script R Completo\n\nAo final do documento, insira uma seção “Apêndice” e coloque seu script R completo e comentado.\nUse echo: true e eval: false para os chunks de código no apêndice, garantindo que o relatório principal (seções 1-5) esteja limpo e focado nos resultados (sem código).",
    "crumbs": [
      "Aulas",
      "Parte 2: Métodos Não Supervisionados",
      "6- Agrupamento com K-Means e Métodos Relacionados"
    ]
  },
  {
    "objectID": "aulas/03-introducao_ao_quarto.html",
    "href": "aulas/03-introducao_ao_quarto.html",
    "title": "Conteúdo 3",
    "section": "",
    "text": "Nesta aula, iniciamos nossa jornada no Quarto, a plataforma unificada que é o padrão atual para comunicação científica no RStudio. Exploramos a estrutura de um documento .qmd, o papel do cabeçalho YAML e o uso de Markdown para formatação. Aprendemos a criar, editar e renderizar documentos que integram texto, blocos de código R, tabelas, gráficos e referências. A aula mostra como o Quarto permite gerar diversos formatos de saída (como HTML, PDF e slides) a partir de um único arquivo. Esse é o ponto de partida para desenvolver habilidades de comunicação eficaz, garantir a reprodutibilidade das análises e adotar boas práticas na documentação de projetos ao longo da disciplina.\nSlides:\n\n\n Versão html \n\n\n Versão pdf \n\n\nPara auxiliar na prática, também está disponível um modelo de exemplo em Quarto para download.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "3- Introdução ao Quarto"
    ]
  },
  {
    "objectID": "aulas/03-introducao_ao_quarto.html#introdução-ao-quarto",
    "href": "aulas/03-introducao_ao_quarto.html#introdução-ao-quarto",
    "title": "Conteúdo 3",
    "section": "",
    "text": "Nesta aula, iniciamos nossa jornada no Quarto, a plataforma unificada que é o padrão atual para comunicação científica no RStudio. Exploramos a estrutura de um documento .qmd, o papel do cabeçalho YAML e o uso de Markdown para formatação. Aprendemos a criar, editar e renderizar documentos que integram texto, blocos de código R, tabelas, gráficos e referências. A aula mostra como o Quarto permite gerar diversos formatos de saída (como HTML, PDF e slides) a partir de um único arquivo. Esse é o ponto de partida para desenvolver habilidades de comunicação eficaz, garantir a reprodutibilidade das análises e adotar boas práticas na documentação de projetos ao longo da disciplina.\nSlides:\n\n\n Versão html \n\n\n Versão pdf \n\n\nPara auxiliar na prática, também está disponível um modelo de exemplo em Quarto para download.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "3- Introdução ao Quarto"
    ]
  },
  {
    "objectID": "aulas/02-introducao_ao_rstudio+github.html",
    "href": "aulas/02-introducao_ao_rstudio+github.html",
    "title": "Conteúdo 2",
    "section": "",
    "text": "Nesta aula, damos nossos primeiros passos práticos na integração entre o RStudio e o GitHub, ferramentas essenciais para o trabalho moderno em ciência de dados. Exploramos o papel do Git no controle de versões e aprendemos a criar, conectar e atualizar repositórios de forma segura e organizada. A aula mostra como essas ferramentas permitem registrar a evolução dos projetos, trabalhar de qualquer lugar e manter um histórico completo das análises. Esse é o ponto de partida para desenvolver autonomia, reprodutibilidade e boas práticas de programação ao longo da disciplina.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "2- Introdução ao RStudio + GitHub"
    ]
  },
  {
    "objectID": "aulas/02-introducao_ao_rstudio+github.html#introdução-ao-rstudio-github",
    "href": "aulas/02-introducao_ao_rstudio+github.html#introdução-ao-rstudio-github",
    "title": "Conteúdo 2",
    "section": "",
    "text": "Nesta aula, damos nossos primeiros passos práticos na integração entre o RStudio e o GitHub, ferramentas essenciais para o trabalho moderno em ciência de dados. Exploramos o papel do Git no controle de versões e aprendemos a criar, conectar e atualizar repositórios de forma segura e organizada. A aula mostra como essas ferramentas permitem registrar a evolução dos projetos, trabalhar de qualquer lugar e manter um histórico completo das análises. Esse é o ponto de partida para desenvolver autonomia, reprodutibilidade e boas práticas de programação ao longo da disciplina.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "2- Introdução ao RStudio + GitHub"
    ]
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#objetivo-da-aula",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#objetivo-da-aula",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Objetivo da aula",
    "text": "Objetivo da aula\n\nEntender o que é e para que serve o  e o .\nSaber como criar um repositório de projeto.\nAtualizar repositório no  via ."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#o-que-é-o",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#o-que-é-o",
    "title": "Introdução ao RStudio + GitHub",
    "section": "O que é o ?",
    "text": "O que é o ?\n\nGit é uma ferramenta que ajuda a controlar e gerenciar mudanças em arquivos ao longo do tempo.\nEle permite que você salve versões diferentes de um trabalho à medida que faz alterações, de modo que possa voltar para versões anteriores se algo der errado ou se precisar revisar mudanças feitas."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#por-que-o-é-importante",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#por-que-o-é-importante",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Por que o  é importante?",
    "text": "Por que o  é importante?\n\nEvita perda de trabalho: Se você estiver escrevendo código ou criando qualquer tipo de documento, o Git permite que você salve diferentes versões do seu trabalho. Assim, se algo der errado, você pode voltar a uma versão anterior.\nFacilita o trabalho em equipe: Quando várias pessoas estão trabalhando no mesmo projeto, o Git permite que cada uma trabalhe de forma independente e depois una os trabalhos de maneira organizada. Isso evita que as alterações de uma pessoa sobrescrevam as de outra.\nOrganização e rastreamento: O Git mantém um histórico completo de todas as mudanças feitas em um projeto, permitindo saber quem fez o quê e quando."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#o-que-é-o-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#o-que-é-o-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": "O que é o ?",
    "text": "O que é o ?\n\nGitHub é uma plataforma online que armazena e organiza projetos que utilizam Git.\nEle permite que você publique seu código, compartilhe arquivos e colabore com outras pessoas em projetos de forma fácil e eficiente."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#por-que-o-é-importante-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#por-que-o-é-importante-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Por que o  é importante?",
    "text": "Por que o  é importante?\n\nArmazenamento seguro: Com o GitHub, seus projetos ficam seguramente armazenados na nuvem. Isso significa que você pode acessar seu trabalho de qualquer lugar e sempre terá uma cópia segura.\nColaboração em equipe: GitHub permite que várias pessoas trabalhem no mesmo projeto ao mesmo tempo. Cada pessoa pode fazer mudanças no código, e o GitHub ajuda a gerenciar essas mudanças sem que uma sobrescreva a outra.\nHistórico e transparência: O GitHub mantém um histórico completo de todas as alterações feitas no seu projeto. Isso permite ver quem fez o quê e quando, facilitando o acompanhamento e revisão do trabalho de equipe."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#como-e-por-que-usar-o-na-disciplina",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#como-e-por-que-usar-o-na-disciplina",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Como e por que usar o  na disciplina?",
    "text": "Como e por que usar o  na disciplina?\n\nVocê receberá um script em R a cada aula\nDurante a aula, vai editar esse script no RStudio, testando e resolvendo problemas\nNo final da aula, envia suas alterações para seu repositório (push) — tudo salvo e organizado\nPode acessar seu trabalho de qualquer lugar, com segurança e histórico garantido\n\n\nGitHub será seu caderno digital de códigos — inteligente, seguro e acessível para a disciplina"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#primeiros-passos",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#primeiros-passos",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Primeiros passos",
    "text": "Primeiros passos\n\nBaixar e instalar o Git: https://happygitwithr.com/install-git.html\nCriar uma conta no GitHub: https://github.com/\nCriar um reposítório Git\nClone esse repositório para sua máquina usando o RStudio\nTrabalhe no projeto e envie as atualizações de volta ao GitHub\n\n\nDesenvolva o hábito de buscar soluções por conta própria. Isso faz parte do dia a dia de quem trabalha com dados. Comece agora a desenvolver essa autonomia."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-repositório-no",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-repositório-no",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Criando um repositório  no ",
    "text": "Criando um repositório  no \n\nApós fazer login no GitHub, Clique em + no canto superior direito\nEm seguida, clique em New repository"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-repositório-no-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-repositório-no-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Criando um repositório  no ",
    "text": "Criando um repositório  no \n\n\n\nEm Repository name dê um anome ao repositóro\nEm Description faça uma descrição do repositório\nMarque a opção Public ou Private\nEm Initialize this repository with: marque a opção Add a README file\nClique em Create repository"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#section",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#section",
    "title": "Introdução ao RStudio + GitHub",
    "section": "",
    "text": "Com o repositório já criado no GitHub, agora vamos usar o RStudio para ligar o projeto local ao repositório remoto.\nAssim, todas as alterações feitas no RStudio poderão ser salvas na nuvem e versionadas automaticamente.\nPara enviar essas alterações ao GitHub, será necessário se autenticar — com login e senha ou com um token de acesso.\n\nVamos ver como criar um token de acesso no GitHub."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Criando um token de acesso no ",
    "text": "Criando um token de acesso no \n\n\n\nEstando logado no GitHub, clique na sua foto de perfil no canto superior direito\n\nClique em Settings"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Criando um token de acesso no ",
    "text": "Criando um token de acesso no \n\nNo canto inferior esquerdo da tela clique em Developer settings"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no-2",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no-2",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Criando um token de acesso no ",
    "text": "Criando um token de acesso no \n\n\n\nNo canto superior esquerdo da tela clique em Personal access tokens\nClique em Tokens (classic)\n\n\n\n\n\n\n\nEm Expiration selecione a data em que o token irá expirar\nMarque todas as opções em Select scopes\nClique em Generate token\n\n\nO token será gerado uma única vez. Guarde-o com cuidado, pois não será possível visualizá-lo novamente no GitHub. Você usará esse token quando for solicitada autenticação."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#integração-prática",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#integração-prática",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : integração prática",
    "text": "+ : integração prática\n\nO RStudio possui integração nativa com o Git e GitHub\n\nOu seja, é possível sincronizar um repositório GitHub a um repositório local\nIsso significa que você pode ligar o repositório do GitHub (na nuvem) ao seu projeto no computador. Assim, o que você altera localmente pode ser enviado para o GitHub — e vice-versa.\n\nPara isso, seguimos os seguintes passos:"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#integração-prática-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#integração-prática-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : integração prática",
    "text": "+ : integração prática\n\nFazemos uma cópia do repositório do GitHub na máquina local usando o RStudio.\n\nQuando já há uma cópia na máquina, começamos o trabalho atualizando o projeto local com as alterações que estão no GitHub (pull).\n\nTrabalhamos normalmente no projeto: scripts, análises, relatórios…\nUsamos o Git para registrar as alterações (commit) e enviar para o GitHub (push)."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : criando o projeto local",
    "text": "+ : criando o projeto local\n\n\n\nNo canto superior direito do RStudio clique em File &gt; New Project\nClique em Version control"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : criando o projeto local",
    "text": "+ : criando o projeto local\n\nClique em Git"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-2",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-2",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : criando o projeto local",
    "text": "+ : criando o projeto local\n\n\n\nNo campo Repository URL, cole a URL do repositório que você criou no GitHub\nEm Create project as subdirectory of, escolha o diretório em que o repositório do GitHub será copiado na máquina local\nClique em Create Project"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-3",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-3",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : criando o projeto local",
    "text": "+ : criando o projeto local\n\nSe você estiver clonando um repositório público, o RStudio irá criar uma cópia do projeto localmente, sem exigir login.\nSe o repositório for privado, o GitHub pedirá que você se autentique (login e senha ou token).\n\n\n\nUma vez que já existe o projeto na máquina local, você só precisa acessar o diretório local (pasta) e clicar no arquivo com extensão .Rproj para abrir o projeto no Rstudio, sem necessidade de clonar o projeto novamente na máquina."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nDepois de salvar as atualizações do seu projeto local, você pode enviar essas alterações para o repositório no GitHub diretamente pelo RStudio. Você deve fazer:\n\n\nNo quadrante superior direito clique em Commit"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nRStudio mostra os arquivos que foram alterados. Selecione-os.\nNo campo Commit message escreva um comentário contendo o que foi atualizado (sugestão: não use caracteres especiais ou acentos)\nClique em Commit"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-2",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-2",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-3",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-3",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nApós finalizado o envio, clique em Close"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-4",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-4",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nNote que irá aparecer a mensagem Your branch is ahead of 'origin/master' by 1 commit (isto indica que você tem alterações ainda não enviadas ao GitHub)\nClique em Push"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-5",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-5",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nEm máquinas com Windows o Rstudio redirecionará para você fazer login na sua conta GitHub no seu navegador. Em Linux preencha o campo Username for 'https://github.com' coloque login e clique em OK"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-6",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-6",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nAinda em Linux, no campo Personal Access Token insira o token criado no GitHub\nClique em OK"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-7",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-7",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nCaso apareça a mensagem abaixo, os arquivos foram atualizados no repositório do GitHub."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#material-extra",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#material-extra",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Material Extra",
    "text": "Material Extra\nAprofunde o que vimos em aula com esses vídeos no YouTube:\n\nCurso completo de Git e GitHub: http://tiny.cc/GitGitHub:\nIntegração do RStudio com o GitHub:\n\nParte 1: http://tiny.cc/RStudioGitHub1\nParte 2: http://tiny.cc/RStudioGitHub2"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#ganhos-da-aula",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#ganhos-da-aula",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Ganhos da aula",
    "text": "Ganhos da aula\n\nVersionamento de código e arquivos com GitHub\nIntegração do RStudio com GitHub\nExperiência com ferramentas do mercado"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#atividade-extraclasse",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#atividade-extraclasse",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Atividade extraclasse",
    "text": "Atividade extraclasse\nConfigure seu ambiente de trabalho pessoal\nObjetivo\nDeixar seu computador pessoal pronto para continuar os trabalhos da disciplina fora do laboratório, de forma independente.\nEtapas:\n\nInstalar o Git: https://happygitwithr.com/install-git.html\nInstalar o R: https://cran.r-project.org\nInstalar o RStudio: https://posit.co/download/rstudio-desktop\n\nCriar um repositório da disciplina do GitHub, clonar via RStudio para a sua máquina local e fazer seu primeiro commit."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#canais-de-comunicação-e-materiais-da-disciplina",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#canais-de-comunicação-e-materiais-da-disciplina",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Canais de Comunicação e Materiais da Disciplina",
    "text": "Canais de Comunicação e Materiais da Disciplina\n\nSite: http://sadraquelucena.github.io/mineracao\nGrupo no WhatsApp: http://tiny.cc/wppmineracao"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#informações-da-disciplina",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#informações-da-disciplina",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Informações da disciplina",
    "text": "Informações da disciplina\n\nComponente curricular: ESTAT0109 – Mineração de Dados em Estatística\nTipo: Disciplina optativa\nCarga horária: 60 horas (4 créditos)\nHorário:\n\nTerças e Quintas - 17h00 às 18h30\n\nDocente: Prof. Dr. Sadraque E. F. Lucena"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#objetivo-da-disciplina",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#objetivo-da-disciplina",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Objetivo da Disciplina",
    "text": "Objetivo da Disciplina\nCapacitar os(as) alunos(as) a aplicar técnicas estatísticas e computacionais para extrair padrões e conhecimentos úteis a partir de conjuntos de dados."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#ementa",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#ementa",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Ementa",
    "text": "Ementa\n\nAnálise estatística em grandes bancos de dados.\nTratamento de dados para processos de Data Mining.\nPrincipais funcionalidades, técnicas e algoritmos.\nAnálise de associações.\nClassificação de dados.\nÁrvores de decisão.\nRegressão Logística.\nRedes Neurais.\nSegmentação e Análise de Cluster.\nEstudo de casos."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Conteúdo Programático",
    "text": "Conteúdo Programático\nParte 1: Fundamentos   1.1. Fundamentos da Mineração de Dados   1.2. Pré-processamento de dados      1.2.1. Exploração      1.2.2. Limpeza      1.2.3. Transformação      1.2.3. Redução  Parte 2: Aprendizado Não Supervisionado   2.1. Regras de Associação   2.2.\\(k\\)-means"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático-1",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático-1",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Conteúdo Programático",
    "text": "Conteúdo Programático\nParte 3: Aprendizado Supervisionado   3.1. Regressão      3.1.1. Regressão linear      3.1.2. Regressão logística   3.2. \\(k\\)-Nearest Neighbors   3.3. Naive Bayes   3.4. Árvores de Decisão   3.5. Florestas aleatórias   3.6. Support Vector Machine"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático-2",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático-2",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Conteúdo Programático",
    "text": "Conteúdo Programático\nParte 3: Aprendizado Supervisionado (continuação)   3.7. Avaliação de desempenho      3.7.1. Validação Cruzada      3.7.2. Amostragem bootstrap      3.7.3. Acurácia      3.7.4. Kappa      3.7.5. Precisão e revocação      3.7.6. Sensibilidade e especificidade   3.8. Ajuste de parâmetros   3.9. Métodos de conjunto (ensemble methods)      3.9.1. Bagging      3.9.2. Boosting      3.9.3. Stacking"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#avaliação",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#avaliação",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Avaliação",
    "text": "Avaliação\nA avaliação do aprendizado será realizada por meio de um portfólio de projetos práticos, composto por:\n\nMini-Projetos: Estudos de casos práticos ao longo do semestre, com relatórios curtos descrevendo a preparação dos dados, aplicação dos algoritmos e interpretação dos resultados.\nProjeto Final Integrador: Relatório final consolidando as análises, com comparação crítica entre modelos, avaliação de desempenho e recomendação do modelo mais adequado ao problema."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#datas-importantes",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#datas-importantes",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Datas Importantes",
    "text": "Datas Importantes\n\n\n\n\n\n\n\nNão haverá aula:\n\n\n\n20/Nov/25: Dia Nacional de Zumbi e da Consciência Negra (feriado nacional)\n25 e 27/Nov/25: XI SEMAC\n22 a 31/12/2025: Recesso de final de ano\n01/01/2026: Confraternização Universal (feriado nacional) e Aniversário de São Cristóvão (feriado municipal)\n02 a 10/01/2026: Férias coletivas para docentes"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#bibliografia-recomendada",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#bibliografia-recomendada",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Bibliografia Recomendada",
    "text": "Bibliografia Recomendada\nBásica"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#bibliografia-recomendada-1",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#bibliografia-recomendada-1",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Bibliografia Recomendada",
    "text": "Bibliografia Recomendada\nComplementar"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#ferramentas",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#ferramentas",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Ferramentas",
    "text": "Ferramentas"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#o-que-é-mineração-de-dados",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#o-que-é-mineração-de-dados",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "O que é Mineração de Dados?",
    "text": "O que é Mineração de Dados?\n\nMineração Tradicional: processo de mineração tradicional, que busca extrair materiais valiosos (ouro, pedras preciosas) de uma mina.\nMineração de Dados:\n\nA Mina → A Base de Dados\nAs Ferramentas → Os Algoritmos\nOs Minerais Preciosos → O Conhecimento"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-hierarquia-de-valor-dados-informação-e-conhecimento",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-hierarquia-de-valor-dados-informação-e-conhecimento",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "A Hierarquia de Valor: Dados, Informação e Conhecimento",
    "text": "A Hierarquia de Valor: Dados, Informação e Conhecimento\n\nPara que a Mineração de Dados faça sentido, precisamos entender como o valor é agregado em cada nível.\n\nDados: Nível base. São símbolos ou signos brutos, não estruturados e sem significado isolado (Ex: o valor “28”).\nInformação: Dados com significado e utilidade. Contexto é adicionado (Ex: “A temperatura do ar é 28°C”).\nConhecimento: É a compreensão obtida a partir da informação, permitindo a tomada de decisão e a agregação de valor. (Ex: “Saber que fará 28°C em Aracaju no fim de semana pode influenciar a decisão de ir à praia”)."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#exemplos",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#exemplos",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Exemplos",
    "text": "Exemplos\n\nCasos em que a mineração de dados geralmente agrega valor:\n\nDescobrir anomalias em registros de sistema e aplicativos que podem indicar um incidente de cibersegurança;\nPrever as vendas de produtos com base nas condições de mercado e ambientais;\nRecomendar o próximo filme que um cliente pode querer assistir com base em sua atividade passada e nas preferências de clientes semelhantes;\nDefinir os preços dos quartos de hotel com bastante antecedência com base na demanda prevista."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#kdd",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#kdd",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "KDD",
    "text": "KDD\nA mineração de dados é uma etapa fundamental de um processo mais abrangente conhecido pela sigla KDD.\n\nKDD (Knowledge Discovery in Databases | Descoberta de Conhecimento em Bases de Dados): Processo completo e abrangente de extrair conhecimento útil de dados.\n\nEnvolve desde a coleta e limpeza dos dados até a validação final dos padrões encontrados.\nSuas etapas incluem: seleção, integração, limpeza, transformação, mineração e avaliação.\n\nMineração de Dados: Etapa fundamental no processo KDD.\n\nAplicação de algoritmos (computacionais e estatísticos) para identificar padrões nos dados já preparados."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#processo-kdd-visão-geral",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#processo-kdd-visão-geral",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Processo KDD: Visão Geral",
    "text": "Processo KDD: Visão Geral\nO processo KDD consiste em quatro etapas:\n\nBase de Dados: Ponto de partida. É uma coleção organizada de dados brutos sobre um conjunto de itens.\nPreparação ou Pré-processamento: A etapa de preparação e limpeza dos dados para garantir a qualidade da análise.\nMineração de Dados: A fase de “escavação”, onde algoritmos são aplicados para buscar padrões e extrair conhecimento.\nAvaliação ou Validação do Conhecimento: A fase final, que filtra e valida se os padrões encontrados são realmente úteis e valiosos.\n\n\nMuitas vezes, após a avaliação (etapa 4), é preciso retornar a etapas anteriores para refinar a análise."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-etapa-mais-crítica-pré-processamento",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-etapa-mais-crítica-pré-processamento",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "A Etapa Mais Crítica: Pré-processamento",
    "text": "A Etapa Mais Crítica: Pré-processamento\nEsta etapa visa preparar os dados para uma análise eficiente:\n\nLimpeza: Tratamento de dados inconsistentes ou faltantes (missing values).\nIntegração: Combinação de dados de múltiplas fontes (planilhas, bancos de dados diferentes).\nSeleção: Escolha dos dados e variáveis (atributos) mais relevantes(redução de dimensionalidade).\nTransformação: Consolidação dos dados em formatos apropriados para a mineração (ex: normalização, padronização, agregação)."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#mineração-coração-do-processo",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#mineração-coração-do-processo",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Mineração (Coração do Processo)",
    "text": "Mineração (Coração do Processo)\nNesta fase, algoritmos são aplicados aos dados já preparados para extrair padrões.\n\nAgrupamento (Clusterização): Divide os dados em grupos semelhantes entre si e distintos dos demais.\nPredição: Constrói modelos para prever valores futuros. Classificação prevê uma categoria, enquanto Estimação (ou Regressão) prevê um valor contínuo.\nRegras de Associação: Descobre atributos que ocorrem juntos com frequência, como no exemplo “quem compra pão também compra manteiga”.\nDetecção de Anomalias: Identifica registros fora do padrão, úteis para detectar fraudes ou defeitos."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#avaliação-e-validação-do-conhecimento",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#avaliação-e-validação-do-conhecimento",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Avaliação e Validação do Conhecimento",
    "text": "Avaliação e Validação do Conhecimento\nNem todo padrão encontrado por um algoritmo é útil. Esta etapa filtra os resultados para garantir que o conhecimento gerado seja valioso. As perguntas a serem respondidas incluem:\n\nO padrão é estatisticamente significativo ou ocorreu ao acaso?\nEle é novo e surpreendente ou apenas confirma algo que já sabíamos?\nÉ compreensível para o especialista do domínio ou para quem toma decisão?\nEle pode ser usado para embasar uma decisão que trará benefícios (aumento de receita, redução de custos, etc.)?\nO objetivo é separar o conhecimento útil de padrões irrelevantes."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#mineração-de-dados-é-interdisciplinar",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#mineração-de-dados-é-interdisciplinar",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Mineração de Dados é Interdisciplinar",
    "text": "Mineração de Dados é Interdisciplinar\n\nEstatística: Fornece a base para modelagem, testes de hipóteses e validação.\nAprendizagem de Máquina e IA: Oferece um vasto arsenal de algoritmos.\nCiência da Computação: Lida com Bancos de Dados, eficiência de algoritmos e computação de alto desempenho.\nVisualização de Dados: Essencial para a interpretação e comunicação dos resultados."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#principais-termos-da-área",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#principais-termos-da-área",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Principais Termos da Área",
    "text": "Principais Termos da Área\n\nA área de Mineração de Dados possui uma vasta quantidade de técnicas e algoritmos.\nFoi desenvolvida ao longo de décadas por diferentes grupos:\n\nPesquisadores acadêmicos\nEmpresas de tecnologia\nConsultores\n\nEssa diversidade de origens e inspirações (da estatística à biologia) gerou diferentes nomenclaturas para contextos muitas vezes similares.\nÉ importante estarmos familiarizados com as nomenclaturas mais utilizadas."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#inteligência-artificial-ia-clássica",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#inteligência-artificial-ia-clássica",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Inteligência Artificial (IA) Clássica",
    "text": "Inteligência Artificial (IA) Clássica\n\nDefinição: A ciência e engenharia de criar máquinas inteligentes, especialmente programas de computador.\nInspiração Principal: A inteligência humana (percepção, resolução de problemas, comunicação).\nAbordagem Central: Era simbólica e baseada em lógica.\n\nConhecimento era representado por símbolos e regras.\nO sistema inteligente era construído codificando-se o conhecimento de um especialista.\n\nExemplo: Sistemas Especialistas (Expert Systems).\n\nSe tosse E febre E dor de cabeça, ENTÃO gripe."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#inteligência-computacional",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#inteligência-computacional",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Inteligência Computacional",
    "text": "Inteligência Computacional\n\nOrigem: Surgiu de uma discordância com a IA Clássica.\n\nA IA Clássica teve dificuldade em cumprir promessas ambiciosas (robôs autônomos, etc.).\nNovas abordagens, com formas de operação diferentes, precisavam de um novo nome.\n\nFoco: Técnicas não-simbólicas, muitas vezes inspiradas em fenômenos biológicos.\nPilares da Inteligência Computacional:\n\nRedes Neurais Artificiais\nSistemas Nebulosos (Fuzzy Systems)\nAlgoritmos Evolutivos"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#aprendizagem-de-máquina",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#aprendizagem-de-máquina",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Aprendizagem de Máquina",
    "text": "Aprendizagem de Máquina\n\nDefinição: Área que desenvolve programas capazes de melhorar seu desempenho automaticamente por meio da experiência.\nFonte da Experiência: Dados.\nIdeia Central: Em vez de programar regras explícitas, o sistema aprende os padrões diretamente dos dados.\nRelação: Está intimamente ligada à Mineração de Dados, Estatística e Inteligência Artificial.\nFoco Principal: Extrair informação e conhecimento a partir de dados de forma automática."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#aplicações-no-mundo-real",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#aplicações-no-mundo-real",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Aplicações no Mundo Real",
    "text": "Aplicações no Mundo Real\n\nRecomendação de Filmes e Produtos: A Netflix aprende seus gostos (Aprendizagem de Máquina) para sugerir novos filmes.\nDiagnóstico Médico por Imagem: Sistemas analisam tomografias para identificar padrões de doenças, aprendendo com milhares de exames anteriores (Redes Neurais).\nDetecção de Fraude em Cartão de Crédito: O sistema aprende o padrão de gastos do cliente (Aprendizagem de Máquina) e sinaliza transações que fogem desse padrão.\nOtimização de Rotas de Entrega: Algoritmos inspirados em colônias de formigas (Computação Natural) encontram os caminhos mais eficientes."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#como-as-máquinas-aprendem",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#como-as-máquinas-aprendem",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Como as Máquinas Aprendem?",
    "text": "Como as Máquinas Aprendem?\n\nAprendizado Supervisionado:\n\nO algoritmo treina com um conjunto de dados que já possui as respostas corretas (rótulos).\nExemplo: Prever o preço de um imóvel usando uma base de dados com o preço de imóveis já vendidos.\n\nAprendizado Não Supervisionado:\n\nO algoritmo recebe dados sem respostas ou rótulos.\nA tarefa é encontrar padrões, estruturas ou grupos ocultos nos dados.\nExemplo: Agrupar clientes de um supermercado em segmentos com base em seus hábitos de compra."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#computação-natural",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#computação-natural",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Computação Natural",
    "text": "Computação Natural\n\nDefinição: Um termo “guarda-chuva” para descrever técnicas que se relacionam com a natureza.\nInspiração: Fenômenos naturais, que vão além da inteligência humana.\n\nExemplos: Evolução das espécies, sistema imunológico, comportamento de enxames (formigas, abelhas), construção de ninhos por cupins.\n\nAbrangência:\n\nMétodos inspirados na natureza para resolver problemas.\n\nAlgoritmos Evolutivos, Inteligência de Enxame.\n\n\nMétodos que usam a natureza para computar. - Computação com moléculas (DNA), Computação Quântica."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "A Mesma Ideia, Nomes Diferentes",
    "text": "A Mesma Ideia, Nomes Diferentes\nMuitos conceitos de Mineração de Dados e Aprendizagem de Máquina têm um equivalente direto na Estatística. A base matemática é frequentemente a mesma.\n\nInstância (Instance)\n\nObservação ou Ponto Amostral\nUma unidade amostral ou indivíduo (equivale a uma linha em uma tabela).\n\nAtributo (Attribute / Feature)\n\nVariável Independente ou Variável Explicativa (preditor)\nÉ a variável que usamos para fazer uma previsão (equivale a uma coluna em uma tabela)."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes-1",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes-1",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "A Mesma Ideia, Nomes Diferentes",
    "text": "A Mesma Ideia, Nomes Diferentes\n\nRótulo ou Atributo-Alvo (Label / Target)\n\nVariável Dependente ou Variável Resposta\nÉ a variável que o modelo estatístico tenta prever ou explicar.\n\nModelo (Model)\n\nModelo estatístico ou algoritmo computacional criado que será usado para fazer novas previsões.\nPode ser, por exemplo, uma árvore de decisão, uma rede neural ou um modelo de regressão logística."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes-2",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes-2",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "A Mesma Ideia, Nomes Diferentes",
    "text": "A Mesma Ideia, Nomes Diferentes\n\nTreinamento (Training)\n\nAjuste do Modelo ou Estimação de Parâmetros\nÉ o processo de usar os dados para encontrar os melhores coeficientes (parâmetros) do modelo (Ex: método de mínimos quadrados em uma regressão).\n\nDiferença sutil no foco:\n\nA Estatística Clássica frequentemente enfatiza a inferência, ou seja, entender e explicar a relação entre as variáveis.\nA Mineração de Dados e Aprendizagem de Máquina geralmente priorizam a capacidade de predição do modelo em dados futuros, mesmo que o modelo seja uma “caixa-preta”."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#objetivo-da-aula",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#objetivo-da-aula",
    "title": "Regressão Logística",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\n\nCompreender por que a Regressão Linear falha em classificação e como a Função Sigmoide resolve isso limitando as probabilidades entre 0 e 1.\nAprender a ajustar um modelo de Regressão Logística para prever a probabilidade de eventos binários (Sim/Não, Fraude/Legal, 0/1).\nLer os coeficientes não apenas como números, mas como fatores de risco (Odds Ratio) que aumentam ou diminuem a chance do evento.\nSuperar a “ilusão da acurácia” aprendendo a usar Matriz de Confusão, Sensibilidade, Especificidade e Curva ROC/AUC para validar o modelo."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#regressão-logística-o-classificador",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#regressão-logística-o-classificador",
    "title": "Regressão Logística",
    "section": "Regressão Logística: O Classificador",
    "text": "Regressão Logística: O Classificador\n\nA regressão logística é a técnica fundamental para classificação binária.\nDiferente da regressão linear (que prevê valores contínuos), aqui queremos estimar a probabilidade de um evento ocorrer.\nAplicações em Mineração de Dados:\n\nChurn: Prever se um cliente vai cancelar o serviço (\\(Y=1\\)) ou ficar (\\(Y=0\\)).\nFraude: Identificar se uma transação é fraudulenta ou legítima.\nMedicina: Classificar um tumor como maligno ou benigno com base em exames.\nCrédito: Estimar o risco de inadimplência (default)."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#formulação",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#formulação",
    "title": "Regressão Logística",
    "section": "Formulação",
    "text": "Formulação\n\nConsidere \\(y_i\\) como nossa variável alvo (Target) binária: \\[\n\\begin{cases}\n  y_i = 1, & \\text{ (evento de interesse: fraude, óbito, clique)}\\\\\n  y_i = 0, & \\text{ (evento negativo)}\n\\end{cases}\n\\]\nTemos um conjunto de features (variáveis explicativas) \\(\\underset{\\sim}{x} = x_1,x_2,\\ldots,x_p\\).\nObjetivo da Predição: Não queremos apenas “0” ou “1”, mas sim a probabilidade (\\(\\pi_i\\)) de pertencer à classe positiva: \\[\nP(y_i=1|~\\underset{\\sim}{x}) = \\pi_i\n\\]"
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#por-que-não-usar-regressão-linear",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#por-que-não-usar-regressão-linear",
    "title": "Regressão Logística",
    "section": "Por que não usar Regressão Linear?",
    "text": "Por que não usar Regressão Linear?\n\nTentar ajustar uma reta \\(\\pi_i = \\beta_0 + \\beta_1 x\\) gera dois problemas fatais para classificação:\n\nViolação de Limites: Uma reta pode prever probabilidades absurdas, como \\(-0.2\\) ou \\(1.5\\). Probabilidade deve estar sempre entre \\([0, 1]\\).\nNão-Linearidade: A transição de “não acontecer” para “acontecer” raramente é linear; geralmente é abrupta (como um “S”).\n\n\n\n\nPrecisamos de uma função que “esprema” as predições para dentro do intervalo \\([0,1]\\)."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#a-solução-função-logística-sigmoide",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#a-solução-função-logística-sigmoide",
    "title": "Regressão Logística",
    "section": "A Solução: Função Logística (Sigmoide)",
    "text": "A Solução: Função Logística (Sigmoide)\n\nPara garantir que a predição \\(\\pi_i\\) fique entre 0 e 1, usamos a Função Logística:\n\n\\[\n  \\pi_i = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_{1i} + \\cdots + \\beta_{p}x_{pi})}}\n\\]\n\nEssa fórmula gera uma curva em formato de S (Sigmoide).\nO termo dentro da exponencial, \\(\\beta_0 + \\beta_1 x + \\dots\\), é chamado de score ou preditor linear.\n\nSe o score for muito alto \\(\\to \\pi_i \\approx 1\\).\nSe o score for muito baixo (negativo) \\(\\to \\pi_i \\approx 0\\).\nSe o score for zero \\(\\to \\pi_i = 0.5\\)."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#o-logit-linearizando-o-problema",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#o-logit-linearizando-o-problema",
    "title": "Regressão Logística",
    "section": "O “Logit” (Linearizando o problema)",
    "text": "O “Logit” (Linearizando o problema)\n\nPodemos reescrever a equação anterior para torná-la linear nos parâmetros. Isso facilita a estimativa:\n\n\\[\n  \\underbrace{\\log\\left( \\frac{\\pi_i}{1-\\pi_i} \\right)}_{\\text{Logit}} = \\beta_0 + \\beta_1 x_{1i} + \\cdots + \\beta_{p}x_{pi}\n\\]\n\nLogit: É o logaritmo da chance (log-odds).\nInterpretação Visual:\n\nO lado direito é a nossa velha conhecida equação linear.\nO lado esquerdo é a transformação necessária para adequar a probabilidade ao mundo linear."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#estimando-os-parâmetros-o-fit",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#estimando-os-parâmetros-o-fit",
    "title": "Regressão Logística",
    "section": "Estimando os Parâmetros (O “Fit”)",
    "text": "Estimando os Parâmetros (O “Fit”)\n\nComo encontramos os melhores \\(\\beta\\)?\nNa regressão linear, usávamos Mínimos Quadrados (menor distância entre pontos e reta).\nNa logística, usamos Máxima Verossimilhança (Maximum Likelihood Estimation - MLE).\n\nIntuição: O algoritmo busca os valores de \\(\\beta\\) que maximizam a probabilidade de observar os dados que realmente coletamos.\nEm Machine Learning, isso é equivalente a minimizar a função de custo Log-Loss (Entropia Cruzada).\n\n\n\nNota: Não usamos \\(R^2\\) aqui. A qualidade do ajuste será medida pela capacidade de classificar corretamente (Acurácia, ROC, AUC)."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#fazendo-a-predição",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#fazendo-a-predição",
    "title": "Regressão Logística",
    "section": "Fazendo a Predição",
    "text": "Fazendo a Predição\n\nUma vez que o modelo “aprendeu” os \\(\\beta\\)s, fazemos a predição em novos dados em dois passos:\n\n\nCalcular o Score Linear: \\(\\eta_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\dots\\)\nConverter para Probabilidade: \\(\\hat{\\pi}_i = \\frac{exp(\\eta_i)}{1+exp(\\eta_i)}\\)"
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#exemplo-prático",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#exemplo-prático",
    "title": "Regressão Logística",
    "section": "Exemplo Prático",
    "text": "Exemplo Prático\nModelo ajustado para prever Inadimplência (\\(y=1\\)): \\[\n  \\text{logit}(\\pi) = -10.65 + 0.0055 \\times (\\text{Saldo Devedor})\n\\]\nPergunta: Qual a probabilidade de calote para um saldo de $2.000?\nCálculo:\n\n\\(\\eta = -10.65 + 0.0055(2000) = -10.65 + 11 = 0.35\\)\n\\(\\pi = \\frac{e^{0.35}}{1 + e^{0.35}} = \\frac{1.419}{2.419} \\approx 0.58\\)\n\n\nConclusão: Há 58% de probabilidade de inadimplência. O modelo classifica como “Mau Pagador” (se o corte for 0.5)."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#interpretando-os-coeficientes-odds-ratio",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#interpretando-os-coeficientes-odds-ratio",
    "title": "Regressão Logística",
    "section": "Interpretando os Coeficientes (Odds Ratio)",
    "text": "Interpretando os Coeficientes (Odds Ratio)\n\nEm Machine Learning, muitas vezes focamos apenas na predição, mas entender os coeficientes ajuda a explicar o modelo (“Explainable AI”).\nO \\(\\beta\\) nos diz como o logaritmo da chance muda. Para facilitar, usamos o Odds Ratio (OR) = \\(e^\\beta\\).\nRegra de Bolso:\n\nOR &gt; 1: A variável aumenta a chance do evento (Risco).\nOR &lt; 1: A variável diminui a chance do evento (Proteção).\nOR = 1: A variável não afeta a predição."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#exemplo-de-interpretação",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#exemplo-de-interpretação",
    "title": "Regressão Logística",
    "section": "Exemplo de Interpretação",
    "text": "Exemplo de Interpretação\nModelo de Risco de Crédito: \\[\n  \\text{logit} = -10.8 + \\underbrace{0.0057}_{\\beta_1} \\text{Saldo} + \\underbrace{0.0001}_{\\beta_2} \\text{Salário} - \\underbrace{0.65}_{\\beta_3} \\text{Estudante (Sim)}\n\\]\n\nSaldo (\\(e^{0.0057} \\approx 1.006\\)): A cada $1 dólar a mais de dívida, o risco aumenta ligeiramente (0.6%).\nEstudante (\\(e^{-0.65} \\approx 0.52\\)):\n\nO valor é menor que 1. Isso indica proteção.\nSer estudante reduz a chance de inadimplência em cerca de 48% (\\(1 - 0.52\\)) comparado a não-estudantes, mantendo as outras variáveis constantes."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#da-probabilidade-à-decisão-threshold",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#da-probabilidade-à-decisão-threshold",
    "title": "Regressão Logística",
    "section": "Da Probabilidade à Decisão (Threshold)",
    "text": "Da Probabilidade à Decisão (Threshold)\n\nO modelo cospe uma probabilidade (ex: \\(0.7\\), \\(0.2\\), \\(0.55\\)).\nPara tomar uma decisão (negar crédito, dar remédio), precisamos de um Ponto de Corte (Threshold) \\(c\\) de forma que\n\n\\[\n\\begin{cases}\n  \\pi_i \\geq c \\Rightarrow \\text{Classifica como 1 (Positivo)} \\\\\n  \\pi_i &lt; c \\Rightarrow \\text{Classifica como 0 (Negativo)}\n\\end{cases}\n\\]\n\nPadrão: \\(c = 0.5\\)\nAjustável: Dependendo do problema, podemos subir ou descer a régua."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#avaliação-matriz-de-confusão",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#avaliação-matriz-de-confusão",
    "title": "Regressão Logística",
    "section": "Avaliação: Matriz de Confusão",
    "text": "Avaliação: Matriz de Confusão\nComparação entre o Real e o Predito:\n\n\n\n\n\n\n\n\n\nNegativo Real (0)\nPositivo Real (1)\n\n\n\n\nPredito 0\nVerdadeiro Negativo (VN)\nFalso Negativo (FN)  (Erro Tipo II)\n\n\nPredito 1\nFalso Positivo (FP)  (Erro Tipo I)\nVerdadeiro Positivo (VP)\n\n\n\n\nAcurácia: De tudo que tentei prever, quanto acertei? \\[\\frac{VP + VN}{\\text{Total}}\\]\nCuidado: Acurácia engana em dados desbalanceados!"
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#o-problema-do-desbalanceamento",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#o-problema-do-desbalanceamento",
    "title": "Regressão Logística",
    "section": "O Problema do Desbalanceamento",
    "text": "O Problema do Desbalanceamento\nImagine que usamos corte = 0.5 em dois modelos diferentes.\nCenário Real: Temos muito mais “Zeros” (Bons Pagadores) do que “Uns” (Maus Pagadores).\n\nSe o modelo “chutar” que todo mundo é bom pagador (0):\n\nEle terá altíssima acurácia (ex: 90%).\nMas terá zero capacidade de detectar a fraude/inadimplência (Sensibilidade = 0).\n\n\n\nEm Data Mining, raramente olhamos apenas para Acurácia. Precisamos olhar para Sensibilidade e Precisão."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#curva-roc-e-auc",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#curva-roc-e-auc",
    "title": "Regressão Logística",
    "section": "Curva ROC e AUC",
    "text": "Curva ROC e AUC\n\nComo escolher o melhor ponto de corte \\(c\\)? Não queremos testar um por um manualmente.\nA Curva ROC plota a performance do modelo para TODOS os pontos de corte possíveis.\nEixos:\n\nY: Sensibilidade (Taxa de VP): Capacidade de detectar o evento.\nX: 1 - Especificidade (Taxa de FP): Taxa de alarme falso."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#curva-roc-e-auc-1",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#curva-roc-e-auc-1",
    "title": "Regressão Logística",
    "section": "Curva ROC e AUC",
    "text": "Curva ROC e AUC\n\nA melhor curva é a que “abraça” o canto superior esquerdo.\n\n\nFONTE: Wikipedia."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#interpretando-a-auc-area-under-curve",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#interpretando-a-auc-area-under-curve",
    "title": "Regressão Logística",
    "section": "Interpretando a AUC (Area Under Curve)",
    "text": "Interpretando a AUC (Area Under Curve)\n\nA área abaixo dessa curva resume a qualidade do modelo em um único número.\n\n\n\n\nValor AUC\nInterpretação\n\n\n\n\n0.5\nAleatório (Igual a jogar moeda)\n\n\n0.7 - 0.8\nAceitável\n\n\n0.8 - 0.9\nExcelente\n\n\n&gt; 0.9\nSuspeite de vazamento de dados (Overfitting)\n\n\n\n\nObjetivo: Maximizar a AUC."
  },
  {
    "objectID": "slides/09-regressao_logistica/09-regressao_logistica.html#validação-cruzada-a-regra-de-ouro",
    "href": "slides/09-regressao_logistica/09-regressao_logistica.html#validação-cruzada-a-regra-de-ouro",
    "title": "Regressão Logística",
    "section": "Validação Cruzada (A Regra de Ouro)",
    "text": "Validação Cruzada (A Regra de Ouro)\n\nNunca avaliamos o modelo nos mesmos dados usados para criar os \\(\\beta\\). Isso seria “decorar a prova”.\n\n\nHold-out: Separar 70% Treino / 30% Teste.\nK-Fold Cross Validation:\n\nDivide os dados em \\(k\\) partes (ex: 10).\nTreina em 9, testa em 1.\nRepete 10 vezes e tira a média.\n\n\n\nSó confiamos na métrica (Acurácia/AUC) obtida na base de TESTE."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#objetivo-da-aula",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#objetivo-da-aula",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\n\nCompreender as lógicas centrais dos algoritmos de clusterização particionada, suas medidas de similaridade e robustez;\nDecidir qual método usar diante de diferentes tipos de dados e problemas."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#conceito-central",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#conceito-central",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Conceito Central",
    "text": "Conceito Central\n\nAgrupamento (Clustering) consiste em métodos usados para particionar dados não rotulados em clusters (subgrupos) baseados em similaridade.\nÉ uma técnica não supervisionada que busca identificar padrões emergentes nos dados.\n\n\n\nObjetivos Principais:\n\nAlta similaridade intraclasse: Itens no mesmo cluster são muito semelhantes.\nBaixa similaridade interclasse: Itens em clusters diferentes são muito diferentes.\n\nObservação: Na clusterização, após criados os grupos, o usuário deve analisá-los e criar rótulos que descrevam o agrupamento gerado."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#exemplos-de-aplicação",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#exemplos-de-aplicação",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Exemplos de Aplicação",
    "text": "Exemplos de Aplicação\nSaúde:\n\nAgrupar internações por idade, diagnóstico e tempo de permanência → revelar perfis clínicos de pacientes e apoiar políticas hospitalares regionais.\n\nFinanças:\n\nAgrupar clientes por renda, histórico de crédito e uso de produtos → identificar perfis de risco e consumo financeiro.\n\nMunicípios:\n\nAgrupar cidades por indicadores socioeconômicos, educacionais e de infraestrutura → mapear padrões territoriais de vulnerabilidade.\n\n\nCada cluster representa um padrão real que surge dos dados — e a escolha do método define quão bem conseguimos enxergá-los."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#tipos-de-agrupamento",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#tipos-de-agrupamento",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Tipos de Agrupamento",
    "text": "Tipos de Agrupamento\nA clusterização pode ser classificada por sua estrutura e regras:\n\n\nHierárquica vs. Particionada\n\nHierárquica: Os clusters podem estar contidos dentro de outros clusters.\nParticionada: O limite de cada cluster é independente do outro.\n\n\n\n\n\n\n\nExclusiva vs. Sobreposta\n\nExclusiva: Um item pertence apenas a um único cluster.\nSobreposta: Cada item pode pertencer a um ou mais clusters.\n\n\n\n\n\n\n\nCompleta vs. Parcial\n\nCompleta: Todos os itens devem pertencer a pelo menos um cluster.\nParcial: Itens atípicos (outliers) podem não ser atribuídos a nenhum cluster."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#problema-central-o-protótipo",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#problema-central-o-protótipo",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Problema Central: O Protótipo",
    "text": "Problema Central: O Protótipo\nNosso foco será em agrupamento particionado. A lógica central desses métodos é:\n\nEscolher \\(k\\) “centros” (chamados de protótipos).\nAtribuir cada ponto de dado ao protótipo mais próximo.\nAtualizar a posição de cada protótipo com base nos pontos que lhe foram atribuídos.\nRepetir os passos 2 e 3 até que os grupos não mudem mais (convergência).\n\n Cada método de clusterização particionada é uma combinação diferente da resposta a duas perguntas:\n\nO que é o “protótipo”? → definição do centro (média, mediana, medoide, moda…)\nComo medir “proximidade”? → escolha da métrica de distância (Euclidiana, Manhattan, Gower…)"
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#mapa-mental-que-tipo-de-dado-eu-tenho",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#mapa-mental-que-tipo-de-dado-eu-tenho",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Mapa Mental: Que tipo de dado eu tenho?",
    "text": "Mapa Mental: Que tipo de dado eu tenho?\n\nA escolha do algoritmo e da medida de distância depende da natureza dos seus dados.\nA pergunta-chave é:\n\nCaso 1: Meus dados são TODOS NUMÉRICOS? (Ex: Idade, Renda, Temperatura)\nCaso 2: Meus dados são TODOS CATEGÓRICOS? (Ex: Região, Sexo, Tipo Sanguíneo)\nCaso 3: Meus dados são MISTOS? (Ex: Idade, Renda, Região, Sexo)\n\n\n\n\nVejamos como lidar com cada caso."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#algoritmo-padrão-k-means-k-médias",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#algoritmo-padrão-k-means-k-médias",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Algoritmo Padrão: K-Means (K-Médias)",
    "text": "Algoritmo Padrão: K-Means (K-Médias)\nO K-means é o ponto de partida clássico para dados numéricos.\n\nAplicação: Dados numéricos.\nCentro (Protótipo): A Média de todos os pontos do cluster.\nMétrica (Distância): Distância Euclidiana.\n\n\n\nEsta abordagem é classificada como:\n\nParticionada (limites independentes)\nExclusiva (um item, um cluster)\nCompleta (todos os itens são atribuídos)\n\nO usuário define o número de clusters (\\(k\\)) que o conjunto de dados terá."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-métrica-de-distância-utilizada-euclidiana",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-métrica-de-distância-utilizada-euclidiana",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Means: Métrica de Distância Utilizada (Euclidiana)",
    "text": "K-Means: Métrica de Distância Utilizada (Euclidiana)\n\nA distância Euclidiana (L2) é a métrica padrão do K-means.\nEla mede a “linha reta” entre dois pontos no espaço vetorial.\nSejam \\(a=(a_1, \\ldots, a_p)\\) e \\(b=(b_1, \\ldots, b_p)\\) duas observações, então\n\n\\[\n  \\text{dist}_E(a,b) = \\sqrt{(a_1-b_1)^2 +(a_2-b_2)^2 + \\cdots + (a_p-b_p)^2}.\n\\]\nAtenção!\n\nPadronize variáveis antes do cálculo: isto evita que uma variável (ex: Salário) domine o resultado sobre outra (ex: Idade).\nA elevação ao quadrado \\((x^2)\\) torna esta medida muito sensível a outliers."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-definição-do-centro-centróide",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-definição-do-centro-centróide",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Means: Definição do Centro (Centróide)",
    "text": "K-Means: Definição do Centro (Centróide)\n\nO centróide de um cluster obtido via K-means é a média das coordenadas de todos os pontos do cluster. \\[\n\\text{centroide}(x,y,z) = \\left( \\frac{x_1+y_1+z_1}{3}, \\frac{x_2+y_2+z_2}{3} \\right)\n\\]\nPonto Crítico: Como se baseia em médias, o centróide é altamente sensível a valores extremos (outliers), que podem deslocar o centro de massa do cluster."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-funcionamento",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-funcionamento",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Means: Funcionamento",
    "text": "K-Means: Funcionamento\nSuponha \\(k=3\\).\n\nO algoritmo escolhe \\(k\\) pontos aleatórios que servem como centros dos clusters iniciais.\nO algoritmo calcula a distância (Euclidiana) de cada item aos centros e atribui o item ao cluster cujo centro está mais próximo."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-funcionamento-1",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-funcionamento-1",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Means: Funcionamento",
    "text": "K-Means: Funcionamento\n\nApós atribuir cada item a um cluster, o algoritmo calcula o novo centróide (a média) de cada cluster formado.\nO algoritmo recalcula a distância de cada item a cada novo centróide e o reatribui ao cluster mais próximo."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-funcionamento-2",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-funcionamento-2",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Means: Funcionamento",
    "text": "K-Means: Funcionamento\n\nO processo de atribuição e avaliação é repetido, com novos centróides calculados para cada cluster e cada item é reatribuído ao cluster mais próximo."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-funcionamento-3",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-means-funcionamento-3",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Means: Funcionamento",
    "text": "K-Means: Funcionamento\n\nEm algum momento, os centróides não mudarão mais de lugar e não resultarão em novas atribuições.\n\nNesse ponto dizemos que o algoritmo convergiu e o processo é interrompido."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#ponto-fraco-do-k-means-outliers",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#ponto-fraco-do-k-means-outliers",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Ponto Fraco do K-Means: Outliers",
    "text": "Ponto Fraco do K-Means: Outliers\n\nO K-Means minimiza a soma dos quadrados das distâncias (associado à Distância Euclidiana L2).\nO centróide (baseado na média) é o ponto de equilíbrio.\nUm único outlier age como um “peso” muito grande, “puxando” o centróide em sua direção, pois sua grande distância é elevada ao quadrado.\nPrecisamos então de alternativas robustas quando há outliers nos dados."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#solução-robusta-1-k-medians-k-medianas",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#solução-robusta-1-k-medians-k-medianas",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Solução Robusta 1: K-Medians (K-medianas)",
    "text": "Solução Robusta 1: K-Medians (K-medianas)\n\nAplicação: Dados numéricos com outliers.\nCentro (Protótipo): A Mediana de cada variável. O centro é calculado.\nMétrica (Distância): Distância de Manhattan (L1).\nVantagem: A Mediana é muito mais robusta a outliers do que a Média."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-medians-a-métrica-métrica-de-distância-utilizada-manhattan",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-medians-a-métrica-métrica-de-distância-utilizada-manhattan",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Medians: A Métrica Métrica de Distância Utilizada (Manhattan)",
    "text": "K-Medians: A Métrica Métrica de Distância Utilizada (Manhattan)\n\nA distância de Manhattan (L1) mede a distância como sendo a soma das diferenças absolutas (“caminho dos quarteirões”).\nSejam \\(a=(a_1, \\ldots, a_p)\\) e \\(b=(b_1, \\ldots, b_p)\\) duas observações, então\n\n\\[\n  \\text{dist}_M(a,b) = |a_1-b_1| + |a_2-b_2| + \\cdots + |a_p-b_p|.\n\\]\nPor que é robusta?\n\nNão eleva as diferenças ao quadrado.\nDiferenças grandes (causadas por outliers) têm um peso linear, e não quadrático.\nO K-Medians, ao usar L1, é naturalmente menos afetado por pontos extremos."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#solução-robusta-2-k-medoids-pam",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#solução-robusta-2-k-medoids-pam",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Solução Robusta 2: K-Medoids (PAM)",
    "text": "Solução Robusta 2: K-Medoids (PAM)\n\nAplicação: Dados numéricos com outliers.\nCentro (Protótipo): Um Ponto Real (o medoide). O centro é eleito.\nMétrica (Distância): Qualquer uma!\nComo o centro é eleito? O medoide é o ponto real cuja distância total aos demais pontos do seu cluster é a mínima. \\[\n\\text{medoide} = \\arg\\min_{x_i \\in C} \\sum_{x_j \\in C} d(x_i, x_j)\n\\]\n\n\nO método também é chamado de PAM (Partitioning Around Medoids – Particionamento em Torno de Medoides)"
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-medoids-vs.-k-medians-a-vantagem-interpretabilidade",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-medoids-vs.-k-medians-a-vantagem-interpretabilidade",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Medoids vs. K-Medians: A Vantagem (Interpretabilidade)",
    "text": "K-Medoids vs. K-Medians: A Vantagem (Interpretabilidade)\n\n\n\n\n\n\n\nK-Medians (Centro Calculado)\nK-Medoids (Centro Real)\n\n\n\n\nO centro é a mediana de cada variável.\nO centro é um ponto real dos dados.\n\n\nO protótipo (med_x, med_y) pode não existir na sua base de dados.\nO protótipo é, por exemplo, o Cliente B (ID 456).\n\n\nInterpretação (Fraca): “O Cluster 1 representa clientes com idade mediana de 25 e salário mediano de R$ 1200.”\nInterpretação (Forte): “O Cluster 1 é representado pelo Cliente B, que tem 25 anos e salário de R$ 1200.”"
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-medoids-vs.-k-medians-a-vantagem-flexibilidade",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-medoids-vs.-k-medians-a-vantagem-flexibilidade",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Medoids vs. K-Medians: A Vantagem (Flexibilidade)",
    "text": "K-Medoids vs. K-Medians: A Vantagem (Flexibilidade)\n\nK-Medians está intrinsecamente ligado à otimização da Distância Manhattan (L1). \nK-Medoids pode usar QUALQUER medida de distância:\n\nDistância Euclidiana (L2)\nDistância Manhattan (L1)\nDistância de Gower (para dados mistos - vamos ver adiante!)\n\nIsso torna o K-Medoids a ferramenta mais poderosa e flexível para dados complexos."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#resumo-clusterização-de-dados-numéricos",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#resumo-clusterização-de-dados-numéricos",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Resumo: Clusterização de Dados Numéricos",
    "text": "Resumo: Clusterização de Dados Numéricos\n\n\n\n\n\n\n\n\n\n\nComparação   \nK-means           \nK-medians         \nK-medoids           \n\n\n\n\nCentro       \nMédia             \nMediana           \nPonto real (medoide)\n\n\nDistância     \nEuclidiana (L2)   \nManhattan (L1)   \nQualquer (Gower!) \n\n\nRobustez* a outlier\nBaixa             \nMédia             \nAlta                 \n\n\nPonto real?   \nNão (calculado)   \nNão (calculado)   \nSim (eleito)     \n\n\nQuando usar   \nDados numéricos limpos\nDados numéricos com outliers\nDados com outliers ou mistos"
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#o-problema-com-dados-categóricos",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#o-problema-com-dados-categóricos",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "O Problema com Dados Categóricos",
    "text": "O Problema com Dados Categóricos\n\nProblema: Agrupar dados como (Sexo, Região, Plano de Saúde).\nMétricas como a Distância Euclidiana ou de Manhattan não funcionam. Não podemos calcular algo como:\n\n\\[\n\\sqrt{(\\text{'Nordeste'} - \\text{'Sul'})^2 + (\\text{'Público'} - \\text{'Privado'})^2}\n\\]\n\nPrecisamos de uma métrica e um centro que funcionem para categorias."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#a-métrica-distância-de-hamming-ou-dissimilaridade-simples",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#a-métrica-distância-de-hamming-ou-dissimilaridade-simples",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "A Métrica: Distância de Hamming (ou Dissimilaridade Simples)",
    "text": "A Métrica: Distância de Hamming (ou Dissimilaridade Simples)\n\nA Distância de Hamming é usada quando todas as variáveis são categóricas (nominais).\nEla mede quantas categorias diferem entre duas observações.\nSejam \\(a=(a_1, a_2, \\ldots, a_p)\\) e \\(b=(b_1, b_2, \\ldots, b_p)\\) duas observações, então \\[\n\\text{dist}_H(a,b) = I(a_1\\neq b_1) + I(a_2\\neq b_2) + \\cdots + I(a_p\\neq b_p)\n\\] em que \\(I(a_i\\neq a_i) = 1\\) se as categorias forem diferentes, e 0 se forem iguais."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#distância-de-hamming-exemplo",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#distância-de-hamming-exemplo",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Distância de Hamming: Exemplo",
    "text": "Distância de Hamming: Exemplo\n\n\n\n\nAtributo     \nPaciente A\nPaciente B\nDiferença\n\n\n\n\nSexo         \nM         \nF         \n1         \n\n\nRegião       \nNordeste   \nNordeste   \n0         \n\n\nTipo de Plano\nPúblico   \nPrivado   \n1         \n\n\nTotal     \n           \n           \n2     \n\n\n\n\nDistância Hamming = 2 (duas categorias diferentes)."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#algoritmo-para-dados-categóricos-k-modes",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#algoritmo-para-dados-categóricos-k-modes",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Algoritmo para Dados Categóricos: K-Modes",
    "text": "Algoritmo para Dados Categóricos: K-Modes\n\nO K-modes é uma extensão do K-means para dados puramente categóricos.\nAplicação: Dados Categóricos (nominais).\nCentro (Protótipo): A Moda de cada variável (o modo).\nMétrica (Distância): Distância de Hamming."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-modes-o-centro-modo",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-modes-o-centro-modo",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Modes: O Centro (Modo)",
    "text": "K-Modes: O Centro (Modo)\n\nNo K-modes, o protótipo (centro) do cluster não é uma média, mas sim o vetor das categorias mais frequentes (a moda) encontradas no cluster.\nExemplo de Cálculo do Modo (Protótipo) para um Cluster:\n\n\n\n\n\n\n\n\n\nVariável\nMembros do Cluster\nModa (Centro)\n\n\n\n\nRegião\nNordeste, Nordeste, Sul, Nordeste, Sudeste\nNordeste (3/5)\n\n\nPlano\nPúblico, Privado, Público, Público, Privado\nPúblico (3/5)\n\n\nSexo\nM, F, F, M, F\nF (3/5)\n\n\n\n\nO protótipo (modo) deste cluster é o vetor: (\"Nordeste\", \"Público\", \"F\").\nO algoritmo atribui novos pontos com base em quantas categorias eles diferem deste protótipo (Distância de Hamming)."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-modes-vantagens-e-limitações",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-modes-vantagens-e-limitações",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Modes: Vantagens e Limitações",
    "text": "K-Modes: Vantagens e Limitações\n\nUso:\n\nBases com apenas variáveis nominais (ex.: diagnóstico primário, modalidade de serviço, ocupação).\n\nVantagens:\n\nRápido e simples.\nInterpretação direta (o “perfil modal” de cada cluster é muito claro).\n\nLimitações:\n\nNão trata variáveis numéricas (ex: Idade).\nNão trata variáveis ordinais de forma natural (ex: Escolaridade)."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#o-problema-com-dados-mistos",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#o-problema-com-dados-mistos",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "O Problema com Dados Mistos",
    "text": "O Problema com Dados Mistos\n\nProblema: Agrupar itens usando variáveis numéricas e categóricas como Idade, Renda, Gênero, Região.\nNesses casos K-Means e K-Modes falham. Precisamos de soluções híbridas.\nTemos duas estratégias principais:\n\nRobusta (Gower + K-Medoids): Usa um algoritmo robusto com uma métrica de distância flexível.\nRápida (K-Prototypes): Usa um algoritmo híbrido que combina K-Means e K-Modes."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#solução-1-robusta-gower-k-medoids",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#solução-1-robusta-gower-k-medoids",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Solução 1 (Robusta): Gower + K-Medoids",
    "text": "Solução 1 (Robusta): Gower + K-Medoids\nUsamos como métrica a Distância de Gower\n\nA Distância de Gower é usada quando os dados são mistos: variáveis numéricas, categóricas, binárias ou ordinais.\nResulta em valores entre 0 e 1 (0 = iguais, 1 = completamente diferentes).\nA dissimilaridade entre duas observações \\(i\\) e \\(j\\) com \\(p\\) atributos é dada por: \\[\nD_{ij} = \\frac{w_{ij1} d_{ij1} + w_{ij2} d_{ij2} + \\cdots + w_{ijp} d_{ijp}}{w_{ij1}+ w_{ij2} + \\cdots + w_{ijp}},\n\\] em que \\(w_{ijk}\\) é o peso (geralmente 1) e \\(d_{ijk}\\) é a dissimilaridade para o \\(k\\)-ésimo atributo:\n\nse o atributo é categórico ou binário, \\(d_{ijk} = I(x_{ik}\\neq x_{jk})\\);\nse o atributo é numérico, \\(d_{ijk} = 1 - \\frac{|x_i-x_j|}{R_k}\\), sendo \\(R_k\\) a amplitude (max-min) da variável \\(k\\)."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#solução-1-robusta-gower-k-medoids-1",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#solução-1-robusta-gower-k-medoids-1",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Solução 1 (Robusta): Gower + K-Medoids",
    "text": "Solução 1 (Robusta): Gower + K-Medoids\n\nAplicação: Dados Mistos.\nCentro (Protótipo): Ponto Real (medoide).\nMétrica (Distância): Distância de Gower.\n\n\n\nComo K-Medoids funciona com qualquer matriz de distância, fazemos o seguinte:\n\nCalculamos a matriz de dissimilaridade \\(N \\times N\\) entre todos os pontos usando Gower.\nFornecemos essa matriz ao algoritmo K-Medoids (PAM).\nO K-Medoids elegerá os pontos reais mais centrais com base nessa distância mista."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#gower-k-medoids-vantagens-e-limitações",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#gower-k-medoids-vantagens-e-limitações",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Gower + K-Medoids: Vantagens e Limitações",
    "text": "Gower + K-Medoids: Vantagens e Limitações\nVantagens:\n\nA solução mais robusta e flexível.\nTrata todos os tipos de variáveis (numéricos, categóricos, ordinais) corretamente.\nRobusto a outliers (medoide é ponto real).\nInterpretação ótima (medoide = observação representativa).\n\nLimitações:\n\nCusto Computacional: A matriz de Gower \\(N \\times N\\) pode ser custosa (memória e tempo) para datasets com N grande (ex: N &gt; 10.000).\nComplexidade elevada (O(\\(N^2\\))): o tempo de execução ou o uso de memória cresce quadraticamente conforme o número de observações aumenta."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#solução-2-rápida-k-prototypes",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#solução-2-rápida-k-prototypes",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Solução 2 (Rápida): K-Prototypes",
    "text": "Solução 2 (Rápida): K-Prototypes\n\nO K-prototypes une K-means (para variáveis numéricas) e K-modes (para variáveis categóricas).\n\n\n\nAplicação : Dados Mistos.\nCentro (Protótipo): Híbrido!\n\nMédia para variáveis numéricas.\nModa para variáveis categóricas.\n\nMétrica (Distância): Híbrida (Euclidiana + Hamming)."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-prototypes-a-métrica-híbrida",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#k-prototypes-a-métrica-híbrida",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "K-Prototypes: A Métrica Híbrida",
    "text": "K-Prototypes: A Métrica Híbrida\n\nA distância é uma soma ponderada das distâncias numéricas e categóricas.\n\\(\\text{dist}(a, b) = \\sum (a_i - b_i)^2 + \\gamma \\sum I(a_j \\neq b_j)\\)\n\n\\(\\sum (a_i - b_i)^2\\): Parte Numérica (Dist. Euclidiana ao Quadrado)\n\\(\\sum I(a_j \\neq b_j)\\): Parte Categórica (Dist. Hamming)\n\\(\\gamma\\): Um peso (parâmetro) que define a importância da parte categórica.\n\n\nVantagens:\n\nEscala bem: Não precisa de matriz N×N. Excelente para grandes bases mistas.\nInterpretação direta (protótipo = perfil de médias + modas).\n\nLimitações:\n\nA parte numérica (K-Means) ainda é sensível a outliers.\nVariáveis ordinais são tratadas como categóricas (perda de ordem).\nO parâmetro \\(\\gamma\\) exige ajuste/escolha."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#como-definir-o-número-de-clusters-escolher-k",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#como-definir-o-número-de-clusters-escolher-k",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Como definir o número de clusters (escolher \\(k\\))?",
    "text": "Como definir o número de clusters (escolher \\(k\\))?\n\nSuponha que escolhemos o método (ex: K-Means). Mas quantos clusters (\\(k\\)) devemos criar?\n\\(k=2\\)? \\(k=3\\)? \\(k=10\\)?\nEsta é a pergunta mais comum em agrupamento.\nNão há uma resposta única “correta”, mas sim métodos que ajudam a encontrar um \\(k\\) “ótimo”.\nVeremos três dos mais usados:\n\nMétodo do Cotovelo (Elbow Method)\nMétodo da Silhueta Média (Average Silhouette)\nEstatística Gap (Gap Statistic)"
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-1-cotovelo-elbow-method",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-1-cotovelo-elbow-method",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Método 1: Cotovelo (Elbow Method)",
    "text": "Método 1: Cotovelo (Elbow Method)\n\nA ideia é testar vários valores de \\(k\\) e calcular a Soma dos Quadrados Intra-clusters (Within-Cluster Sum of Squares, \\(WCSS\\)).\n\\(WCSS\\) mede a compactação (homogeneidade) total dos clusters. \\[\nWCSS_k = \\sum_{\\text{cluster } 1} \\text{dist}(P_i, C_1)^2 + \\sum_{\\text{cluster } 2} \\text{dist}(P_i, C_2)^2 + \\cdots\n\\]\nQuanto mais \\(k\\), menor o \\(WCSS\\) (naturalmente, \\(WCSS=0\\) se \\(k=N\\)).\nProcuramos o \\(k\\) onde a redução do \\(WCSS\\) começa a diminuir drasticamente: o “cotovelo” da curva.\nÉ o ponto de equilíbrio: aumentar \\(k\\) não traz melhora significativa."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-1-cotovelo-elbow-method-1",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-1-cotovelo-elbow-method-1",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Método 1: Cotovelo (Elbow Method)",
    "text": "Método 1: Cotovelo (Elbow Method)"
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-2-silhueta-média-average-silhouette",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-2-silhueta-média-average-silhouette",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Método 2: Silhueta Média (Average Silhouette)",
    "text": "Método 2: Silhueta Média (Average Silhouette)\n\nMede o grau de coesão e separação dos clusters. Avalia o quão bem cada item está posicionado.\nPara cada observação \\(i\\), calcula-se \\(S(i) = \\frac{b(i) - a(i)}{\\max\\{ a(i), b(i) \\}}\\)\n\n\\(a(i)\\): distância média de \\(i\\) aos pontos do mesmo cluster (coesão).\n\\(b(i)\\): distância média de \\(i\\) aos pontos do cluster vizinho mais próximo (separação).\n\n\\(S(i)\\) varia de -1 a 1:\n\n\\(\\approx 1\\): Item bem ajustado (ideal).\n\\(\\approx 0\\): Item na fronteira entre clusters.\n\\(&lt; 0\\): Item provavelmente no cluster errado.\n\nO \\(k\\) ótimo é aquele que maximiza a Silhueta Média de todas as observações."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-2-silhueta-média-average-silhouette-1",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-2-silhueta-média-average-silhouette-1",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Método 2: Silhueta Média (Average Silhouette)",
    "text": "Método 2: Silhueta Média (Average Silhouette)"
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-3-estatística-gap",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-3-estatística-gap",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Método 3: Estatística Gap",
    "text": "Método 3: Estatística Gap\n\nCompara a dispersão observada (\\(WCSS_k\\)) com a dispersão esperada sob uma distribuição de referência aleatória (sem clusters).\nA ideia é: \\(k\\) é bom se a compactação dos nossos clusters for muito melhor do que uma compactação aleatória.\n\n\nPara cada \\(k\\), calcule \\(\\log(WCSS_k)\\) dos dados originais.\nGere \\(B\\) amostras aleatórias (uniformes) e calcule a média de \\(\\log(WCSS^{*b}_k)\\).\nA Estatística Gap é a diferença: \\[\n  Gap(k) = E[\\log(WCSS^{*b}_k)] - \\log(WCSS_k)\n\\]\n\n\nProcuramos o \\(k\\) que maximiza o \\(Gap(k)\\)."
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-3-estatística-gap-1",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#método-3-estatística-gap-1",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Método 3: Estatística Gap",
    "text": "Método 3: Estatística Gap"
  },
  {
    "objectID": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#para-definir-o-algoritmo-de-agrupamento",
    "href": "slides/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados/06-agrupamento_de_dados_com_k-means_e_metodos_relacionados.html#para-definir-o-algoritmo-de-agrupamento",
    "title": "Agrupamento de Dados com k-means e Métodos Relacionados",
    "section": "Para definir o algoritmo de agrupamento",
    "text": "Para definir o algoritmo de agrupamento\n\n\nE para encontrar \\(k\\), use métodos de validação como Cotovelo (WCSS), Silhueta ou Estatística Gap."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#objetivo-da-aula",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#objetivo-da-aula",
    "title": "Regras de Associação",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\n\nCompreender o problema da Análise de Cesta de Mercado e o conceito de Regras de Associação no formato SE (Antecedente) \\(\\rightarrow\\) ENTÃO (Consequente).\nDominar as métricas fundamentais (Suporte, Confiança e Lift) para filtrar e avaliar a força e o interesse dos padrões de afinidade entre itens.\nEntender o funcionamento do Algoritmo Apriori e a estratégia FP-Growth para a mineração eficiente de itemsets frequentes em grandes volumes de dados de transações."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#o-problema-análise-de-cesta-de-mercado",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#o-problema-análise-de-cesta-de-mercado",
    "title": "Regras de Associação",
    "section": "O Problema: Análise de Cesta de Mercado",
    "text": "O Problema: Análise de Cesta de Mercado\nAs Regras de Associação nasceram da necessidade de entender o comportamento de consumo. O problema clássico é a Análise de Cesta de Mercado (Market Basket Analysis).\n\nPergunta: Quais itens os clientes tendem a comprar juntos?\nObjetivo: Identificar padrões de afinidade para otimizar layout de loja, criar promoções (ex: “compre X e Y, ganhe desconto”), e planejar o inventário.\n\nDefinições Formais\n\nItem: Um produto (ex: Pão, Leite, Fralda).\nTransação: Uma única “cesta de compras” (ex: T1, T2, …).\nItemset (Conjunto de Itens): Uma coleção de 1 ou mais itens (ex: {Leite, Fralda})."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#o-problema-análise-de-cesta-de-mercado-1",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#o-problema-análise-de-cesta-de-mercado-1",
    "title": "Regras de Associação",
    "section": "O Problema: Análise de Cesta de Mercado",
    "text": "O Problema: Análise de Cesta de Mercado\nExemplo Base (N=5 Transações)\nVamos usar esta base de dados para todos os nossos cálculos:\n\n\n\n\n\n\n\n\n\n\n\n\nTransação (TID)\nPão\nLeite\nCerveja\nFralda\nOvos\nRefrigerante\n\n\n\n\nT1\n1\n1\n1\n0\n0\n0\n\n\nT2\n1\n0\n1\n1\n1\n0\n\n\nT3\n0\n1\n1\n1\n0\n1\n\n\nT4\n1\n1\n1\n1\n0\n0\n\n\nT5\n1\n1\n0\n1\n0\n1\n\n\nTotal (N=5)\n4\n4\n3\n4\n1\n2"
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-regra",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-regra",
    "title": "Regras de Associação",
    "section": "A Regra",
    "text": "A Regra\nUma Regra de Associação tem o formato SE \\(\\rightarrow\\) ENTÃO:\n\\[\n\\text{Antecedente} \\rightarrow \\text{Consequente}\n\\] \\[\n\\{X\\} \\rightarrow \\{Y\\}\n\\]\n\nO Antecedente (X) é um itemset.\nO Consequente (Y) é um itemset.\nRestrição: \\(X\\) e \\(Y\\) são disjuntos (\\(X \\cap Y = \\emptyset\\)).\nExemplo: A regra \\(\\{\\text{Cerveja, Fralda}\\} \\rightarrow \\{\\text{Pão}\\}\\) sugere que clientes que compram Cerveja e Fralda também tendem a comprar Pão."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-regra-1",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-regra-1",
    "title": "Regras de Associação",
    "section": "A Regra",
    "text": "A Regra\nO Desafio Computacional\nCom \\(p\\) itens distintos, o número total de regras possíveis é \\(3^p - 2^{p+1} + 1\\).\n\nPara 6 itens (nosso exemplo): \\(3^6 - 2^7 + 1 = 602\\) regras.\nPara 50 itens (mercearia pequena): \\(1.125 \\times 10^{15}\\) (mais de 1 quatrilhão) de regras.\n\nConclusão: Não podemos avaliar todas. Precisamos de métricas para filtrar e encontrar apenas as regras “fortes” ou “interessantes”."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais",
    "title": "Regras de Associação",
    "section": "Métricas Fundamentais",
    "text": "Métricas Fundamentais\nPara uma regra \\(\\{X\\} \\rightarrow \\{Y\\}\\), usamos três métricas principais.\n1. Suporte (Relevância)\nO Suporte mede a frequência ou popularidade de um itemset no banco de dados.\n\\[\nSuporte(X) = P(X) = \\frac{\\text{Nº de transações contendo o itemset } X}{\\text{Total de transações (N)}}\n\\]\n\nSuporte da Regra: O suporte de uma regra \\(\\{X\\} \\rightarrow \\{Y\\}\\) é o suporte do itemset que contém ambos os lados. \\[\n  Suporte(X \\rightarrow Y) = Suporte(X \\cup Y) = P(X \\cap Y)\n  \\]"
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-1",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-1",
    "title": "Regras de Associação",
    "section": "Métricas Fundamentais",
    "text": "Métricas Fundamentais\n1. Suporte (Relevância)\nUsando nossa tabela (N=5):\n\nSuporte de 1 item:\n\n\\(Suporte(\\{\\text{Pão}\\}) = 4/5 = 0.8\\)\n\\(Suporte(\\{\\text{Leite}\\}) = 4/5 = 0.8\\)\n\\(Suporte(\\{\\text{Cerveja}\\}) = 4/5 = 0.8\\)\n\\(Suporte(\\{\\text{Fralda}\\}) = 4/5 = 0.8\\)\n\nSuporte de Itemset (2 itens):\n\nItemset: \\(\\{\\text{Cerveja, Leite}\\}\\)\nOcorrências: T1, T3, T4 (3 transações)\n\\(Suporte(\\{\\text{Cerveja, Leite}\\}) = 3/5 = 0.6\\)"
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-2",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-2",
    "title": "Regras de Associação",
    "section": "Métricas Fundamentais",
    "text": "Métricas Fundamentais\n1. Suporte (Relevância)\nUsando nossa tabela (N=5):\n\nSuporte de Itemset (3 itens):\n\nItemset: \\(\\{\\text{Cerveja, Leite, Fralda}\\}\\)\nOcorrências: T3, T4 (2 transações)\n\\(Suporte(\\{\\text{Cerveja, Leite, Fralda}\\}) = 2/5 = 0.4\\)"
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-3",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-3",
    "title": "Regras de Associação",
    "section": "Métricas Fundamentais",
    "text": "Métricas Fundamentais\n2. Confiança (Precisão)\nA Confiança mede a probabilidade de o Consequente (Y) aparecer, dado que o Antecedente (X) já apareceu. É uma medida de probabilidade condicional, \\(P(Y|X)\\).\n\\[\nConfiança(X \\rightarrow Y) = P(Y|X) = \\frac{Suporte(X \\cup Y)}{Suporte(X)}\n\\]\n\nInterpretação: “De todas as vezes que X foi comprado, em qual percentual Y também foi comprado?”"
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-4",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-4",
    "title": "Regras de Associação",
    "section": "Métricas Fundamentais",
    "text": "Métricas Fundamentais\n2. Confiança (Precisão)\nCálculo (Regra: \\(\\{\\text{Cerveja, Leite}\\} \\rightarrow \\{\\text{Fralda}\\}\\))\n\\[\n  \\begin{aligned}\n    Confiança(\\{\\text{Cerveja, Leite}\\} \\rightarrow \\{\\text{Fralda}\\}) &= \\frac{Suporte(\\{\\text{Cerveja, Leite, Fralda}\\})}{Suporte(\\text{{Cerveja, Leite}})}\\\\\n    &= \\frac{2/5}{3/5} = 0.67\n  \\end{aligned}\n\\]\n\nInterpretação: “67% dos clientes que compraram Cerveja e Leite também compraram Fralda.”"
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-5",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-5",
    "title": "Regras de Associação",
    "section": "Métricas Fundamentais",
    "text": "Métricas Fundamentais\n2. Confiança (Precisão)\n\nA Confiança pode ser enganosa.\nImagine a regra \\(\\{\\text{Qualquer Coisa}\\} \\rightarrow \\{\\text{Pão}\\}\\).\nSe “Pão” for um item extremamente popular (ex: \\(Suporte(\\{\\text{Pão}\\}) = 95\\%\\)), quase qualquer regra apontando para “Pão” terá uma Confiança alta.\nIsso não significa que o Antecedente “causa” a compra do Pão; significa apenas que o Pão é comprado o tempo todo, independentemente.\nPrecisamos de uma métrica que desconte a popularidade do Consequente."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-6",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-6",
    "title": "Regras de Associação",
    "section": "Métricas Fundamentais",
    "text": "Métricas Fundamentais\n3. Lift (Interesse / “Poder de Tração”)\nO Lift mede o quão mais (ou menos) provável é que X e Y ocorram juntos do que se fossem estatisticamente independentes. É o “teste” de interesse da regra.\n\\[\nLift(X \\rightarrow Y) = \\frac{Confiança(X \\rightarrow Y)}{Suporte(Y)} = \\frac{P(Y|X)}{P(Y)}\n\\] Forma alternativa (e simétrica): \\[\nLift(X \\rightarrow Y) = \\frac{P(X\\cup Y)}{P(X)P(Y)} = \\frac{Suporte(X \\cup Y)}{Suporte(X) \\times Suporte(Y)}\n\\]"
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-7",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-7",
    "title": "Regras de Associação",
    "section": "Métricas Fundamentais",
    "text": "Métricas Fundamentais\n3. Lift (Interesse / “Poder de Tração”)\n\nInterpretação do Lift:\n\nLift = 1: Independência. A ocorrência de X não altera a probabilidade de Y. A regra é inútil.\nLift &gt; 1: Associação positiva. X e Y aparecem juntos mais do que o esperado. X “puxa” Y. (Interessante!)\nLift &lt; 1: Associação negativa. X e Y aparecem juntos menos do que o esperado. X “inibe” Y. (Também interessante!)"
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-8",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-fundamentais-8",
    "title": "Regras de Associação",
    "section": "Métricas Fundamentais",
    "text": "Métricas Fundamentais\n3. Lift (Interesse / “Poder de Tração”)\nCálculo (Regra: \\(\\{\\text{Cerveja, Leite}\\} \\rightarrow \\{\\text{Fralda}\\}\\))\n\n\\(Confiança(X \\rightarrow Y) = 2/3\\)\n\\(Suporte(Y) = Suporte(\\{\\text{Fralda}\\}) = 4/5\\)\n\\(Lift = (2/3) / (4/5) = (2/3) \\times (5/4) = 10/12 \\approx 0.833\\)\nInterpretação: O Lift é menor que 1. Isso significa que clientes que compram {Cerveja, Leite} são, na verdade, um pouco menos prováveis (cerca de 17% menos prováveis) de comprar Fralda do que um cliente aleatório.\nConclusão da Regra: Embora a Confiança de 67% parecesse alta, o Lift nos mostra que esta regra não é acionável e a associação é, na verdade, negativa."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-adicionais",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-adicionais",
    "title": "Regras de Associação",
    "section": "Métricas Adicionais",
    "text": "Métricas Adicionais\nPara uma análise de nível sênior, Lift, Suporte e Confiança são o mínimo. Duas outras métricas dão uma visão mais completa:\n\nLeverage (Alavancagem):\n\n\\(Leverage(X \\rightarrow Y) = Suporte(X \\cup Y) - (Suporte(X) \\times Suporte(Y))\\)\nO que mede: A diferença absoluta entre a frequência observada de (X e Y) e a frequência esperada se fossem independentes.\nInterpretação: Um valor de 0 indica independência. Um valor positivo indica quantos mais transações (em proporção) contêm X e Y do que o esperado. É útil para medir o impacto em números absolutos, não apenas relativos."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-adicionais-1",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#métricas-adicionais-1",
    "title": "Regras de Associação",
    "section": "Métricas Adicionais",
    "text": "Métricas Adicionais\n\nConviction (Convicção):\n\n\\(Conviction(X \\rightarrow Y) = \\frac{1 - Suporte(Y)}{1 - Confiança(X \\rightarrow Y)}\\)\nO que mede: O grau de “erro” que a regra faria se a associação não existisse. Mede o quão dependente o Consequente é do Antecedente.\nInterpretação: Uma Convicção alta significa que o Consequente (Y) raramente aparece sem o Antecedente (X). É uma medida de direcionalidade muito mais forte que o Lift."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#classificando-as-regras-o-que-fazer",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#classificando-as-regras-o-que-fazer",
    "title": "Regras de Associação",
    "section": "Classificando as Regras (O Que Fazer)",
    "text": "Classificando as Regras (O Que Fazer)\nO objetivo não é apenas encontrar regras, mas classificá-las quanto à utilidade:\n\nAcionáveis: Regras com bom Suporte, Confiança e Lift &gt; 1. Elas fornecem insights claros que podem ser aplicados (ex: “Coloque o {Achocolatado} perto do {Leite Condensado}”).\nTriviais: Regras que são óbvias para qualquer especialista no domínio (ex: \\(\\{\\text{Caneta}\\} \\rightarrow \\{\\text{Caderno}\\}\\)). Elas validam o modelo, mas não geram insights novos.\nInexplicáveis: Regras que desafiam a lógica (ex: \\(\\{\\text{Sapatos}\\} \\rightarrow \\{\\text{Canetas}\\}\\)). Podem ser ruído estatístico (baixo Suporte) ou exigir mais pesquisa para serem compreendidas."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#o-algoritmo-apriori-como-fazer",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#o-algoritmo-apriori-como-fazer",
    "title": "Regras de Associação",
    "section": "O Algoritmo Apriori (Como Fazer)",
    "text": "O Algoritmo Apriori (Como Fazer)\n\nComo evitamos o \\(1 \\text{ quatrilhão}\\) de cálculos? Usamos o Algoritmo Apriori.\nO insight genial do Apriori é baseado em uma propriedade chamada “Fechamento para Baixo” (Downward Closure Property).\n\nIdeia do algoritmo\n\nSe um itemset é frequente (passa no limiar de Suporte), todos os seus subconjuntos também devem ser frequentes. (Isso é óbvio: se {Pão, Leite} é frequente, {Pão} tem que ser pelo menos* tão frequente).*\nCOROLÁRIO (A Poda): Se um itemset é INFREQUENTE (falha no Suporte), todos os seus SUPERCONJUNTOS também serão infrequentes. (Se {Ovos} é infrequente, não precisamos nem calcular* o suporte de {Ovos, Pão} ou {Ovos, Pão, Leite}. Sabemos que eles falharão).*"
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#o-algoritmo-apriori",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#o-algoritmo-apriori",
    "title": "Regras de Associação",
    "section": "O Algoritmo Apriori",
    "text": "O Algoritmo Apriori\nEtapas do Algoritmo (Join & Prune)\nO Apriori funciona “de baixo para cima”, construindo itemsets maiores a partir dos menores.\n\nPasso 1 (k=1):\n\nCalcule o Suporte de todos os itens individuais (k=1).\nPoda: Descarte todos os itens que não atingem o min_suporte. (Se {Ovos} tem \\(Suporte=1/5=0.2\\) e o min_suporte é 0.3, {Ovos} é podado).\n\nPasso 2 (k=2):\n\nJoin: Gere itemsets candidatos de 2 itens (C2) apenas com os itens que sobreviveram (L1).\nPoda (Apriori): Se {Ovos} foi podado, o candidato {Pão, Ovos} nem é gerado.\nPoda (Suporte): Calcule o Suporte de C2 e descarte os que não atingem min_suporte. Os que sobram são L2."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#o-algoritmo-apriori-1",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#o-algoritmo-apriori-1",
    "title": "Regras de Associação",
    "section": "O Algoritmo Apriori",
    "text": "O Algoritmo Apriori\nEtapas do Algoritmo (Join & Prune)\n\nPasso k:\n\nJoin: Gere candidatos C(k) a partir dos frequentes L(k-1).\nPoda (Apriori): Verifique se todos os subconjuntos de (k-1) itens de um candidato C(k) estão em L(k-1). Se não, pode o candidato.\nPoda (Suporte): Calcule o Suporte de C(k) e descarte os infrequentes.\n\nFim: O processo para quando não há mais itemsets frequentes a serem gerados."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#uma-alternativa-eficiente-fp-growth",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#uma-alternativa-eficiente-fp-growth",
    "title": "Regras de Associação",
    "section": "Uma Alternativa Eficiente: FP-Growth",
    "text": "Uma Alternativa Eficiente: FP-Growth\n\nEmbora o Apriori seja o algoritmo clássico, ele possui um gargalo computacional severo.\n\nO Gargalo do Apriori\n\nO problema do Apriori não é o cálculo do suporte. O problema é a geração de candidatos.\n\nExplosão Combinatória: O processo de “Join” (juntar L(k-1) para criar C(k)) pode gerar um número astronômico de candidatos que precisarão ter seu suporte contado.\nMúltiplas Varreduras: O Apriori precisa varrer o banco de dados inteiro \\(k\\) vezes (uma vez para cada nível de itemset). Se \\(k=10\\), são 10 varreduras.\n\nPara bancos de dados muito grandes ou com padrões longos (ex: compras complexas, sequenciamento de DNA), o Apriori se torna computacionalmente inviável."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-solução-fp-growth-comprimir-e-dividir",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-solução-fp-growth-comprimir-e-dividir",
    "title": "Regras de Associação",
    "section": "A Solução FP-Growth: Comprimir e Dividir",
    "text": "A Solução FP-Growth: Comprimir e Dividir\n\nO algoritmo FP-Growth (Frequent Pattern Growth) ataca esses dois gargalos:\n\nSem Geração de Candidatos: O FP-Growth não gera itemsets candidatos.\nApenas 2 Varreduras: Ele varre o banco de dados apenas duas vezes, independentemente do número de itens.\n\nA Grande Ideia: Em vez de varrer o banco de dados repetidamente para testar os itemsets, o FP-Growth comprime o banco de dados inteiro em uma estrutura de dados em árvore (a FP-Tree) e minera essa árvore compacta diretamente na memória."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-solução-fp-growth-comprimir-e-dividir-1",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-solução-fp-growth-comprimir-e-dividir-1",
    "title": "Regras de Associação",
    "section": "A Solução FP-Growth: Comprimir e Dividir",
    "text": "A Solução FP-Growth: Comprimir e Dividir\nEtapa 1: Construindo a FP-Tree (Frequent Pattern Tree)\n\nVarredura 1 (Scan 1):\n\nConta o suporte de todos os itens individuais (1-itemsets).\nDescarta os itens infrequentes (abaixo do min_suporte).\n\nOrdenação (Sorting):\n\nCria uma “lista de itens frequentes” (F-List) ordenada por suporte (do mais frequente para o menos frequente).\nPor quê? Isso garante que os itens mais comuns fiquem mais próximos da raiz da árvore, maximizando a compressão."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-solução-fp-growth-comprimir-e-dividir-2",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-solução-fp-growth-comprimir-e-dividir-2",
    "title": "Regras de Associação",
    "section": "A Solução FP-Growth: Comprimir e Dividir",
    "text": "A Solução FP-Growth: Comprimir e Dividir\nEtapa 1: Construindo a FP-Tree (Frequent Pattern Tree)\n\nVarredura 2 (Scan 2):\n\nLê cada transação, uma por uma.\nFiltra apenas os itens frequentes daquela transação.\nOrdena esses itens de acordo com a F-List.\nInsere a transação ordenada na FP-Tree."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-solução-fp-growth-comprimir-e-dividir-3",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#a-solução-fp-growth-comprimir-e-dividir-3",
    "title": "Regras de Associação",
    "section": "A Solução FP-Growth: Comprimir e Dividir",
    "text": "A Solução FP-Growth: Comprimir e Dividir\nEtapa 2: Mineração da FP-Tree (Divide and Conquer)\nFP-Growth usa uma estratégia de “Dividir e Conquistar”.\n\nComeça pela Tabela de Cabeçalho, do item menos frequente (no final da lista).\nPara esse item (ex: “Ovos”), ele coleta todos os “caminhos prefixos” que terminam em “Ovos”. Isso forma sua Base de Padrões Condicionais.\nA partir dessa base, ele constrói uma nova FP-Tree Condicional (uma árvore muito menor, apenas para “Ovos”).\nEle minera recursivamente essa pequena árvore.\nTodos os padrões encontrados (ex: {Pão}, {Pão, Leite}) são combinados com o item original (ex: {Pão, Ovos}, {Pão, Leite, Ovos}).\n\n\nAo quebrar o problema grande (minerar a árvore inteira) em problemas menores (minerar sub-árvores condicionais), o FP-Growth é exponencialmente mais rápido que o Apriori em datasets densos."
  },
  {
    "objectID": "slides/07-regras_de_associacao/07-regras_de_associacao.html#apriori-vs.-fp-growth",
    "href": "slides/07-regras_de_associacao/07-regras_de_associacao.html#apriori-vs.-fp-growth",
    "title": "Regras de Associação",
    "section": "Apriori vs. FP-Growth",
    "text": "Apriori vs. FP-Growth\n\n\n\n\n\n\n\n\nCaracterística\nApriori\nFP-Growth\n\n\n\n\nAbordagem\n“Gerar e Testar”” (Join & Prune)\n“Dividir e Conquistar” (Pattern Growth)\n\n\nGeração de Candidatos\nSim (Principal gargalo)\nNão\n\n\nVarreduras no Banco\n\\(k+1\\) varreduras (lento)\n2 varreduras (rápido)\n\n\nUso de Memória\nBaixo (só mantém L(k-1))\nAlto (A FP-Tree precisa caber na memória)\n\n\nQuando Usar?\nDatasets esparsos, simples, ou quando \\(k\\) é pequeno.\nDatasets densos, grandes, ou com padrões longos."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bem-vindo(a)!",
    "section": "",
    "text": "Bem-vindo(a)!\nEste espaço foi criado pelo Prof. Dr. Sadraque E. F. Lucena para centralizar todos os conteúdos, atividades e o cronograma da disciplina ESTAT0109 - Mineração de Dados em Estatística, ofertado pelo Departamento de Estatística e Ciências Atuariais da Universidade Federal de Sergipe.\nAo longo do semestre, vamos construir juntos uma base sólida nos fundamentos da Mineração de Dados, explorando o processo de descoberta de conhecimento em bases de dados, as principais técnicas de aprendizado supervisionado e não supervisionado, e as aplicações práticas de algoritmos estatísticos e computacionais para extrair padrões, prever resultados e transformar dados em conhecimento útil."
  },
  {
    "objectID": "info/conteudo.html",
    "href": "info/conteudo.html",
    "title": "Conteúdo",
    "section": "",
    "text": "O conteúdo programático detalhado da disciplina é apresentado a seguir. Ele está organizado em três grandes eixos que abordaremos ao longo do semestre.\n\nParte 1: Fundamentos   1.1. Fundamentos da Mineração de Dados   1.2. Pré-processamento de Dados      1.2.1. Exploração      1.2.2. Limpeza      1.2.3. Transformação      1.2.3. Redução\nParte 2: Aprendizado Não Supervisionado   2.1. Regras de Associação   2.2. \\(k\\)-means\nParte 3: Aprendizado Supervisionado   3.1. Regressão      3.1.1. Regressão linear      3.1.2. Regressão logística   3.2. \\(k\\)-Nearest Neighbors   3.3. Naive Bayes   3.4. Árvores de Decisão   3.5. Florestas aleatórias   3.6. Support Vector Machine   3.7. Avaliação de desempenho      3.7.1. Validação Cruzada      3.7.2. Amostragem bootstrap      3.7.3. Acurácia      3.7.4. Kappa      3.7.5. Precisão e revocação      3.7.6. Sensibilidade e especificidade   3.8. Ajuste de parâmetros   3.9. Métodos de conjunto (ensemble methods)      3.9.1. Bagging      3.9.2. Boosting      3.9.3. Stacking",
    "crumbs": [
      "Informações da disciplina",
      "Conteúdo"
    ]
  },
  {
    "objectID": "info/cronograma.html",
    "href": "info/cronograma.html",
    "title": "Cronograma de Aulas",
    "section": "",
    "text": "Confira abaixo o cronograma de aulas do semestre, baseado no calendário acadêmico do período 2025-2.\n\n\n\n\n\n\n\n\n\nData\nDia da Semana\nAula\nAssunto Previsto\n\n\n\n\n07/10/25\nTerça\n1\nVI Encontro de Estatística e Ciências Atuariais da UFS\n\n\n09/10/25\nQuinta\n2\nApresentação da disciplina. Introdução à mineração de dados.\n\n\n14/10/25\nTerça\n3\nIntrodução ao RStudio + GitHub.\n\n\n16/10/25\nQuinta\n4\nIntrodução ao Quarto.\n\n\n21/10/25\nTerça\n5\nPré-processamento de dados.\n\n\n23/10/25\nQuinta\n6\nAlgoritmos de agrupamento.\n\n\n28/10/25\nTerça\n7\nAlgoritmos de agrupamento.\n\n\n30/10/25\nQuinta\n8\nAlgoritmos de agrupamento.\n\n\n04/11/25\nTerça\n9\nIntrodução à Classificação de dados. Validação cruzada e avaliação de desempenho.\n\n\n06/11/25\nQuinta\n10\nRegressão Logística.\n\n\n11/11/25\nTerça\n11\nRegressão Logística.\n\n\n13/11/25\nQuinta\n12\nk-Nearest Neighbors (k-NN).\n\n\n18/11/25\nTerça\n13\nk-Nearest Neighbors (k-NN).\n\n\n20/11/25\nQuinta\n–\nDia Nacional de Zumbi e da Consciência Negra (feriado nacional)\n\n\n25/11/25\nTerça\n14\nXI SEMAC\n\n\n27/11/25\nQuinta\n15\nXI SEMAC\n\n\n02/12/25\nTerça\n16\nNaive Bayes.\n\n\n04/12/25\nQuinta\n17\nNaive Bayes.\n\n\n09/12/25\nTerça\n18\nÁrvores de decisão.\n\n\n11/12/25\nQuinta\n19\nÁrvores de decisão.\n\n\n16/12/25\nTerça\n20\nFloresta Aleatória (Random Forest).\n\n\n18/12/25\nQuinta\n21\nFloresta Aleatória (Random Forest).\n\n\n23/12/25\nTerça\n–\nRecesso acadêmico\n\n\n25/12/25\nQuinta\n–\nRecesso acadêmico\n\n\n30/12/25\nTerça\n–\nRecesso acadêmico\n\n\n01/01/26\nQuinta\n–\nConfraternização Universal (feriado nacional) e Aniversário de São Cristóvão (feriado municipal)\n\n\n06/01/26\nTerça\n–\nFérias coletivas para docentes\n\n\n08/01/26\nQuinta\n–\nFérias coletivas para docentes\n\n\n13/01/26\nTerça\n22\nSupport Vector Machine.\n\n\n15/01/26\nQuinta\n23\nSupport Vector Machine.\n\n\n20/01/26\nTerça\n24\nRegressão Linear.\n\n\n22/01/26\nQuinta\n25\nRegressão Linear.\n\n\n27/01/26\nTerça\n26\nRegras de Associação.\n\n\n29/01/26\nQuinta\n27\nRegras de Associação.\n\n\n03/02/26\nTerça\n28\nProjeto Final\n\n\n05/02/26\nQuinta\n29\nProjeto Final\n\n\n10/02/26\nTerça\n30\nApresentação do Projeto Final",
    "crumbs": [
      "Informações da disciplina",
      "Cronograma"
    ]
  },
  {
    "objectID": "info/dados_gerais.html",
    "href": "info/dados_gerais.html",
    "title": "Dados Gerais da Disciplina",
    "section": "",
    "text": "Esta seção centraliza todas as informações essenciais sobre nosso componente curricular, incluindo horários, avaliações e datas importantes.",
    "crumbs": [
      "Informações da disciplina",
      "Dados gerais"
    ]
  },
  {
    "objectID": "info/dados_gerais.html#informações",
    "href": "info/dados_gerais.html#informações",
    "title": "Dados Gerais da Disciplina",
    "section": "Informações",
    "text": "Informações\n\nComponente curricular: ESTAT0109 - Mineração de Dados em Estatística\nCarga Horária: 60 horas (4 créditos)\nUnidade Responsável: Departamento de Estatística e Ciências Atuariais (DECAT)\nDocente Responsável: Prof. Dr. Sadraque E. F. Lucena\nPeríodo Letivo: 2025-2\nPlano de Ensino da Disciplina: pdf\n\nDisciplina optativa para o curso de Estatística e de Ciências Atuariais da Universidade Federal de Sergipe.",
    "crumbs": [
      "Informações da disciplina",
      "Dados gerais"
    ]
  },
  {
    "objectID": "info/dados_gerais.html#horários-das-aulas",
    "href": "info/dados_gerais.html#horários-das-aulas",
    "title": "Dados Gerais da Disciplina",
    "section": "Horários das Aulas",
    "text": "Horários das Aulas\nAs aulas ocorrerão nos seguintes horários:\n\nTerças: 17h00 às 18h30 na DID 5 sala 017\nQuintas: 17h00 às 18h30 na DID 5 sala 107",
    "crumbs": [
      "Informações da disciplina",
      "Dados gerais"
    ]
  },
  {
    "objectID": "info/dados_gerais.html#avaliações",
    "href": "info/dados_gerais.html#avaliações",
    "title": "Dados Gerais da Disciplina",
    "section": "Avaliações",
    "text": "Avaliações\nSerá realizada uma avaliação contínua, com solicitação de atividades extraclasse e apresentações em sala de aula. Ao final da disciplina os alunos deverão apresentar um projeto final.",
    "crumbs": [
      "Informações da disciplina",
      "Dados gerais"
    ]
  },
  {
    "objectID": "info/dados_gerais.html#não-haverá-aula",
    "href": "info/dados_gerais.html#não-haverá-aula",
    "title": "Dados Gerais da Disciplina",
    "section": "Não haverá aula",
    "text": "Não haverá aula\n\n20/11/2025: Dia Nacional de Zumbi e da Consciência Negra (feriado nacional)\n25 e 27/11/2025: XI SEMAC (suspensão das atividades de aula para participação nos eventos da XI SEMAC)\n22 a 31/12/2025: Recesso de final de ano\n01/01/2026: Confraternização Universal (feriado nacional) e Aniversário de São Cristóvão (feriado municipal)\n02 a 10/01/2026: Férias coletivas para docentes",
    "crumbs": [
      "Informações da disciplina",
      "Dados gerais"
    ]
  }
]