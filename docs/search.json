[
  {
    "objectID": "info/bibliografia.html",
    "href": "info/bibliografia.html",
    "title": "Bibliografia",
    "section": "",
    "text": "Abaixo, você encontra a bibliografia básica e complementar da disciplina.\n\nBásica\n\n\n\n\n\n\n\n \n\n\n\nTítulo\n\n\n\n\n\n\n\n\n\n\n\nPANG-NING, Tan; STEINBACH, Michael, KARPATNE, Anuj; KUMAR, Vipin. Introduction to data mining. 2. ed. New York: Pearson, 2019.\n\n\n\n\n\n\n\n\n\nHan, J.; Pei, J.; Tong, H. Data Mining: Concepts and Techniques. Morgan Kaufmann Publishers, 2023.\n\n\n\n\n\n\n\n\n\nNWANGANGA, Fred; CHAPPLE, Mike. Practical Machine Learning in R. Indianapolis, Indiana: John Wiley & Sons, 2020.\n\n\n\n\n\n\n\n\n\nAGGARWAL, Charu C. et al. Data mining: the textbook. New York: springer, 2015.\n\n\n\n\n\n\n\n\n\nHASTIE, T.; TIBSHIRANI, R; FRIEDMAN, J. The Elements of Statistical Learning: Data Mining, Inference and Prediction. 2. ed. New York, NY: Springer, 2009.\n\n\n\n\n\n\n\n\n\nDUNHAM, Margaret H. Data Mining: Introductory and Advanced Topics. Pearson, 2020.\n\n\n\n\n\n\nNenhum item correspondente\n\n\n\nComplementar\n\n\n\n\n\n\n \n\n\n\nTítulo\n\n\n\n\n\n\n\n\n\n\n\nCASTRO, Leandro N.; FERRARI, Daniel G. Introdução à mineração de dados: conceitos básicos, algoritmos e aplicações. São Paulo : Saraiva, 2016.\n\n\n\n\n\n\n\n\n\nBRAMER, Max. Principles of Data Mining. 4. ed. Springer, 2020.\n\n\n\n\n\n\n\n\n\nLAROSE, Daniel T.; LAROSE, Chantal D. . Discovering knowledge in data: an introduction to data mining. 2. ed. John Wiley & Sons, 2014.\n\n\n\n\n\n\nNenhum item correspondente",
    "crumbs": [
      "Informações da disciplina",
      "Bibliografia"
    ]
  },
  {
    "objectID": "info/softwares.html",
    "href": "info/softwares.html",
    "title": "Mineração de Dados",
    "section": "",
    "text": "Para acompanhar as atividades da disciplina, será necessário instalar os softwares listados abaixo. Todos são gratuitos e amplamente utilizados nas áreas de Estatística e Ciência de Dados:\n\n\n\nR é um ambiente computacional gratuito voltado para análises estatísticas e produção de visualizações gráficas. Link\n\n\n\nO RStudio consiste em um ambiente de desenvolvimento integrado (IDE) projetado para aumentar a produtividade no uso da linguagem R, oferecendo ferramentas especializadas para programação, depuração e visualização de dados. Link\n\n\n\nQuarto é um sistema de publicação técnico-científica de código aberto que integra análise computacional (Python, R, Julia) e produção de documentos dinâmicos em múltiplos formatos (HTML, PDF, Word). Combina escrita em Markdown com recursos avançados para equações, citações e visualizações reprodutíveis. Link",
    "crumbs": [
      "Informações da disciplina",
      "Softwares Necessários"
    ]
  },
  {
    "objectID": "info/softwares.html#softwares-necessários",
    "href": "info/softwares.html#softwares-necessários",
    "title": "Mineração de Dados",
    "section": "",
    "text": "Para acompanhar as atividades da disciplina, será necessário instalar os softwares listados abaixo. Todos são gratuitos e amplamente utilizados nas áreas de Estatística e Ciência de Dados:\n\n\n\nR é um ambiente computacional gratuito voltado para análises estatísticas e produção de visualizações gráficas. Link\n\n\n\nO RStudio consiste em um ambiente de desenvolvimento integrado (IDE) projetado para aumentar a produtividade no uso da linguagem R, oferecendo ferramentas especializadas para programação, depuração e visualização de dados. Link\n\n\n\nQuarto é um sistema de publicação técnico-científica de código aberto que integra análise computacional (Python, R, Julia) e produção de documentos dinâmicos em múltiplos formatos (HTML, PDF, Word). Combina escrita em Markdown com recursos avançados para equações, citações e visualizações reprodutíveis. Link",
    "crumbs": [
      "Informações da disciplina",
      "Softwares Necessários"
    ]
  },
  {
    "objectID": "info/ementa.html",
    "href": "info/ementa.html",
    "title": "Ementa e Objetivos",
    "section": "",
    "text": "Análise estatística em grandes bancos de dados. Tratamento de dados para processos de Data Mining. Principais funcionalidades, técnicas e algoritmos. Análise de associações. Classificação de dados. Árvores de decisão. Regressão Logística. Redes Neurais. Segmentação e Análise de Cluster. Estudo de casos.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "info/ementa.html#ementa",
    "href": "info/ementa.html#ementa",
    "title": "Ementa e Objetivos",
    "section": "",
    "text": "Análise estatística em grandes bancos de dados. Tratamento de dados para processos de Data Mining. Principais funcionalidades, técnicas e algoritmos. Análise de associações. Classificação de dados. Árvores de decisão. Regressão Logística. Redes Neurais. Segmentação e Análise de Cluster. Estudo de casos.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "info/ementa.html#objetivos",
    "href": "info/ementa.html#objetivos",
    "title": "Ementa e Objetivos",
    "section": "Objetivos",
    "text": "Objetivos\nCapacitar o aluno a compreender, aplicar e avaliar as principais técnicas e algoritmos de mineração de dados sob uma perspectiva estatística. Ao final da disciplina, o estudante deverá ser capaz de conduzir um projeto de extração de conhecimento a partir de dados, desde a preparação e análise exploratória até a construção, interpretação e validação de modelos preditivos e descritivos, comunicando os resultados de forma clara e objetiva.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "info/ementa.html#metodologia",
    "href": "info/ementa.html#metodologia",
    "title": "Ementa e Objetivos",
    "section": "Metodologia",
    "text": "Metodologia\nSerão ministradas aulas teóricas expositivas; utilizados recursos computacionais e visuais; aplicação de métodos em dados reais; solicitação de atividades extraclasse e realização de projetos.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "info/ementa.html#habilidades-e-competências",
    "href": "info/ementa.html#habilidades-e-competências",
    "title": "Ementa e Objetivos",
    "section": "Habilidades e Competências",
    "text": "Habilidades e Competências\nAo final da disciplina, espera-se que o(a) aluno(a) seja capaz de executar as rotinas essenciais de pré-processamento em grandes volumes de dados e a implementar os principais algoritmos de classificação, segmentação e associação para construir modelos preditivos e descritivos. O(A) aluno(a) também estará habilitado a avaliar criticamente a performance e a validade dos modelos gerados, bme como interpretar os resultados para extrair insights acionáveis e a comunicar suas conclusões de forma clara para diferentes públicos.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "info/ementa.html#avaliação",
    "href": "info/ementa.html#avaliação",
    "title": "Ementa e Objetivos",
    "section": "Avaliação",
    "text": "Avaliação\nSerá realizada uma avaliação contínua, com solicitação de atividades extraclasse e apresentações em sala de aula. Ao final da disciplina os alunos deverão apresentar um projeto final.",
    "crumbs": [
      "Informações da disciplina",
      "Ementa e objetivos"
    ]
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#objetivo-da-aula",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#objetivo-da-aula",
    "title": "Pré-Processamento de Dados",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\n\nDominar o pipeline de pré-processamento de dados"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#por-que-pré-processar-os-dados",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#por-que-pré-processar-os-dados",
    "title": "Pré-Processamento de Dados",
    "section": "Por que Pré-Processar os Dados",
    "text": "Por que Pré-Processar os Dados\n\nA qualidade de um modelo depende completamente da qualidade dos dados que utilizamos para construí-lo.\nFacilmente encontramos em bases de dados:\n\nRuído (noisy): Valores errados ou impossíveis (ex: um paciente com IDADE = 200 anos).\nInconsistência (inconsistency): A mesma informação registrada de formas diferentes (ex: MUNICIPIO = “Aracaju”, “Aracajú”).\nHeterogeneidade (heterogeneity): Dados de múltiplas fontes, com formatos e chaves diferentes (ex: o código o município do Censo Escolar e do SIM usando padrões diferentes – 6 ou 7 dígitos).\nDandos faltantes (Missing): O famoso NA."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#por-que-pré-processar-os-dados-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#por-que-pré-processar-os-dados-1",
    "title": "Pré-Processamento de Dados",
    "section": "Por que Pré-Processar os Dados",
    "text": "Por que Pré-Processar os Dados\n\nO objetivo do pré-processamento de dados é transformar dados brutos e “sujos” em um conjunto de dados limpo, coeso e de alta qualidade que seja apropriado para a mineração.\n\n\n\nAntes de aplicar qualquer técnica de limpeza, transformação ou integração, precisamos fazer um diagnóstico. A primeira e mais fundamental etapa desse diagnóstico é entender a natureza dos nossos dados.\nPrecisamos identificar os tipos de atributos (ou variáveis) que temos."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-dados-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-dados-1",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Dados",
    "text": "Tipos de Dados\nTodo conjunto de dados é composto por duas partes fundamentais, assim como uma planilha:\n\nObjetos de Dados (as Linhas): Representam a entidade que estamos observando.\n\nTambém chamados de: amostras, instâncias, casos ou tuplas (em bancos de dados).\nExemplos: um paciente, um cliente, um município, um domicílio.\n\nAtributos (as Colunas): Representam a característica ou propriedade que descreve o objeto.\n\nTambém chamados de: dimensões, features (em Machine Learning) ou variáveis (nosso termo preferido em Estatística).\nExemplos: IDADE, SEXO, POPULACAO_2022, IDH_M.\n\nClassificar os tipos de atributos, define quais técnicas estatísticas e de mineração podemos usar. Vejamos as classificações."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Atributos",
    "text": "Tipos de Atributos\nNominal\n\nA ordem não importa.\nExemplos: ocupacao(estatístico, médico, professor…), COD_MUNICIPIO_IBGE (ex: “2800308” = Aracaju).\nUm atributo nominal pode usar números (como COD_MUN_IBGE ou ID_cliente), mas operações matemáticas são sem sentido.\n\nNão podemos calcular a “média” dos códigos de município.\nA única medida de tendência central válida é a Moda (o valor mais frequente)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-1",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Atributos",
    "text": "Tipos de Atributos\nBinário (booleano)\n\nÉ um atributo nominal com apenas dois estados).\nExemplos: OBITO (1=Sim, 0=Não), FUMANTE (1=Sim, 0=Não).\nSubtipos Importantes:\n\nSimétrico: Ambos os estados têm o mesmo “peso”. Ex: SEXO (M/F).\nAssimétrico: Um estado é mais “raro” ou “importante”. Ex: TESTE_COVID (Positivo=1, Negativo=0). Por convenção, o “1” é o resultado de maior interesse."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-2",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Atributos",
    "text": "Tipos de Atributos\nOrdinal\n\nOs valores têm uma ordem ou ranking significativo, mas a magnitude (distância) entre eles é desconhecida.\nSabemos que Grande &gt; Médio &gt; Pequeno, mas não o quanto “Grande” é maior que “Médio”.\nExemplos: ESCOLARIDADE (Analfabeto &lt; Fundamental &lt; Médio &lt; Superior), SATISFACAO_ATENDIMENTO: (Muito Ruim, Ruim, Neutro, Bom, Muito Bom).\nEstatísticas Válidas: Moda e Mediana. A Média ainda não faz sentido."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-3",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-3",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Atributos",
    "text": "Tipos de Atributos\nQuantitativo (Numérico)\nSão quantidades mensuráveis (números inteiros ou reais) onde as operações matemáticas (média, desvio padrão) fazem sentido. Há dois tipos:\n\nIntervalar (Interval-Scaled): Tem ordem e as “distâncias” (intervalos) são iguais. O zero é apenas um ponto na escala, não significa ausência. Exemplos:\n\nTemperatura (°C / °F): 0°C não é “ausência de temperatura”. Não podemos dizer que 20°C é “o dobro do calor” de 10°C.\nDatas (Ano): O “Ano 0” não foi o começo do tempo.\n\n\n\nOperações: Média, Mediana, Moda, Diferenças (20°C – 10°C = 10°C)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-4",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tipos-de-atributos-4",
    "title": "Pré-Processamento de Dados",
    "section": "Tipos de Atributos",
    "text": "Tipos de Atributos\nQuantitativo (Numérico)\n\nRacional (Ratio-Scaled): Tem ordem, distâncias iguais E POSSUI UM “ZERO VERDADEIRO”. O Zero (0) significa a ausência total da medida.\n\nVL_TOTAL_INTERNACAO (R$ 0,00 é ausência de custo).\nIDADE, PESO, ALTURA.\nRENDA_MENSAL, N_DE_FILHOS.\n\n\n\nOperações: Todas! Média, Mediana, Moda, Diferenças E Rácios (R$ 100 é exatamente o dobro de R$ 50)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#a-visão-do-machine-learning",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#a-visão-do-machine-learning",
    "title": "Pré-Processamento de Dados",
    "section": "A Visão do Machine Learning",
    "text": "A Visão do Machine Learning\nMuitas vezes, os algoritmos e softwares (como R e Python) simplificam a classificação em dois grandes grupos, que não são exatamente iguais aos anteriores, mas os englobam.\n\nAtributo DISCRETO: Possui um conjunto de valores finito ou infinito contável (geralmente inteiros). Engloba:\n\nNominal (ex: RACA_COR)\nBinário (ex: OBITO)\nOrdinal (ex: ESCOLARIDADE)\nNuméricos Inteiros (ex: N_DE_FILHOS, DIAS_DE_INTERNACAO)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#a-visão-do-machine-learning-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#a-visão-do-machine-learning-1",
    "title": "Pré-Processamento de Dados",
    "section": "A Visão do Machine Learning",
    "text": "A Visão do Machine Learning\n\nAtributo CONTÍNUO: Possui um número infinito de valores “não contáveis” dentro de um intervalo (números reais, floating-point). Engloba atributos numéricos (Intervalares ou Racionais) que são medidos com casas decimais:\n\nPESO (ex: 75,32 kg)\nTAXA_MORTALIDADE_INFANTIL (ex: 12.4 por 1000)\nVL_MEDICAMENTO (ex: R$ 150,75)"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#pré-processamento-de-dados-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#pré-processamento-de-dados-1",
    "title": "Pré-Processamento de Dados",
    "section": "Pré-Processamento de Dados",
    "text": "Pré-Processamento de Dados\n\nDados de entrada incorretos ou de baixa qualidade resultam inevitavelmente em saídas incorretas ou de baixa qualidade.\nSe não for tomado o devido cuidado em lidar adequadamente com questões de qualidade de dados antes de treinar um modelo, a saída do modelo será não confiável, enganadora ou simplesmente incorreta.\n\nObjetivo: Arrumar os dados para iniciar uma análise de boa qualidade. Questões que temos que lidar:\n\nTratamento de Inconsistências\nValores Ausentes (Missing Values)\nRuído (Noise)\nIntegração de Dados (Data Integration)\nTransformação de Dados (Data Transformation)\nRedução de Dados (Data Reduction)\n\n\nVejamos detalhes de cada fase."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tratamento-de-inconsistências-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#tratamento-de-inconsistências-1",
    "title": "Pré-Processamento de Dados",
    "section": "1. Tratamento de Inconsistências",
    "text": "1. Tratamento de Inconsistências\n\nOcorre quando o mesmo dado é registrado de formas diferentes (sintaxe) ou quando um valor viola uma regra lógica (semântica).\nCom identificar?\n\nPara categorias: Fazer uma tabela de frequência para avaliar há registros com sintaxe diferente (ex: municipio com respostas “Aracaju” e “Aracajú”).\nPara numéricos: Obter mínimo, máximo e Boxplots par aver se há valores fora so possível (ex: idade_da_mae = 5 anos).\n\nO que fazer:\n\nPadronização de categorias: Agrupar sinônimos ou erros de digitação em um único rótulo padrão (ex: “Aracajú”, “AJU”, “Aracaju” → “Aracaju”).\nValidação de regras: Transformar valores inválidos em NAs."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-nas-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-nas-1",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values, NAs)",
    "text": "2. Valores Ausentes (Missing Values, NAs)\nUm NA pode ocorrer por 2 fatores principais:\n\nErro Aleatório:\n\nO digitador esqueceu; o paciente/cliente não quis informar.\nAção: Imputação.\n\nErro Estrutural / “Não Aplicável”:\n\nEx (DATASUS): DATA_OBITO está NA (porque o paciente está vivo).\nEx (CadÚnico): NOME_ESCOLA_FILHO está NA (porque a família não tem filhos).\nAção: Não imputar! O NA aqui é informação. Talvez criar uma categoria “Não Aplicável”.\n\n\nMoral: Sempre leia o Dicionário de Dados!"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values)",
    "text": "2. Valores Ausentes (Missing Values)\nAo lidarmos com NAs, algumas estratégias costumam ser utilizadas:\n\nRemover a linha inteira se ela tiver algum NA;\nSubstituir por uma constante;\nSubstituir por uma medida de tendência central;\nSubstituir pelo valor mais provável."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-1",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values)",
    "text": "2. Valores Ausentes (Missing Values)\na. Remover a linha inteira se ela tiver algum NA\n\nRemover a linha inteira apenas se o NA ocorreu por acaso e se a perda for menor que 5% dos dados.\nProblema:\n\nPerda de Informação: Se o NA estava só em RACA_COR, jogamos fora IDADE, SEXO, MUNICIPIO e o desfecho (a label).\nViés de Seleção (PERIGO!): E se os dados não estiverem faltando ao acaso?\n\nExemplo: Se só os mais ricos não responderam a renda e você remove os mais ricos da sua análise, o seu modelo se torna enviesado."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-2",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values)",
    "text": "2. Valores Ausentes (Missing Values)\nb. Substituir por uma constante\n\nNA em RENDA → 0\nNA em RACA_COR → \"Desconhecido\" ou \"99\"\nProblema:\n\nO algoritmo pode erroneamente achar que “os NAs formam um conceito interessante”.\nO modelo aprende que “Renda = 0” é um forte preditor, quando na verdade ele só significa “dado faltante”.\nIsso distorce a distribuição dos dados (ex: cria um pico falso no “0”)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-3",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-3",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values)",
    "text": "2. Valores Ausentes (Missing Values)\nc. Substituir por uma medida de tendência central\nSubstitui o NA pela medida “do meio” da distribuição daquele atributo. * A Regra de Ouro: * Média: Usar se a distribuição for simétrica (ex: IDADE, se for normal). * Mediana: Usar se a distribuição for assimétrica (ex: RENDA). * Vantagem: É rápido e preserva a média/mediana geral. * Desvantagem: Ignora as relações entre variáveis e “achata” a variância (subestima a variabilidade real)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-4",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#valores-ausentes-missing-values-4",
    "title": "Pré-Processamento de Dados",
    "section": "2. Valores Ausentes (Missing Values)",
    "text": "2. Valores Ausentes (Missing Values)\nd. Substituir pelo valor mais provável\nEsta é a abordagem moderna e preferida na maioria dos casos. Trata o valor ausente como um problema de predição.\n\nConceito: Usamos os outros atributos (X1, X2, X3) para prever o valor faltante (Y_na).\nComo?\n\nRegressão: Para prever RENDA (numérico) usando IDADE e ESCOLARIDADE.\nÁrvore de Decisão / k-NN: Para prever RACA_COR (categórico) usando MUNICIPIO e RENDA.\nNo R: Pacotes como recipes (Tidymodels) ou mice fazem isso.\n\nVantagem: Usa a maior parte da informação dos dados presentes e preserva as relações entre os atributos."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-1",
    "title": "Pré-Processamento de Dados",
    "section": "3. Ruído (Noise)",
    "text": "3. Ruído (Noise)\nRuído é um erro aleatório ou variância em uma variável medida.\n\nNão é um NA, mas um valor que parece “deslocado”.\nExemplo (SIH/DATASUS):\n\nUma internação por apendicite (VL_TOTAL) com custo de R$ 1,50.\nUma internação com custo de R$ 5.000.000,00 (enquanto a média é R$ 2.000,00).\n\nObjetivo: “Suavizar” (smooth) esses dados para remover a variação aleatória sem perder o sinal verdadeiro."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-2",
    "title": "Pré-Processamento de Dados",
    "section": "3. Ruído (Noise)",
    "text": "3. Ruído (Noise)\nTécnica 1: Binning (Agrupamento ou Discretização)\nBinning é uma técnica de suavização local (olha a “vizinhança”).\nO Processo (Ex: VALOR_INTERNACAO):\n\nOrdenar os dados: [4, 8, 15, 21, 21, 24, 25, 28, 34]\nParticionar em “Bins” (Baldes):\n\nEx: Bins de frequência igual (tamanho 3)\nBin 1: [4, 8, 15]\nBin 2: [21, 21, 24]\nBin 3: [25, 28, 34]\n\nSubstituir (Suavizar): Aplicar uma regra ao bin."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-3",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-3",
    "title": "Pré-Processamento de Dados",
    "section": "3. Ruído (Noise)",
    "text": "3. Ruído (Noise)\nTipos de Suavização por Binning\nUsando o exemplo (Bin 1: [4, 8, 15]):\n1. Suavização pela MÉDIA: * O que faz: Substitui todos os valores pela média do bin. * Ex: Média(4, 8, 15) = 9 * Resultado: [9, 9, 9]\n2. Suavização pela MEDIANA: (Muito recomendado!) * O que faz:** Substitui todos pela mediana do bin (robusto a outliers!). * Ex: Mediana(4, 8, 15) = 8 * Resultado: [8, 8, 8]\n3. Suavização pelos LIMITES: * O que faz: Substitui cada valor pelo limite (min/max) mais próximo. * Ex: [4, 8, 15] -&gt; [4, 4, 15] (8 está mais perto de 4 do que de 15)"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-4",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#ruído-noise-4",
    "title": "Pré-Processamento de Dados",
    "section": "3. Ruído (Noise)",
    "text": "3. Ruído (Noise)\nTécnica 2 e 3: Regressão e Análise de Outliers\nO Binning não é a única forma de suavizar dados.\nRegressão: Ajusta os dados a uma função (ex: uma linha de regressão linear). * Como suaviza? O “ruído” é a variação aleatória (o erro, \\(\\epsilon\\)) ao redor da linha. O valor “suavizado” é o valor predito pela linha.\nAnálise de Outliers (via Clustering): Agrupa dados similares (clusters). * Como suaviza? Valores que caem fora dos clusters podem ser considerados outliers (ruído)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-1",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nÉ o processo de combinar dados de múltiplas fontes.\nO Desafio: Os dados nunca vêm de uma única fonte limpa. * Queremos cruzar Taxas de Mortalidade (SIM/DATASUS)… * … com Indicadores Socioeconômicos (Censo/IBGE)… * … com Dados de Escolaridade (CadÚnico)… * … para cada Município de Sergipe.\nTemos quatro grandes desafios ao fazer isso. Vejamos."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-2",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nDesafio 1: O Problema da Identificação da Entidade\nComo o computador sabe que ‘Aracaju’ é ‘Aracaju’?\n\nDefinição: Como parear entidades do mundo real (pacientes, municípios, clientes) que estão em bases diferentes?\nEx: id_cliente (Base A) vs. numero_client (Base B).\n\nExemplo: * Base IBGE (Censo): O código de Aracaju é CD_MUN_IBGE = “2800308” (7 dígitos). * Base DATASUS (SIH): O código de Aracaju é CD_MUN_DATASUS = “280030” (6 dígitos). * Solução: Não dá para juntar direto! Precisamos transformar CD_MUN_IBGE para criar uma chave compatível com CD_MUN_DATASUS."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-3",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-3",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nDesafio 2: Conflito de Valores\nOk, conseguimos fazer o join() pelo código do município. Agora o problema é outro: os valores não “falam” a mesma língua.\nCausas (do Texto):\n\nDiferença de Escala/Unidade: (O mais comum!)\n\nBase A (IBGE): RENDA em “Salários Mínimos”.\nBase B (CadÚnico): RENDA_PER_CAPITA em “Reais (R$)”.\nBase C (World Bank): GDP em “Dólares (USD)”.\n\nDiferença de Abstração:\n\nBase A (SIH): VL_TOTAL_INTERNACAO (nível do paciente).\nBase B (CNES): ORCAMENTO_ANUAL_HOSPITAL (nível da unidade).\n\nDiferença de Semântica:\n\nBase A: INDICE_ESCOLARIDADE (População &gt; 18 anos).\nBase B: INDICE_ESCOLARIDADE (População &gt; 25 anos)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-4",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-4",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nDesafio 3: Redundância (“Informação Repetida”)\nUm atributo que pode ser “derivado” de outros.\n\nExemplo:\n\nVocê baixa uma tabela que tem as colunas:\nPOP_TOTAL\nPOP_URBANA\nPOP_RURAL\n\nProblema: POP_TOTAL é redundante (é POP_URBANA + POP_RURAL).\nPor que é ruim?\n\nAumenta a dimensionalidade (Maldição da Dimensionalidade).\nViola premissas de alguns modelos (ex: Multicolinearidade em Regressão).\nDá peso duplicado a uma mesma informação em algoritmos de distância (K-means)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-5",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-5",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nComo Detectar Redundância? Com Estatística!\nPara Atributos NUMÉRICOS (ex: POP_TOTAL vs POP_URBANA): * Coeficiente de Correlação (Pearson) * cor(dados$pop_total, dados$pop_urbana) * Se \\(r\\) for muito alto (ex: &gt; 0.9), há forte suspeita de redundância. * Covariância\nPara Atributos NOMINAIS (Categóricos): * Teste \\(\\chi^2\\) (Qui-Quadrado) * chisq.test(table(dados$var1, dados$var2)) * Mede a independência. Se \\(p\\)-valor for baixo (ex: &lt; 0.05), as variáveis são dependentes, o que pode indicar redundância (ex: COD_MUNICIPIO e NOME_MUNICIPIO são 100% dependentes)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-6",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#integração-de-dados-data-integration-6",
    "title": "Pré-Processamento de Dados",
    "section": "4. Integração de Dados (Data Integration)",
    "text": "4. Integração de Dados (Data Integration)\nDesafio 4: Duplicação de linhas\nA mesma entidade (linha) aparece mais de uma vez.\n\nExemplo: O mesmo cliente (\"João da Silva\") aparece duas vezes na tabela de compras, uma com endereço “Rua A” e outra com “Rua B” (pois ele se mudou e a base não foi atualizada corretamente).\nExemplo:\n\nRecord Linkage (Ligação de Registros)\nA paciente MARIA JOSE DA SILVA (do CadÚnico) é a mesma paciente M J SILVA (do SINAN/Dengue)?\n\nProblema: Gera inconsistências e superestima contagens.\nSolução: Requer técnicas avançadas (ex: fuzzy matching) para encontrar duplicatas “prováveis” e consolidá-las. (Isso dá um ótimo TCC com o Prof. Sadraque!)"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-1",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\n\nFrequentemente é preciso modificar a estrutura ou características dos dados para formas “apropriadas para a mineração”.\nAlgumas técnicas usadas são:\n\nNormalização Z-score;\nDiscretização Min-Max;\nTransformação logarítmica;\nDiscretização;\nCodificação de variáveis dummy."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-2",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\na. Normalização Z-score\n\nConhecida como normalização z-score ou normalização de média zero.\nEsta abordagem resulta em valores com média 0 e variância 1.\nA variável normalizada \\(v'\\) é dada por \\[ v' = \\frac{v-\\overline{v}}{\\sigma_v}, \\] em que \\(v\\) é a variável original, \\(\\overline{v}\\) é a média da variável \\(v\\) e \\(\\sigma_v\\) é o desvio padrão da variável \\(v\\).\n\nQuem Precisa Disso?\n\nK-Means (Clusterização), K-Nearest Neighbors (K-NN) (Classificação), SVM (Classificação), Redes Neurais, PCA (Redução de Dimensionalidade).\n\nBasicamente, qualquer algoritmo baseado em distância!"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-3",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-3",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\nb. Normalização Min-Max\n\nMapeia linearmente os valores para um novo intervalo, geralmente [0, 1], usando: \\[\nv'_{i} = \\frac{v_i - \\min_A}{\\max_A - \\min_A} \\times (\\text{novo_max} - \\text{novo_min}) + \\text{novo_min}\n\\] (Para [0, 1], os dois últimos termos desaparecem).\n\nExemplo (RENDA):\n\n\\(v = 700\\), \\(\\min = 200\\), \\(\\max = 2000\\)\n\\(v' = (700 - 200) / (2000 - 200) = 500 / 1800 = 0.277\\)\nVantagem: Preserva as relações lineares.\nDesvantagem: Extremamente sensível a outliers! Um único valor de Renda de R$ 50.000 (um erro) “espremeria” todos os outros dados perto de 0."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-4",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-4",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\nAtenção!!!\nNUNCA ajuste seus parâmetros de normalização (min/max ou z-score) usando os dados de TREINO E TESTE juntos!\nIsto é um vazamento de dados (data leakage). Você estaria “contando” ao seu modelo de treino sobre a distribuição do futuro (teste).\nO Processo Correto (Pipeline):\n\nDivida os dados: Treino e Teste.\nCalcule os parâmetros (ex: mean(), sd()) APENAS no conjunto de Treino.\nAplique esses mesmos parâmetros em ambos (Treino e Teste).\nNo R (Tidymodels), o recipe() + step_normalize() faz isso automaticamente!"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-5",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-5",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\nc. Transformação logarítmica\n\nAs transformações anteriores são boas quando os dados são simétricos.\nA transformação logarítmica é mais adequada para distribuições assimétricas e dados com valores que variam amplamente em magnitude.\nA transformação é \\[ v' = \\log(v). \\]"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-6",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-6",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\nd. Discretização\n\nA discretização consiste em transformar variáveis contínuas em categóricas.\nAlguns algoritmos exigem que a variável independente seja binária ou tenha um número limitado de valores distintos.\nEsse processo pode ser feito usando a suavização com médias de intervalo ou suavização com limites de intervalo.\nOutra forma comum é a dicotomização.\n\nExemplo: Os valores \\(\\{4,8, 9,15, 21, 21, 24, 25, 26, 28, 29,34\\}\\) seriam dicotomizados usado \\(20\\) como valore de corte, ficando \\(\\{0, 0, 0, 0,1,1,1,1,1,1,1,1\\}\\)."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-7",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-7",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\ne. Codificação de variáveis dummy\n\nUma variável dummy é uma dicotomização de uma variável contínua.\nEla é muito usada em algoritmos que exigem que os atributos independentes sejam numericos (como regressão ou k-NN) e como uma forma de representar dados ausentes.\nSuponha que temos a variável abaixo:\n\n\n\n\nEscolaridade\nCódigo\n\n\n\n\nEnino Fundamental\n1\n\n\nEnsino Médio\n2\n\n\nEnsino Superior\n3"
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-8",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#transformação-de-dados-data-transformation-8",
    "title": "Pré-Processamento de Dados",
    "section": "5. Transformação de Dados (Data Transformation)",
    "text": "5. Transformação de Dados (Data Transformation)\ne. Codificação de variáveis dummy\n\nUsando uma variável dummy completa, temos:\n\n\n\n\nEscolaridade\nEnsino Médio\nEnsino Superior\n\n\n\n\nEnino Fundamental\n0\n0\n\n\nEnsino Médio\n1\n0\n\n\nEnsino Superior\n0\n1\n\n\n\n\nAgora, ao invés de uma variável, temos \\(2\\) variáveis dummies.\nEm geral, o número de variáveis dummies criadas é \\(n-1\\), em que \\(n\\) é o número de categorias da variável original.\nEm geral, a categoria que não virou dummy é porque ela é, de alguma forma, menos importante para o estudo."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#redução-de-dados-data-reduction-1",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#redução-de-dados-data-reduction-1",
    "title": "Pré-Processamento de Dados",
    "section": "6. Redução de Dados (Data Reduction)",
    "text": "6. Redução de Dados (Data Reduction)\nO Objetivo: Reduzir o número de colunas (\\(k\\)) de \\(d\\) para \\(k\\) (onde \\(k &lt; d\\)), preservando o máximo de “sinal” e removendo “ruído”.\nTrês Estratégias Principais:\n\nProjeção Linear (PCA - Principal Components Analysis):\n\nO que faz: Combina atributos correlacionados para criar novos eixos (Componentes Principais) que capturam o máximo de variância dos dados.\nResultado: Um novo dataset (ex: \\(k=5\\)) onde cada coluna é uma combinação linear das originais (ex: \\(d=50\\))."
  },
  {
    "objectID": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#redução-de-dados-data-reduction-2",
    "href": "slides/05-pre-processamento_de_dados/05-pre-processamento_de_dados.html#redução-de-dados-data-reduction-2",
    "title": "Pré-Processamento de Dados",
    "section": "6. Redução de Dados (Data Reduction)",
    "text": "6. Redução de Dados (Data Reduction)\n\nSeleção de Atributos (Attribute Subset Selection):\n\nO que faz: Remove atributos irrelevantes ou redundantes. Não cria novas colunas.\nComo: Métodos greedy (Heurísticos) como Forward Selection (adiciona o melhor) ou Backward Elimination (remove o pior).\nResultado: Um subconjunto do dataset original (ex: \\(k=10\\) das \\(d=50\\) colunas originais).\n\nMapeamento Não Linear (ex: t-SNE, Kernel PCA):\n\nO que faz: (Para quando o PCA falha). Mapeia os dados de alta dimensão para baixa dimensão (ex: \\(k=2\\) ou \\(k=3\\)) preservando a estrutura de vizinhança (proximidade).\nResultado: Essencial para visualizar clusters complexos que são “emaranhados” nos dados originais."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#canais-de-comunicação-e-materiais-da-disciplina",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#canais-de-comunicação-e-materiais-da-disciplina",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Canais de Comunicação e Materiais da Disciplina",
    "text": "Canais de Comunicação e Materiais da Disciplina\n\nSite: http://sadraquelucena.github.io/mineracao\nGrupo no WhatsApp: http://tiny.cc/wppmineracao"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#informações-da-disciplina",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#informações-da-disciplina",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Informações da disciplina",
    "text": "Informações da disciplina\n\nComponente curricular: ESTAT0109 – Mineração de Dados em Estatística\nTipo: Disciplina optativa\nCarga horária: 60 horas (4 créditos)\nHorário:\n\nTerças e Quintas - 17h00 às 18h30\n\nDocente: Prof. Dr. Sadraque E. F. Lucena"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#objetivo-da-disciplina",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#objetivo-da-disciplina",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Objetivo da Disciplina",
    "text": "Objetivo da Disciplina\nCapacitar os(as) alunos(as) a aplicar técnicas estatísticas e computacionais para extrair padrões e conhecimentos úteis a partir de conjuntos de dados."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#ementa",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#ementa",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Ementa",
    "text": "Ementa\n\nAnálise estatística em grandes bancos de dados.\nTratamento de dados para processos de Data Mining.\nPrincipais funcionalidades, técnicas e algoritmos.\nAnálise de associações.\nClassificação de dados.\nÁrvores de decisão.\nRegressão Logística.\nRedes Neurais.\nSegmentação e Análise de Cluster.\nEstudo de casos."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Conteúdo Programático",
    "text": "Conteúdo Programático\nParte 1: Fundamentos   1.1. Fundamentos da Mineração de Dados   1.2. Pré-processamento de dados      1.2.1. Exploração      1.2.2. Limpeza      1.2.3. Transformação      1.2.3. Redução  Parte 2: Aprendizado Não Supervisionado   2.1. Regras de Associação   2.2.\\(k\\)-means"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático-1",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático-1",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Conteúdo Programático",
    "text": "Conteúdo Programático\nParte 3: Aprendizado Supervisionado   3.1. Regressão      3.1.1. Regressão linear      3.1.2. Regressão logística   3.2. \\(k\\)-Nearest Neighbors   3.3. Naive Bayes   3.4. Árvores de Decisão   3.5. Florestas aleatórias   3.6. Support Vector Machine"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático-2",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#conteúdo-programático-2",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Conteúdo Programático",
    "text": "Conteúdo Programático\nParte 3: Aprendizado Supervisionado (continuação)   3.7. Avaliação de desempenho      3.7.1. Validação Cruzada      3.7.2. Amostragem bootstrap      3.7.3. Acurácia      3.7.4. Kappa      3.7.5. Precisão e revocação      3.7.6. Sensibilidade e especificidade   3.8. Ajuste de parâmetros   3.9. Métodos de conjunto (ensemble methods)      3.9.1. Bagging      3.9.2. Boosting      3.9.3. Stacking"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#avaliação",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#avaliação",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Avaliação",
    "text": "Avaliação\nA avaliação do aprendizado será realizada por meio de um portfólio de projetos práticos, composto por:\n\nMini-Projetos: Estudos de casos práticos ao longo do semestre, com relatórios curtos descrevendo a preparação dos dados, aplicação dos algoritmos e interpretação dos resultados.\nProjeto Final Integrador: Relatório final consolidando as análises, com comparação crítica entre modelos, avaliação de desempenho e recomendação do modelo mais adequado ao problema."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#datas-importantes",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#datas-importantes",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Datas Importantes",
    "text": "Datas Importantes\n\n\n\n\n\n\n\nNão haverá aula:\n\n\n\n20/Nov/25: Dia Nacional de Zumbi e da Consciência Negra (feriado nacional)\n25 e 27/Nov/25: XI SEMAC\n22 a 31/12/2025: Recesso de final de ano\n01/01/2026: Confraternização Universal (feriado nacional) e Aniversário de São Cristóvão (feriado municipal)\n02 a 10/01/2026: Férias coletivas para docentes"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#bibliografia-recomendada",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#bibliografia-recomendada",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Bibliografia Recomendada",
    "text": "Bibliografia Recomendada\nBásica"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#bibliografia-recomendada-1",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#bibliografia-recomendada-1",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Bibliografia Recomendada",
    "text": "Bibliografia Recomendada\nComplementar"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#ferramentas",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#ferramentas",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Ferramentas",
    "text": "Ferramentas"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#o-que-é-mineração-de-dados",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#o-que-é-mineração-de-dados",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "O que é Mineração de Dados?",
    "text": "O que é Mineração de Dados?\n\nMineração Tradicional: processo de mineração tradicional, que busca extrair materiais valiosos (ouro, pedras preciosas) de uma mina.\nMineração de Dados:\n\nA Mina → A Base de Dados\nAs Ferramentas → Os Algoritmos\nOs Minerais Preciosos → O Conhecimento"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-hierarquia-de-valor-dados-informação-e-conhecimento",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-hierarquia-de-valor-dados-informação-e-conhecimento",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "A Hierarquia de Valor: Dados, Informação e Conhecimento",
    "text": "A Hierarquia de Valor: Dados, Informação e Conhecimento\n\nPara que a Mineração de Dados faça sentido, precisamos entender como o valor é agregado em cada nível.\n\nDados: Nível base. São símbolos ou signos brutos, não estruturados e sem significado isolado (Ex: o valor “28”).\nInformação: Dados com significado e utilidade. Contexto é adicionado (Ex: “A temperatura do ar é 28°C”).\nConhecimento: É a compreensão obtida a partir da informação, permitindo a tomada de decisão e a agregação de valor. (Ex: “Saber que fará 28°C em Aracaju no fim de semana pode influenciar a decisão de ir à praia”)."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#exemplos",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#exemplos",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Exemplos",
    "text": "Exemplos\n\nCasos em que a mineração de dados geralmente agrega valor:\n\nDescobrir anomalias em registros de sistema e aplicativos que podem indicar um incidente de cibersegurança;\nPrever as vendas de produtos com base nas condições de mercado e ambientais;\nRecomendar o próximo filme que um cliente pode querer assistir com base em sua atividade passada e nas preferências de clientes semelhantes;\nDefinir os preços dos quartos de hotel com bastante antecedência com base na demanda prevista."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#kdd",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#kdd",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "KDD",
    "text": "KDD\nA mineração de dados é uma etapa fundamental de um processo mais abrangente conhecido pela sigla KDD.\n\nKDD (Knowledge Discovery in Databases | Descoberta de Conhecimento em Bases de Dados): Processo completo e abrangente de extrair conhecimento útil de dados.\n\nEnvolve desde a coleta e limpeza dos dados até a validação final dos padrões encontrados.\nSuas etapas incluem: seleção, integração, limpeza, transformação, mineração e avaliação.\n\nMineração de Dados: Etapa fundamental no processo KDD.\n\nAplicação de algoritmos (computacionais e estatísticos) para identificar padrões nos dados já preparados."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#processo-kdd-visão-geral",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#processo-kdd-visão-geral",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Processo KDD: Visão Geral",
    "text": "Processo KDD: Visão Geral\nO processo KDD consiste em quatro etapas:\n\nBase de Dados: Ponto de partida. É uma coleção organizada de dados brutos sobre um conjunto de itens.\nPreparação ou Pré-processamento: A etapa de preparação e limpeza dos dados para garantir a qualidade da análise.\nMineração de Dados: A fase de “escavação”, onde algoritmos são aplicados para buscar padrões e extrair conhecimento.\nAvaliação ou Validação do Conhecimento: A fase final, que filtra e valida se os padrões encontrados são realmente úteis e valiosos.\n\n\nMuitas vezes, após a avaliação (etapa 4), é preciso retornar a etapas anteriores para refinar a análise."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-etapa-mais-crítica-pré-processamento",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-etapa-mais-crítica-pré-processamento",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "A Etapa Mais Crítica: Pré-processamento",
    "text": "A Etapa Mais Crítica: Pré-processamento\nEsta etapa visa preparar os dados para uma análise eficiente:\n\nLimpeza: Tratamento de dados inconsistentes ou faltantes (missing values).\nIntegração: Combinação de dados de múltiplas fontes (planilhas, bancos de dados diferentes).\nSeleção: Escolha dos dados e variáveis (atributos) mais relevantes(redução de dimensionalidade).\nTransformação: Consolidação dos dados em formatos apropriados para a mineração (ex: normalização, padronização, agregação)."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#mineração-coração-do-processo",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#mineração-coração-do-processo",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Mineração (Coração do Processo)",
    "text": "Mineração (Coração do Processo)\nNesta fase, algoritmos são aplicados aos dados já preparados para extrair padrões.\n\nAgrupamento (Clusterização): Divide os dados em grupos semelhantes entre si e distintos dos demais.\nPredição: Constrói modelos para prever valores futuros. Classificação prevê uma categoria, enquanto Estimação (ou Regressão) prevê um valor contínuo.\nRegras de Associação: Descobre atributos que ocorrem juntos com frequência, como no exemplo “quem compra pão também compra manteiga”.\nDetecção de Anomalias: Identifica registros fora do padrão, úteis para detectar fraudes ou defeitos."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#avaliação-e-validação-do-conhecimento",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#avaliação-e-validação-do-conhecimento",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Avaliação e Validação do Conhecimento",
    "text": "Avaliação e Validação do Conhecimento\nNem todo padrão encontrado por um algoritmo é útil. Esta etapa filtra os resultados para garantir que o conhecimento gerado seja valioso. As perguntas a serem respondidas incluem:\n\nO padrão é estatisticamente significativo ou ocorreu ao acaso?\nEle é novo e surpreendente ou apenas confirma algo que já sabíamos?\nÉ compreensível para o especialista do domínio ou para quem toma decisão?\nEle pode ser usado para embasar uma decisão que trará benefícios (aumento de receita, redução de custos, etc.)?\nO objetivo é separar o conhecimento útil de padrões irrelevantes."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#mineração-de-dados-é-interdisciplinar",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#mineração-de-dados-é-interdisciplinar",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Mineração de Dados é Interdisciplinar",
    "text": "Mineração de Dados é Interdisciplinar\n\nEstatística: Fornece a base para modelagem, testes de hipóteses e validação.\nAprendizagem de Máquina e IA: Oferece um vasto arsenal de algoritmos.\nCiência da Computação: Lida com Bancos de Dados, eficiência de algoritmos e computação de alto desempenho.\nVisualização de Dados: Essencial para a interpretação e comunicação dos resultados."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#principais-termos-da-área",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#principais-termos-da-área",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Principais Termos da Área",
    "text": "Principais Termos da Área\n\nA área de Mineração de Dados possui uma vasta quantidade de técnicas e algoritmos.\nFoi desenvolvida ao longo de décadas por diferentes grupos:\n\nPesquisadores acadêmicos\nEmpresas de tecnologia\nConsultores\n\nEssa diversidade de origens e inspirações (da estatística à biologia) gerou diferentes nomenclaturas para contextos muitas vezes similares.\nÉ importante estarmos familiarizados com as nomenclaturas mais utilizadas."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#inteligência-artificial-ia-clássica",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#inteligência-artificial-ia-clássica",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Inteligência Artificial (IA) Clássica",
    "text": "Inteligência Artificial (IA) Clássica\n\nDefinição: A ciência e engenharia de criar máquinas inteligentes, especialmente programas de computador.\nInspiração Principal: A inteligência humana (percepção, resolução de problemas, comunicação).\nAbordagem Central: Era simbólica e baseada em lógica.\n\nConhecimento era representado por símbolos e regras.\nO sistema inteligente era construído codificando-se o conhecimento de um especialista.\n\nExemplo: Sistemas Especialistas (Expert Systems).\n\nSe tosse E febre E dor de cabeça, ENTÃO gripe."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#inteligência-computacional",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#inteligência-computacional",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Inteligência Computacional",
    "text": "Inteligência Computacional\n\nOrigem: Surgiu de uma discordância com a IA Clássica.\n\nA IA Clássica teve dificuldade em cumprir promessas ambiciosas (robôs autônomos, etc.).\nNovas abordagens, com formas de operação diferentes, precisavam de um novo nome.\n\nFoco: Técnicas não-simbólicas, muitas vezes inspiradas em fenômenos biológicos.\nPilares da Inteligência Computacional:\n\nRedes Neurais Artificiais\nSistemas Nebulosos (Fuzzy Systems)\nAlgoritmos Evolutivos"
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#aprendizagem-de-máquina",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#aprendizagem-de-máquina",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Aprendizagem de Máquina",
    "text": "Aprendizagem de Máquina\n\nDefinição: Área que desenvolve programas capazes de melhorar seu desempenho automaticamente por meio da experiência.\nFonte da Experiência: Dados.\nIdeia Central: Em vez de programar regras explícitas, o sistema aprende os padrões diretamente dos dados.\nRelação: Está intimamente ligada à Mineração de Dados, Estatística e Inteligência Artificial.\nFoco Principal: Extrair informação e conhecimento a partir de dados de forma automática."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#aplicações-no-mundo-real",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#aplicações-no-mundo-real",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Aplicações no Mundo Real",
    "text": "Aplicações no Mundo Real\n\nRecomendação de Filmes e Produtos: A Netflix aprende seus gostos (Aprendizagem de Máquina) para sugerir novos filmes.\nDiagnóstico Médico por Imagem: Sistemas analisam tomografias para identificar padrões de doenças, aprendendo com milhares de exames anteriores (Redes Neurais).\nDetecção de Fraude em Cartão de Crédito: O sistema aprende o padrão de gastos do cliente (Aprendizagem de Máquina) e sinaliza transações que fogem desse padrão.\nOtimização de Rotas de Entrega: Algoritmos inspirados em colônias de formigas (Computação Natural) encontram os caminhos mais eficientes."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#como-as-máquinas-aprendem",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#como-as-máquinas-aprendem",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Como as Máquinas Aprendem?",
    "text": "Como as Máquinas Aprendem?\n\nAprendizado Supervisionado:\n\nO algoritmo treina com um conjunto de dados que já possui as respostas corretas (rótulos).\nExemplo: Prever o preço de um imóvel usando uma base de dados com o preço de imóveis já vendidos.\n\nAprendizado Não Supervisionado:\n\nO algoritmo recebe dados sem respostas ou rótulos.\nA tarefa é encontrar padrões, estruturas ou grupos ocultos nos dados.\nExemplo: Agrupar clientes de um supermercado em segmentos com base em seus hábitos de compra."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#computação-natural",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#computação-natural",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "Computação Natural",
    "text": "Computação Natural\n\nDefinição: Um termo “guarda-chuva” para descrever técnicas que se relacionam com a natureza.\nInspiração: Fenômenos naturais, que vão além da inteligência humana.\n\nExemplos: Evolução das espécies, sistema imunológico, comportamento de enxames (formigas, abelhas), construção de ninhos por cupins.\n\nAbrangência:\n\nMétodos inspirados na natureza para resolver problemas.\n\nAlgoritmos Evolutivos, Inteligência de Enxame.\n\n\nMétodos que usam a natureza para computar. - Computação com moléculas (DNA), Computação Quântica."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "A Mesma Ideia, Nomes Diferentes",
    "text": "A Mesma Ideia, Nomes Diferentes\nMuitos conceitos de Mineração de Dados e Aprendizagem de Máquina têm um equivalente direto na Estatística. A base matemática é frequentemente a mesma.\n\nInstância (Instance)\n\nObservação ou Ponto Amostral\nUma unidade amostral ou indivíduo (equivale a uma linha em uma tabela).\n\nAtributo (Attribute / Feature)\n\nVariável Independente ou Variável Explicativa (preditor)\nÉ a variável que usamos para fazer uma previsão (equivale a uma coluna em uma tabela)."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes-1",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes-1",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "A Mesma Ideia, Nomes Diferentes",
    "text": "A Mesma Ideia, Nomes Diferentes\n\nRótulo ou Atributo-Alvo (Label / Target)\n\nVariável Dependente ou Variável Resposta\nÉ a variável que o modelo estatístico tenta prever ou explicar.\n\nModelo (Model)\n\nModelo estatístico ou algoritmo computacional criado que será usado para fazer novas previsões.\nPode ser, por exemplo, uma árvore de decisão, uma rede neural ou um modelo de regressão logística."
  },
  {
    "objectID": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes-2",
    "href": "slides/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados/01-Apresentacao_da_disciplina_e_introducao_a_mineracao_de_dados.html#a-mesma-ideia-nomes-diferentes-2",
    "title": "Apresentação da Disciplina e Introdução à mineração de dados",
    "section": "A Mesma Ideia, Nomes Diferentes",
    "text": "A Mesma Ideia, Nomes Diferentes\n\nTreinamento (Training)\n\nAjuste do Modelo ou Estimação de Parâmetros\nÉ o processo de usar os dados para encontrar os melhores coeficientes (parâmetros) do modelo (Ex: método de mínimos quadrados em uma regressão).\n\nDiferença sutil no foco:\n\nA Estatística Clássica frequentemente enfatiza a inferência, ou seja, entender e explicar a relação entre as variáveis.\nA Mineração de Dados e Aprendizagem de Máquina geralmente priorizam a capacidade de predição do modelo em dados futuros, mesmo que o modelo seja uma “caixa-preta”."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#objetivo-da-aula",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#objetivo-da-aula",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Objetivo da aula",
    "text": "Objetivo da aula\n\nEntender o que é e para que serve o  e o .\nSaber como criar um repositório de projeto.\nAtualizar repositório no  via ."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#o-que-é-o",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#o-que-é-o",
    "title": "Introdução ao RStudio + GitHub",
    "section": "O que é o ?",
    "text": "O que é o ?\n\nGit é uma ferramenta que ajuda a controlar e gerenciar mudanças em arquivos ao longo do tempo.\nEle permite que você salve versões diferentes de um trabalho à medida que faz alterações, de modo que possa voltar para versões anteriores se algo der errado ou se precisar revisar mudanças feitas."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#por-que-o-é-importante",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#por-que-o-é-importante",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Por que o  é importante?",
    "text": "Por que o  é importante?\n\nEvita perda de trabalho: Se você estiver escrevendo código ou criando qualquer tipo de documento, o Git permite que você salve diferentes versões do seu trabalho. Assim, se algo der errado, você pode voltar a uma versão anterior.\nFacilita o trabalho em equipe: Quando várias pessoas estão trabalhando no mesmo projeto, o Git permite que cada uma trabalhe de forma independente e depois una os trabalhos de maneira organizada. Isso evita que as alterações de uma pessoa sobrescrevam as de outra.\nOrganização e rastreamento: O Git mantém um histórico completo de todas as mudanças feitas em um projeto, permitindo saber quem fez o quê e quando."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#o-que-é-o-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#o-que-é-o-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": "O que é o ?",
    "text": "O que é o ?\n\nGitHub é uma plataforma online que armazena e organiza projetos que utilizam Git.\nEle permite que você publique seu código, compartilhe arquivos e colabore com outras pessoas em projetos de forma fácil e eficiente."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#por-que-o-é-importante-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#por-que-o-é-importante-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Por que o  é importante?",
    "text": "Por que o  é importante?\n\nArmazenamento seguro: Com o GitHub, seus projetos ficam seguramente armazenados na nuvem. Isso significa que você pode acessar seu trabalho de qualquer lugar e sempre terá uma cópia segura.\nColaboração em equipe: GitHub permite que várias pessoas trabalhem no mesmo projeto ao mesmo tempo. Cada pessoa pode fazer mudanças no código, e o GitHub ajuda a gerenciar essas mudanças sem que uma sobrescreva a outra.\nHistórico e transparência: O GitHub mantém um histórico completo de todas as alterações feitas no seu projeto. Isso permite ver quem fez o quê e quando, facilitando o acompanhamento e revisão do trabalho de equipe."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#como-e-por-que-usar-o-na-disciplina",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#como-e-por-que-usar-o-na-disciplina",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Como e por que usar o  na disciplina?",
    "text": "Como e por que usar o  na disciplina?\n\nVocê receberá um script em R a cada aula\nDurante a aula, vai editar esse script no RStudio, testando e resolvendo problemas\nNo final da aula, envia suas alterações para seu repositório (push) — tudo salvo e organizado\nPode acessar seu trabalho de qualquer lugar, com segurança e histórico garantido\n\n\nGitHub será seu caderno digital de códigos — inteligente, seguro e acessível para a disciplina"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#primeiros-passos",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#primeiros-passos",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Primeiros passos",
    "text": "Primeiros passos\n\nBaixar e instalar o Git: https://happygitwithr.com/install-git.html\nCriar uma conta no GitHub: https://github.com/\nCriar um reposítório Git\nClone esse repositório para sua máquina usando o RStudio\nTrabalhe no projeto e envie as atualizações de volta ao GitHub\n\n\nDesenvolva o hábito de buscar soluções por conta própria. Isso faz parte do dia a dia de quem trabalha com dados. Comece agora a desenvolver essa autonomia."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-repositório-no",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-repositório-no",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Criando um repositório  no ",
    "text": "Criando um repositório  no \n\nApós fazer login no GitHub, Clique em + no canto superior direito\nEm seguida, clique em New repository"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-repositório-no-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-repositório-no-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Criando um repositório  no ",
    "text": "Criando um repositório  no \n\n\n\nEm Repository name dê um anome ao repositóro\nEm Description faça uma descrição do repositório\nMarque a opção Public ou Private\nEm Initialize this repository with: marque a opção Add a README file\nClique em Create repository"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#section",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#section",
    "title": "Introdução ao RStudio + GitHub",
    "section": "",
    "text": "Com o repositório já criado no GitHub, agora vamos usar o RStudio para ligar o projeto local ao repositório remoto.\nAssim, todas as alterações feitas no RStudio poderão ser salvas na nuvem e versionadas automaticamente.\nPara enviar essas alterações ao GitHub, será necessário se autenticar — com login e senha ou com um token de acesso.\n\nVamos ver como criar um token de acesso no GitHub."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Criando um token de acesso no ",
    "text": "Criando um token de acesso no \n\n\n\nEstando logado no GitHub, clique na sua foto de perfil no canto superior direito\n\nClique em Settings"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Criando um token de acesso no ",
    "text": "Criando um token de acesso no \n\nNo canto inferior esquerdo da tela clique em Developer settings"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no-2",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-um-token-de-acesso-no-2",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Criando um token de acesso no ",
    "text": "Criando um token de acesso no \n\n\n\nNo canto superior esquerdo da tela clique em Personal access tokens\nClique em Tokens (classic)\n\n\n\n\n\n\n\nEm Expiration selecione a data em que o token irá expirar\nMarque todas as opções em Select scopes\nClique em Generate token\n\n\nO token será gerado uma única vez. Guarde-o com cuidado, pois não será possível visualizá-lo novamente no GitHub. Você usará esse token quando for solicitada autenticação."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#integração-prática",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#integração-prática",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : integração prática",
    "text": "+ : integração prática\n\nO RStudio possui integração nativa com o Git e GitHub\n\nOu seja, é possível sincronizar um repositório GitHub a um repositório local\nIsso significa que você pode ligar o repositório do GitHub (na nuvem) ao seu projeto no computador. Assim, o que você altera localmente pode ser enviado para o GitHub — e vice-versa.\n\nPara isso, seguimos os seguintes passos:"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#integração-prática-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#integração-prática-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : integração prática",
    "text": "+ : integração prática\n\nFazemos uma cópia do repositório do GitHub na máquina local usando o RStudio.\n\nQuando já há uma cópia na máquina, começamos o trabalho atualizando o projeto local com as alterações que estão no GitHub (pull).\n\nTrabalhamos normalmente no projeto: scripts, análises, relatórios…\nUsamos o Git para registrar as alterações (commit) e enviar para o GitHub (push)."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : criando o projeto local",
    "text": "+ : criando o projeto local\n\n\n\nNo canto superior direito do RStudio clique em File &gt; New Project\nClique em Version control"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : criando o projeto local",
    "text": "+ : criando o projeto local\n\nClique em Git"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-2",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-2",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : criando o projeto local",
    "text": "+ : criando o projeto local\n\n\n\nNo campo Repository URL, cole a URL do repositório que você criou no GitHub\nEm Create project as subdirectory of, escolha o diretório em que o repositório do GitHub será copiado na máquina local\nClique em Create Project"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-3",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#criando-o-projeto-local-3",
    "title": "Introdução ao RStudio + GitHub",
    "section": " + : criando o projeto local",
    "text": "+ : criando o projeto local\n\nSe você estiver clonando um repositório público, o RStudio irá criar uma cópia do projeto localmente, sem exigir login.\nSe o repositório for privado, o GitHub pedirá que você se autentique (login e senha ou token).\n\n\n\nUma vez que já existe o projeto na máquina local, você só precisa acessar o diretório local (pasta) e clicar no arquivo com extensão .Rproj para abrir o projeto no Rstudio, sem necessidade de clonar o projeto novamente na máquina."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nDepois de salvar as atualizações do seu projeto local, você pode enviar essas alterações para o repositório no GitHub diretamente pelo RStudio. Você deve fazer:\n\n\nNo quadrante superior direito clique em Commit"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-1",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-1",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nRStudio mostra os arquivos que foram alterados. Selecione-os.\nNo campo Commit message escreva um comentário contendo o que foi atualizado (sugestão: não use caracteres especiais ou acentos)\nClique em Commit"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-2",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-2",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-3",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-3",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nApós finalizado o envio, clique em Close"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-4",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-4",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nNote que irá aparecer a mensagem Your branch is ahead of 'origin/master' by 1 commit (isto indica que você tem alterações ainda não enviadas ao GitHub)\nClique em Push"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-5",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-5",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nEm máquinas com Windows o Rstudio redirecionará para você fazer login na sua conta GitHub no seu navegador. Em Linux preencha o campo Username for 'https://github.com' coloque login e clique em OK"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-6",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-6",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nAinda em Linux, no campo Personal Access Token insira o token criado no GitHub\nClique em OK"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-7",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#enviando-alterações-para-o-via-7",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Enviando alterações para o  via ",
    "text": "Enviando alterações para o  via \n\nCaso apareça a mensagem abaixo, os arquivos foram atualizados no repositório do GitHub."
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#material-extra",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#material-extra",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Material Extra",
    "text": "Material Extra\nAprofunde o que vimos em aula com esses vídeos no YouTube:\n\nCurso completo de Git e GitHub: http://tiny.cc/GitGitHub:\nIntegração do RStudio com o GitHub:\n\nParte 1: http://tiny.cc/RStudioGitHub1\nParte 2: http://tiny.cc/RStudioGitHub2"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#ganhos-da-aula",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#ganhos-da-aula",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Ganhos da aula",
    "text": "Ganhos da aula\n\nVersionamento de código e arquivos com GitHub\nIntegração do RStudio com GitHub\nExperiência com ferramentas do mercado"
  },
  {
    "objectID": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#atividade-extraclasse",
    "href": "slides/02-introducao_ao_rstudio+github/02-introducao_ao_rstudio+github.html#atividade-extraclasse",
    "title": "Introdução ao RStudio + GitHub",
    "section": "Atividade extraclasse",
    "text": "Atividade extraclasse\nConfigure seu ambiente de trabalho pessoal\nObjetivo\nDeixar seu computador pessoal pronto para continuar os trabalhos da disciplina fora do laboratório, de forma independente.\nEtapas:\n\nInstalar o Git: https://happygitwithr.com/install-git.html\nInstalar o R: https://cran.r-project.org\nInstalar o RStudio: https://posit.co/download/rstudio-desktop\n\nCriar um repositório da disciplina do GitHub, clonar via RStudio para a sua máquina local e fazer seu primeiro commit."
  },
  {
    "objectID": "aulas/03-introducao_ao_quarto.html",
    "href": "aulas/03-introducao_ao_quarto.html",
    "title": "Conteúdo 3",
    "section": "",
    "text": "Nesta aula, iniciamos nossa jornada no Quarto, a plataforma unificada que é o padrão atual para comunicação científica no RStudio. Exploramos a estrutura de um documento .qmd, o papel do cabeçalho YAML e o uso de Markdown para formatação. Aprendemos a criar, editar e renderizar documentos que integram texto, blocos de código R, tabelas, gráficos e referências. A aula mostra como o Quarto permite gerar diversos formatos de saída (como HTML, PDF e slides) a partir de um único arquivo. Esse é o ponto de partida para desenvolver habilidades de comunicação eficaz, garantir a reprodutibilidade das análises e adotar boas práticas na documentação de projetos ao longo da disciplina.\nSlides:\n\n\n Versão html \n\n\n Versão pdf \n\n\nPara auxiliar na prática, também está disponível um modelo de exemplo em Quarto para download.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "3- Introdução ao Quarto"
    ]
  },
  {
    "objectID": "aulas/03-introducao_ao_quarto.html#introdução-ao-quarto",
    "href": "aulas/03-introducao_ao_quarto.html#introdução-ao-quarto",
    "title": "Conteúdo 3",
    "section": "",
    "text": "Nesta aula, iniciamos nossa jornada no Quarto, a plataforma unificada que é o padrão atual para comunicação científica no RStudio. Exploramos a estrutura de um documento .qmd, o papel do cabeçalho YAML e o uso de Markdown para formatação. Aprendemos a criar, editar e renderizar documentos que integram texto, blocos de código R, tabelas, gráficos e referências. A aula mostra como o Quarto permite gerar diversos formatos de saída (como HTML, PDF e slides) a partir de um único arquivo. Esse é o ponto de partida para desenvolver habilidades de comunicação eficaz, garantir a reprodutibilidade das análises e adotar boas práticas na documentação de projetos ao longo da disciplina.\nSlides:\n\n\n Versão html \n\n\n Versão pdf \n\n\nPara auxiliar na prática, também está disponível um modelo de exemplo em Quarto para download.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "3- Introdução ao Quarto"
    ]
  },
  {
    "objectID": "aulas/01-Apresentacao_da_disciplina.html",
    "href": "aulas/01-Apresentacao_da_disciplina.html",
    "title": "Conteúdo 1",
    "section": "",
    "text": "Sejam bem-vindos(as) à disciplina Mineração de Dados em Estatística!\nNesta primeira aula, abrimos oficialmente nossa jornada pelo fascinante universo da descoberta de conhecimento em bases de dados. Apresentamos os objetivos da disciplina, o formato das avaliações, os canais de comunicação e o portfólio de projetos que guiará nosso semestre. Em seguida, mergulhamos nos fundamentos da mineração de dados, explorando o processo KDD (Knowledge Discovery in Databases), a hierarquia entre dados, informação e conhecimento, e a conexão entre Estatística, Aprendizado de Máquina e Inteligência Artificial. Essa introdução marca o início de uma trilha que combina teoria, prática e análise crítica para transformar dados em decisões inteligentes.\nSlides:\n\n\n Versão html \n\n\n Versão pdf \n\n\nVídeo da aula:",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "1- Apresentação da Disciplina"
    ]
  },
  {
    "objectID": "aulas/01-Apresentacao_da_disciplina.html#apresentação-da-disciplina-e-introdução-à-mineração-de-dados",
    "href": "aulas/01-Apresentacao_da_disciplina.html#apresentação-da-disciplina-e-introdução-à-mineração-de-dados",
    "title": "Conteúdo 1",
    "section": "",
    "text": "Sejam bem-vindos(as) à disciplina Mineração de Dados em Estatística!\nNesta primeira aula, abrimos oficialmente nossa jornada pelo fascinante universo da descoberta de conhecimento em bases de dados. Apresentamos os objetivos da disciplina, o formato das avaliações, os canais de comunicação e o portfólio de projetos que guiará nosso semestre. Em seguida, mergulhamos nos fundamentos da mineração de dados, explorando o processo KDD (Knowledge Discovery in Databases), a hierarquia entre dados, informação e conhecimento, e a conexão entre Estatística, Aprendizado de Máquina e Inteligência Artificial. Essa introdução marca o início de uma trilha que combina teoria, prática e análise crítica para transformar dados em decisões inteligentes.\nSlides:\n\n\n Versão html \n\n\n Versão pdf \n\n\nVídeo da aula:",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "1- Apresentação da Disciplina"
    ]
  },
  {
    "objectID": "aulas/05-pre-processamento_de_dados.html",
    "href": "aulas/05-pre-processamento_de_dados.html",
    "title": "Conteúdo 5",
    "section": "",
    "text": "O pilar fundamental de qualquer modelo de mineração é a qualidade dos seus dados, reconhecendo o princípio de que entradas de baixa qualidade geram resultados de baixa qualidade (Garbage In, Garbage Out). Esta aula explora os desafios comuns encontrados em dados brutos — como ruído, inconsistências, dados faltantes e heterogeneidade — e introduz o pipeline de pré-processamento como um fluxo de trabalho estruturado para diagnosticar e remediar esses problemas. O processo se inicia pela base, com a classificação correta dos tipos de atributos (nominais, ordinais, intervalares e racionais) para definir as operações válidas. A partir daí, o pipeline detalha as etapas essenciais de tratamento de inconsistências (padronização e validação), estratégias para valores ausentes (da remoção simples à imputação preditiva), suavização de ruído (usando técnicas como binning), superação dos desafios da integração de dados (conflitos, redundância e identificação de entidades), aplicação de métodos de transformação (normalização Z-score, Min-Max, dummy coding) e o uso de técnicas de redução de dados (como PCA e seleção de atributos). Dominar este pipeline é um passo indispensável para garantir que os algoritmos de machine learning operem com máxima eficiência e que os resultados da análise sejam confiáveis, precisos e robustos.\nSlides:\n\n\n Versão html \n\n\n Versão pdf \n\n\nComo exemplo de aplicação iremos usar os mesmos dados da aula anterior, em que usamos dados do Sistema de Informação sobre Mortalidade (SIM) e do IBGE. O código R pode ser baixado aqui. Os dados estão disponíveis em:\n\nMortes ocorridas no Brasil em 2024 disponíveis no Sistema de Informação sobre Mortalidade (SIM): https://opendatasus.saude.gov.br/dataset/sim\nTabela de Códigos de Municípios do IBGE: https://www.ibge.gov.br/explica/codigos-dos-municipios.php\n\nTambém temos outro código em R para outro pr-é-processamento de dados. O arquivo com o código R e os dados podem ser baixados aqui.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "5- Pré-Processamento de Dados"
    ]
  },
  {
    "objectID": "aulas/05-pre-processamento_de_dados.html#pré-processamento-de-dados",
    "href": "aulas/05-pre-processamento_de_dados.html#pré-processamento-de-dados",
    "title": "Conteúdo 5",
    "section": "",
    "text": "O pilar fundamental de qualquer modelo de mineração é a qualidade dos seus dados, reconhecendo o princípio de que entradas de baixa qualidade geram resultados de baixa qualidade (Garbage In, Garbage Out). Esta aula explora os desafios comuns encontrados em dados brutos — como ruído, inconsistências, dados faltantes e heterogeneidade — e introduz o pipeline de pré-processamento como um fluxo de trabalho estruturado para diagnosticar e remediar esses problemas. O processo se inicia pela base, com a classificação correta dos tipos de atributos (nominais, ordinais, intervalares e racionais) para definir as operações válidas. A partir daí, o pipeline detalha as etapas essenciais de tratamento de inconsistências (padronização e validação), estratégias para valores ausentes (da remoção simples à imputação preditiva), suavização de ruído (usando técnicas como binning), superação dos desafios da integração de dados (conflitos, redundância e identificação de entidades), aplicação de métodos de transformação (normalização Z-score, Min-Max, dummy coding) e o uso de técnicas de redução de dados (como PCA e seleção de atributos). Dominar este pipeline é um passo indispensável para garantir que os algoritmos de machine learning operem com máxima eficiência e que os resultados da análise sejam confiáveis, precisos e robustos.\nSlides:\n\n\n Versão html \n\n\n Versão pdf \n\n\nComo exemplo de aplicação iremos usar os mesmos dados da aula anterior, em que usamos dados do Sistema de Informação sobre Mortalidade (SIM) e do IBGE. O código R pode ser baixado aqui. Os dados estão disponíveis em:\n\nMortes ocorridas no Brasil em 2024 disponíveis no Sistema de Informação sobre Mortalidade (SIM): https://opendatasus.saude.gov.br/dataset/sim\nTabela de Códigos de Municípios do IBGE: https://www.ibge.gov.br/explica/codigos-dos-municipios.php\n\nTambém temos outro código em R para outro pr-é-processamento de dados. O arquivo com o código R e os dados podem ser baixados aqui.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "5- Pré-Processamento de Dados"
    ]
  },
  {
    "objectID": "aulas/05-pre-processamento_de_dados.html#projeto-2-pré-processamento-de-dados-para-modelagem-de-risco",
    "href": "aulas/05-pre-processamento_de_dados.html#projeto-2-pré-processamento-de-dados-para-modelagem-de-risco",
    "title": "Conteúdo 5",
    "section": "Projeto 2 – Pré-Processamento de Dados para Modelagem de Risco",
    "text": "Projeto 2 – Pré-Processamento de Dados para Modelagem de Risco\nVocê agora atua como Cientista de Dados Júnior no mesmo time do Projeto 1. Seu trabalho começa onde o Projeto 1 terminou: com o dataframe filtrado do SCR.data.\nO objetivo desta etapa é limpar, padronizar, transformar os dados para prepará-los para modelagem estatística ou machine learning. O projeto é INDIVIDUAL.\nPrazo: Próxima aula.\nTarefa: Você deve reutilizar exatamente o dataframe final obtido no Projeto 1 (com PF ou PJ e UF filtrados). Caso tenha cometido algum erro no Projeto 1, você pode corrigi-lo agora – mas deve declarar isso no relatório. O foco agora é limpeza e preparação, não precisa colocar o que já foi feito no Projeto 1.\nFaça o pré-processamento dos dados que você organizou no Projeto 1. O dataframe resultante deve passar por no mínimo uma dessas etapas de pré-processamento, sendo obrigatória a etapa de Normalização:\n\nTratamento de valores ausentes usando imputação ou remoção\nCriação de variáveis derivadas log-transform, dummies, faixas etárias, grupos de risco, etc.\nDetecção de outliers, não precisa removê-los\nPadronização de nomes/renomeação de colunas se necessário\nChecagem de qualidade porcentagem de NAs por coluna\nNormalização/padronização z-score (obrigatório)\n\nEntrega: Produza um relatório em pdf gerado em Quarto que contenha:\n\nO script R completo e comentado no documento Quarto.\nAs saídas do R.\nDocumentação do dicionário de variáveis da tabela obtida (dataframe) com nome, tipo de variável e descrição.\nO envio deve ser realizado pelo SIGAA.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "5- Pré-Processamento de Dados"
    ]
  },
  {
    "objectID": "aulas/04-processamento_out-of-core.html",
    "href": "aulas/04-processamento_out-of-core.html",
    "title": "Conteúdo 4",
    "section": "",
    "text": "Nesta aula, enfrentamos o desafio de analisar dados que excedem a memória RAM do computador, introduzindo o paradigma de processamento Out-of-Core no R. Exploramos a arquitetura dessa solução, compreendendo o papel do pacote duckdb como o motor analítico in-process e do pacote DBI como a interface de conexão universal. Aprendemos a estrutura fundamental da linguagem SQL para realizar consultas diretamente no disco, focando nos comandos SELECT, FROM, WHERE, GROUP BY e ORDER BY. A aula demonstra, com exemplos práticos usando dados do DATASUS, como agregar e filtrar milhões de registros instantaneamente, trazendo para o R apenas o resultado consolidado. Este é um passo essencial para escalar análises, garantir a performance em datasets massivos e superar as limitações do processamento in-memory tradicional.\nDados que iremos usar:\n\nMortes ocorridas no Brasil em 2024 disponíveis no Sistema de Informação sobre Mortalidade (SIM): https://opendatasus.saude.gov.br/dataset/sim\nTabela de Códigos de Municípios do IBGE: https://www.ibge.gov.br/explica/codigos-dos-municipios.php\n\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "4- Processamento *Out-of-Core*"
    ]
  },
  {
    "objectID": "aulas/04-processamento_out-of-core.html#processamento-out-of-core-com-duckdb-e-dbi-no-r",
    "href": "aulas/04-processamento_out-of-core.html#processamento-out-of-core-com-duckdb-e-dbi-no-r",
    "title": "Conteúdo 4",
    "section": "",
    "text": "Nesta aula, enfrentamos o desafio de analisar dados que excedem a memória RAM do computador, introduzindo o paradigma de processamento Out-of-Core no R. Exploramos a arquitetura dessa solução, compreendendo o papel do pacote duckdb como o motor analítico in-process e do pacote DBI como a interface de conexão universal. Aprendemos a estrutura fundamental da linguagem SQL para realizar consultas diretamente no disco, focando nos comandos SELECT, FROM, WHERE, GROUP BY e ORDER BY. A aula demonstra, com exemplos práticos usando dados do DATASUS, como agregar e filtrar milhões de registros instantaneamente, trazendo para o R apenas o resultado consolidado. Este é um passo essencial para escalar análises, garantir a performance em datasets massivos e superar as limitações do processamento in-memory tradicional.\nDados que iremos usar:\n\nMortes ocorridas no Brasil em 2024 disponíveis no Sistema de Informação sobre Mortalidade (SIM): https://opendatasus.saude.gov.br/dataset/sim\nTabela de Códigos de Municípios do IBGE: https://www.ibge.gov.br/explica/codigos-dos-municipios.php\n\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "4- Processamento *Out-of-Core*"
    ]
  },
  {
    "objectID": "aulas/04-processamento_out-of-core.html#projeto-1-preparação-de-datasets-para-análise-de-risco",
    "href": "aulas/04-processamento_out-of-core.html#projeto-1-preparação-de-datasets-para-análise-de-risco",
    "title": "Conteúdo 4",
    "section": "Projeto 1 – Preparação de Datasets para Análise de Risco",
    "text": "Projeto 1 – Preparação de Datasets para Análise de Risco\nVocê é um(a) Engenheiro(a) de Dados. O time de Cientistas de Dados solicitou um dataset filtrado do SCR.data. Vocês devem usar duckdb para consultar arquivos CSV brutos, fazer a filtragem necessária usando SQL, e entregar um dataframe leve no R. O projeto é INDIVIDUAL.\nPrazo: Próxima aula.\nTarefa: Acesse https://dadosabertos.bcb.gov.br/dataset/scr_data, baixe os dados de 2025 e selecione o conjunto de dados (arquivo CSV) do mês mais recente disponível.\nEm seguida, escolha 1 Estado (UF) e 1 das duas opções de projeto abaixo.\nO objetivo de ambas as opções é escrever uma consulta SQL que leia o CSV e filtre os dados. A consulta deve usar WHERE para selecionar apenas as linhas que correspondam à UF escolhida E ao tipo de cliente ('PF' ou 'PJ').\nOpção 1: Extração de Micro-Segmentos de Risco (Pessoa Física)\n\nObjetivo: Preparar o dataset de clientes Pessoa Física (PF) para uma futura análise de risco e segmentação.\nFiltro Requerido: cliente = 'PF' (além da UF escolhida).\n\nOpção 2: Extração de Risco Setorial (Pessoa Jurídica)\n\nObjetivo: Preparar o dataset de clientes Pessoa Jurídica (PJ) para uma futura análise de risco dos diferentes setores da economia (CNAE).\nFiltro Requerido: cliente = 'PJ' (além da UF escolhida).\n\nEntrega: Produza um relatório em pdf gerado em Quarto que contenha:\n\nQual das 2 opções foi escolhida e qual a UF (Estado) selecionada.\nO script R completo e comentado no documento Quarto. Nesta tarefa, o código SQL dentro do R é a parte principal do trabalho.\nA saída da consulta no R. Você deve usar as funções glimpse() e summary() no dataframe resultante para provar que os filtros foram aplicados corretamente.\nO envio deve ser realizado pelo SIGAA.",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "4- Processamento *Out-of-Core*"
    ]
  },
  {
    "objectID": "aulas/02-introducao_ao_rstudio+github.html",
    "href": "aulas/02-introducao_ao_rstudio+github.html",
    "title": "Conteúdo 2",
    "section": "",
    "text": "Nesta aula, damos nossos primeiros passos práticos na integração entre o RStudio e o GitHub, ferramentas essenciais para o trabalho moderno em ciência de dados. Exploramos o papel do Git no controle de versões e aprendemos a criar, conectar e atualizar repositórios de forma segura e organizada. A aula mostra como essas ferramentas permitem registrar a evolução dos projetos, trabalhar de qualquer lugar e manter um histórico completo das análises. Esse é o ponto de partida para desenvolver autonomia, reprodutibilidade e boas práticas de programação ao longo da disciplina.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "2- Introdução ao RStudio + GitHub"
    ]
  },
  {
    "objectID": "aulas/02-introducao_ao_rstudio+github.html#introdução-ao-rstudio-github",
    "href": "aulas/02-introducao_ao_rstudio+github.html#introdução-ao-rstudio-github",
    "title": "Conteúdo 2",
    "section": "",
    "text": "Nesta aula, damos nossos primeiros passos práticos na integração entre o RStudio e o GitHub, ferramentas essenciais para o trabalho moderno em ciência de dados. Exploramos o papel do Git no controle de versões e aprendemos a criar, conectar e atualizar repositórios de forma segura e organizada. A aula mostra como essas ferramentas permitem registrar a evolução dos projetos, trabalhar de qualquer lugar e manter um histórico completo das análises. Esse é o ponto de partida para desenvolver autonomia, reprodutibilidade e boas práticas de programação ao longo da disciplina.\nSlides:\n\n\n Versão html \n\n\n Versão pdf",
    "crumbs": [
      "Aulas",
      "Parte 1: Fundamentos",
      "2- Introdução ao RStudio + GitHub"
    ]
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#objetivo-da-aula",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#objetivo-da-aula",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\n\nAprender a manipular grandes bases de dados no R.\nConhecer os pacotes duckdb e DBI.\nFazer consultas usando a linguagem SQL dentro do R."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-muro-da-memória-ram",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-muro-da-memória-ram",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "O Muro da Memória RAM",
    "text": "O Muro da Memória RAM\n\nO R é, por natureza, uma ferramenta in-memory. É comum usarmos o comando: meus_dados &lt;- read.csv(\"arquivo_grande.csv\").\nProblema: O que acontece se arquivo_grande.csv tem 50 GB e seu notebook tem 16 GB de RAM?\n\nO R tenta alocar 50 GB de espaço na RAM.\nO sistema operacional tenta compensar usando swap (disco), o que torna o processo astronomicamente lento.\nNa maioria dos casos, a sessão do R simplesmente trava ou é morta pelo sistema.\n\nSolução: Em vez de trazer os dados para o R, nós lemos e processamos os dados diretamente no disco, e trazemos para a RAM apenas o resultado final (que geralmente é pequeno).\n\nIsso é chamado de processamento Out-of-Core (ou On-Disk).\nPodemos usar os pacotes duckdb e DBI para fazê-lo."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-duckdb",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-duckdb",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "O Pacote duckdb",
    "text": "O Pacote duckdb\n\nFunciona como seu assistente inteligente para dados grandes.\nImagine que seus dados são uma biblioteca gigante:\n\nMétodo tradicional: Trazer todos os livros para sua mesa (RAM).\nCom DuckDB: Pedir ao bibliotecário que consulte os livros nas estantes (disco) e traga apenas a resposta."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-duckdb-1",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-duckdb-1",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "O Pacote duckdb",
    "text": "O Pacote duckdb\n\nÉ um sistema de gerenciamento de banco de dados (SGBD) analítico, in-process e colunar. Ou seja:\n\nAnalítico (OLAP): Otimizado para consultas complexas, agregações e filtros (ex: GROUP BY, SUM, AVG).\nIn-Process: Não é um servidor (como PostgreSQL ou MySQL). Ele roda dentro da sua sessão R. Não há instalação, configuração ou gerenciamento de servidor. Apenas install.packages(\"duckdb\") e pronto.\nColunar: Esta é a chave. Bancos de dados tradicionais armazenam dados por linha. O duckdb armazena por coluna.\n\nSe sua consulta é SELECT VARIAVEL1, COUNT(*) ..., ele lê apenas a coluna VARIAVEL1 do disco, ignorando todas as outras (nome, data, etc.). Isso resulta em uma velocidade maior.\nduckdb implementa uma versão muito abrangente e moderna do padrão SQL (Structured Query Language)."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-dbi",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#o-pacote-dbi",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "O Pacote DBI",
    "text": "O Pacote DBI\n\nDBI (Database Interface) é um pacote que fornece uma camada de abstração universal para comunicação com bancos de dados no R.\nEle define um conjunto de funções consistentes:\n\ndbConnect(): para iniciar a conexão.\ndbGetQuery(): para enviar uma consulta e receber os dados de volta.\ndbDisconnect(): para encerrar a conexão.\n\nPor que usá-lo?\n\nConsistência: Você usa as mesmas funções DBI para falar com duckdb, RPostgres, RMariaDB, RSQLite, etc.\nPortabilidade: Seu código R não muda. Se amanhã você decidir migrar seu processo do duckdb (local) para um PostgreSQL (servidor), você só precisa alterar a linha do dbConnect()."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#como-o-sql-se-encaixa",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#como-o-sql-se-encaixa",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Como o SQL se encaixa?",
    "text": "Como o SQL se encaixa?\n\nO DBI permite que o R fale com o duckdb, e a língua que eles usam é o SQL (Structured Query Language).\nEm vez de usar comandos do pacte dplyr (como filter, group_by, summarise) que operam em data.frames na memória, nós escrevemos uma string de consulta SQL (ex: SELECT ... FROM ... WHERE ...)\nNós passamos essa string para o DBI (ex: dbGetQuery(…)).\nO DBI entrega a string ao duckdb.\nO duckdb interpreta o SQL, otimiza a consulta, executa a operação diretamente no arquivo em disco, e retorna apenas o data.frame resultante para o R."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uso",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uso",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Estrutura Geral de Uso",
    "text": "Estrutura Geral de Uso\nEste é o esquema de 5 passos para qualquer análise out-of-core com duckdb:\n\n# 1. Carregar as bibliotecas na sessão\nlibrary(DBI)\nlibrary(duckdb)\n\n# 2. Criar a conexão com o banco de dados (para salvar as consultas)\n\n# Opção A: Em memória (rápido, mas volátil)\n#con &lt;- dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\n\n# Opção B: Persistente (recomendado)\ncon &lt;- dbConnect(duckdb::duckdb(),\n                 dbdir = \"meu_banco_analitico.duckdb\")\n\n# 3. Informar ao duckdb onde estão os dados\n# Isso NÃO carrega o CSV. Apenas cria um \"ponteiro\" para ele.\nduckdb_register(con, \"meus_dados\", \"arquivo_grande.csv\")"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uso-1",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uso-1",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Estrutura Geral de Uso",
    "text": "Estrutura Geral de Uso\nEste é o esquema de 5 passos para qualquer análise out-of-core com duckdb:\n\n# 4. Fazer consultas ao banco usando SQL\nresultado &lt;- dbGetQuery(con, \"SELECT COUNT(*) FROM meus_dados\")\n\n# 5. Encerrar a conexão e liberar os recursos\ndbDisconnect(con, shutdown = TRUE)\n\n\n\nComo as cosultas usam SQL, vamos fazer uma breve explicação sobre o uso da linguagem."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uma-consulta-sql",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#estrutura-geral-de-uma-consulta-sql",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Estrutura Geral de uma Consulta SQL",
    "text": "Estrutura Geral de uma Consulta SQL\nUma consulta SQL é como uma frase que descreve os dados que você deseja. A ordem de escrita é quase sempre esta:\n\nSELECT coluna1, FUNCAO(coluna2) AS novo_nome\nFROM nome_da_tabela\nWHERE condicao_de_filtro (ex: ano = 2023)\nGROUP BY coluna_de_agrupamento (ex: coluna1)\nORDER BY coluna_de_ordenacao (ex: novo_nome) DESC\nLIMIT 10"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-instrução-select",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-instrução-select",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "A instrução SELECT",
    "text": "A instrução SELECT\n\nEspecifica as colunas que você quer ver no resultado final.\nSempre vem acompanhada de FROM, que especifica de qual tabela os dados devem ser lidos.\n\nSintaxe:\n\nSELECT coluna1, coluna2, ...\nFROM nome_tabela\n\n\ncoluna1, coluna2, ... são as colunas das tabelas que você quer selecionar.\nnome_tabela representa o nome da tabela que contém os dados.\n\nExemplo: Suponha que temos uma tabela clientes e queremos selecionar todas as colunas.\n\nSELECT *\nFROM clientes"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-cláusula-where",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-cláusula-where",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "A cláusula WHERE",
    "text": "A cláusula WHERE\n\nSeleciona linhas que atendem a uma condição.\n\nSintaxe:\n\nSELECT coluna1, coluna2, ...\nFROM nome_tabela\nWHERE condição\n\nExemplos:\n\n\n\nSELECT *\nFROM clientes\nWHERE idade=30\n\n\n\nSELECT *\nFROM clientes\nWHERE idade&gt;24"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-cláusula-where-1",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-cláusula-where-1",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "A cláusula WHERE",
    "text": "A cláusula WHERE\nWHERE aceita alguns operadores:\n\n\n\n\n\n\n\n\n\nOperador\nDescrição\nOperador\nDescrição\n\n\n\n\n=\nIgual\n&lt;&gt; ou !=\nDiferente\n\n\n&gt;\nMaior que\n&lt;\nMenor que\n\n\n&gt;=\nMaior ou igual\n&lt;=\nMenor ou igual\n\n\nBETWEEN\nEntre um intervalo\nLIKE\nBusca por um padrão\n\n\nIN\nPara especificar múltiplos valores possíveis para uma coluna\n\n\n\n\n\nExemplo:\n\nSELECT *\nFROM clientes\nWHERE Idade BETWEEN 20 AND 30"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-instrução-group-by",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#a-instrução-group-by",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "A instrução GROUP BY",
    "text": "A instrução GROUP BY\n\nAgrupa linhas com mesmo valor.\nGeralmente é usada com funções de agregação (COUNT(), MAX(), MIN(), SUM(), AVG()) para agrupar os resultados de uma ou mais colunas.\nMuito usada em conjunto com ORDER BY, para ordenação dos resultados.\n\nSintaxe:\n\nSELECT nomes_das_colunas\nFROM nome_tabela\nWHERE condição\nGROUP BY nomes_das_colunas\nORDER BY nomes_das_colunas\n\nExemplo:\n\nSELECT COUNT(ID_cliente), estado\nFROM clientes\nGROUP BY estado\nORDER BY COUNT(ID_cliente) DESC"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-2",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-2",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo",
    "text": "Exemplo\nVamos usar o banco de dados sobre mortes ocorridas no Brasil em 2024 disponíveis no Sistema de Informação sobre Mortalidade (SIM), desenvolvido pelo Ministério da Saúde. Os dados estão disponíveis em: https://opendatasus.saude.gov.br/dataset/sim.\n\nVamos usar o conjunto de dados DO24OPEN.csv (óbitos ocorridos em 2024) e as variáveis:\n\nCODMUNOCOR: Código relativo ao município onde ocorreu o óbito\nCAUSABAS: Causa básica da declaração de óbito\n\nTambém vamos usar uma tabela do IBGE com os códigos e nomes dos municípios obtida em https://www.ibge.gov.br/explica/codigos-dos-municipios.php.\n\nUsaremos o arquivo RELATORIO_DTB_BRASIL_2024_MUNICIPIOS.xls."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-preparação-do-ambiente",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-preparação-do-ambiente",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo: Preparação do ambiente",
    "text": "Exemplo: Preparação do ambiente\n\n# 0. Instalando os pacotes (apenas uma vez)\n# install.packages(c(\"DBI\", \"duckdb\"))\n\n# 1. Carregando pacotes.\nlibrary(duckdb)\nlibrary(DBI)\n\n# 2. Especificando onde serão armazenadas as consultas.\n# Isso prepara o \"motor\" do duckdb para receber comandos\ncon &lt;- dbConnect(    # 'con' vai armazenar o objeto da conexão\n  duckdb::duckdb(),  # Especifica DuckDB como SGBD\n  dbdir = \":memory:\" # as consultas serão salvas na memória\n                     # e depois apagadas ao finalizar\n  #dbdir = \"sim_obitos.duckdb\" # cria uma arquivo p/ armazenar\n                               # os resultados da consulta\n)\n\n# 3. Definindo o caminho para o arquivo gigante\n# para não precisarmos escrever em toda consulta\ncaminho &lt;- \"/home/sadraque/Documentos/UFS/Disciplinas/2025.2/mineracao de dados em estatistica/slides/04-processamento_out-of-core/DO24OPEN.csv\""
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-1-contagem-total-de-linhas",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-1-contagem-total-de-linhas",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 1: Contagem total de linhas",
    "text": "Exemplo 1: Contagem total de linhas\nVamos contar quantas linhas há na tabela de dados.\n\n# Criando a consulta SQL\n# SELECT COUNT(*): \"Selecione a contagem de todas as linhas\"\n# FROM '%s' será substituído pelo caminho do arquivo\nconsult &lt;- sprintf(\"SELECT COUNT(*) AS total\n                           FROM '%s'\", caminho)\n\n# Enviando a consulta e pegando o resultado.\n# O duckdb vai ler o arquivo (sem carregá-lo) e retornar\n# apenas o resultado.\ntotal_linhas &lt;- dbGetQuery(con, consult)\ntotal_linhas\n\n    total\n1 1426346"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-2-agregando-por-município",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-2-agregando-por-município",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 2: Agregando por Município",
    "text": "Exemplo 2: Agregando por Município\nVamos contar o número de óbitos por código do município (CODMUNOCOR).\n\n# Montar a consulta SQL\nconsult &lt;- sprintf(\"SELECT CODMUNOCOR, COUNT(*) AS total_obitos\n                      FROM '%s'\n                      GROUP BY CODMUNOCOR\n                      ORDER BY total_obitos DESC\",\n                     caminho)\n\n\n# Enviar a consulta e pegar o resultado\nobitos_por_municipio &lt;- dbGetQuery(con, consult)\n\n# Ver as primeiras 4 linhas do resultado\nhead(obitos_por_municipio, n = 4L)\n\n  CODMUNOCOR total_obitos\n1     355030        89208\n2     330455        61443\n3     310620        23340\n4     261160        22146"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 3: Adicionando filtragem",
    "text": "Exemplo 3: Adicionando filtragem\nVamos consultar o número de óbitos por causas externas.\n\n# Criar a consulta SQL\n# CODMUNOCOR: Codigo do município onde ocorreu o óbito.\n# CAUSABAS: 'V01' a 'V99' são os códigos da CID-10 para\n#           acidentes de transporte.\nconsult &lt;- sprintf(\"SELECT CODMUNOCOR,\n                           COUNT(CAUSABAS) AS obitos_acidentes\n                    FROM '%s'\n                    WHERE CAUSABAS BETWEEN 'V01' AND 'V99'\n                    GROUP BY CODMUNOCOR\n                    ORDER BY obitos_acidentes DESC\",\n                   caminho)\nobitos_acidentes_mun &lt;- dbGetQuery(con, consult)\nhead(obitos_acidentes_mun, n = 4L) # primeiras 4 linhas\n\n  CODMUNOCOR obitos_acidentes\n1     130260              380\n2     520870              367\n3     261160              347\n4     355030              281"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-1",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-1",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 3: Adicionando filtragem",
    "text": "Exemplo 3: Adicionando filtragem\n\nOs códigos do SIM vêm sem os nomes dos municípios.\nPrecisamos cruzar com a tabela do IBGE para saber os nomes dos municípios.\n\n\nlibrary(tidyverse)\n\ntab_cod_ibge &lt;- readxl::read_excel(\n  \"/home/sadraque/Documentos/UFS/Disciplinas/2025.2/mineracao de dados em estatistica/slides/04-processamento_out-of-core/RELATORIO_DTB_BRASIL_2024_MUNICIPIOS.xls\",\n  skip = 6,  # Pula as 6 primeiras linhas\n  col_names = TRUE  # Usa a 7ª linha como nome das variáveis (default)\n) |&gt;\n  # Limpar nomes das colunas\n  janitor::clean_names()"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-2",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-2",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 3: Adicionando filtragem",
    "text": "Exemplo 3: Adicionando filtragem\n\ntab_cod_ibge &lt;- tab_cod_ibge |&gt;\n  # Cria código de 6 dígitos removendo o dígito verificador\n  mutate(codigo_6digitos = str_sub(codigo_municipio_completo,\n                                   1, -2)) |&gt;\n  # Converte para numérico\n  mutate(codigo_6digitos = as.numeric(codigo_6digitos)) |&gt;\n  # Seleciona e renomeia colunas finais\n  select(codigo = codigo_6digitos,\n         municipio = nome_municipio,\n         UF = nome_uf)"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-3",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exemplo-3-adicionando-filtragem-3",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exemplo 3: Adicionando filtragem",
    "text": "Exemplo 3: Adicionando filtragem\n\n# juntando o número de acidentes e os nomes dos municípios\nobitos_acidentes_nome_municipios &lt;- tab_cod_ibge |&gt;\n  left_join(obitos_acidentes_mun,\n            by = c(\"codigo\" = \"CODMUNOCOR\"))  |&gt;\n  arrange(desc(obitos_acidentes)) # ordem decrescente\nhead(obitos_acidentes_nome_municipios)\n\n# A tibble: 6 × 4\n  codigo municipio UF               obitos_acidentes\n   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                       &lt;dbl&gt;\n1 130260 Manaus    Amazonas                      380\n2 520870 Goiânia   Goiás                         367\n3 261160 Recife    Pernambuco                    347\n4 355030 São Paulo São Paulo                     281\n5 530010 Brasília  Distrito Federal              271\n6 211130 São Luís  Maranhão                      269\n\n# Encerrando a conexão\ndbDisconnect(con, shutdown = TRUE)"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exercícios",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#exercícios",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Exercícios",
    "text": "Exercícios\n\nFaça um histograma das idades das pessoas que vieram a óbito em 2024 em todo o país (note que primeiro você precisa fazer uma consulta na base de dados).\nFaça um gráfico de barras contando os óbitos por sexo para cada estado do país."
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#conclusão-e-revisão",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#conclusão-e-revisão",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "Conclusão e Revisão",
    "text": "Conclusão e Revisão\n\nProblema: A RAM é limitada; dados massivos não cabem nela.\nSolução: Processamento Out-of-Core (On-Disk).\nFerramentas:\n\nduckdb: Motor que faz o trabalho pesado no disco.\nDBI: Interface que o R usa para se comunicar.\nSQL: A linguagem que usamos para descrever o que queremos.\n\nFluxo: dbConnect -&gt; duckdb_register -&gt; dbGetQuery (com SQL) -&gt; dbDisconnect.\nVerbos SQL:\n\n\n\n\nSELECT (o quê)\nFROM (de onde)\nWHERE (filtro de linha)\n\n\n\nGROUP BY (agregar)\nORDER BY (ordenar)"
  },
  {
    "objectID": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#section",
    "href": "slides/04-processamento_out-of-core/04-processamento_out-of-core.html#section",
    "title": "Processamento Out-of-Core com duckdb e DBI no R",
    "section": "",
    "text": "Mais sobre a estrutura de SQL você pode encontrar em https://www.w3schools.com/sql/."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#objetivo-da-aula",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#objetivo-da-aula",
    "title": "Introdução ao Quarto",
    "section": "Objetivo da Aula",
    "text": "Objetivo da Aula\nAprender a criar, editar e renderizar documentos Quarto no RStudio, integrando\n\ntexto;\ncódigo;\ntabelas;\nsaídas do R;\ngráficos;\nreferências."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#estrutura-da-aula",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#estrutura-da-aula",
    "title": "Introdução ao Quarto",
    "section": "Estrutura da Aula",
    "text": "Estrutura da Aula\n\nO que é o Quarto?\nQuando e como usaremos o Quarto no RStudio\nEstrutura de um documento .qmd\nYAML e principais chaves\nTexto e formatação (Markdown)\nBlocos de código (R)\nRenderização e formatos de saída\nDicas, dúvidas e referências"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#o-que-é-o-quarto",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#o-que-é-o-quarto",
    "title": "Introdução ao Quarto",
    "section": "O que é o Quarto?",
    "text": "O que é o Quarto?\nQuarto é uma plataforma unificada para criar documentos, apresentações e sites combinando texto, código (em R, Python, Julia ou Bash) e suas saídas.\n\nSubstitui o R Markdown\nIntegra código, texto e resultados no mesmo arquivo\nPode gerar HTML, PDF, Word, slides, sites e livros\nÉ o padrão atual para comunicação científica com RStudio."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#pré-requisitos",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#pré-requisitos",
    "title": "Introdução ao Quarto",
    "section": "Pré-requisitos",
    "text": "Pré-requisitos\nAntes de começar, você precisa ter instalado:\n  \n\n\nAlternativa: use o Posit Cloud (https://posit.cloud/) para criar e renderizar documentos na nuvem."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#começando",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#começando",
    "title": "Introdução ao Quarto",
    "section": "Começando",
    "text": "Começando\nPrimeiro crie um projeto.\n\nFonte: https://rladies-sp.org/"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#começando-1",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#começando-1",
    "title": "Introdução ao Quarto",
    "section": "Começando",
    "text": "Começando\nO arquivo quarto editável tem extensão .qmd. Para renderizá-lo clique em render ou utilize o atalho do teclado CTRL + SHIFT + K.\n\nFonte: https://rladies-sp.org/"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#estrutura-de-um-arquivo-.qmd",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#estrutura-de-um-arquivo-.qmd",
    "title": "Introdução ao Quarto",
    "section": "Estrutura de um arquivo .qmd",
    "text": "Estrutura de um arquivo .qmd\nUm arquivo .qmd é dividido em três partes:\n\nCabeçalho (YAML) — define o formatação do documento, título, autor, data e outros detalhes.\nCorpo (Markdown) — texto, títulos, listas, tabelas, imagens.\nBlocos de código (Code chunks) — código executável em R, Python, Julia e outras linguagens."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#yaml-yet-another-markup-language",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#yaml-yet-another-markup-language",
    "title": "Introdução ao Quarto",
    "section": "YAML (Yet Another Markup Language)",
    "text": "YAML (Yet Another Markup Language)\nO YAML fica no início do documento e define as configurações básicas. Exemplo:\n---\ntitle: \"Relatório Anual\"\nauthor: \"Equipe de Estatística\"\ndate: today\nlang: pt\nformat: html\n---\n\nDica: Tudo entre --- e --- é parte do YAML e deve ser escrito com atenção à indentação."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#yaml-yet-another-markup-language-1",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#yaml-yet-another-markup-language-1",
    "title": "Introdução ao Quarto",
    "section": "YAML (Yet Another Markup Language)",
    "text": "YAML (Yet Another Markup Language)\nEm YAML, os elementos são chamados de pares chave-valor. Algumas chaves são:\n\ntitle: título do documento.\nauthor: nome do(a) autor(a). Pode ser mais de um(a).\ndate: Define a data do documento. Exemplos: \"13-03-2025\", today.\nlang: Define o idioma do documento. Exemplos: pt, en.\nformat: tipo de arquivo de saída.\n\nMais detalhes: quarto.org/docs/authoring/front-matter.html"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código",
    "title": "Introdução ao Quarto",
    "section": "Blocos de código",
    "text": "Blocos de código\nBlocos de código são onde você executa o R (ou outra linguagem). Começam com três crases e o nome da linguagem. Exemplo:\n```{r}\n#| echo: false\n#| eval: true\nhead(airquality)\n```"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código-1",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código-1",
    "title": "Introdução ao Quarto",
    "section": "Blocos de código",
    "text": "Blocos de código\nAlgumas das principais opções são:\n\n#| echo: controla se o código é exibido no documento.\n#| eval: determina se o código é executado e a saída apresentada.\n#| warning: controla a exibição de mensagens de aviso geradas pelo código.\n#| error: determina se os erros devem ser incluídos na saída.\n#| label: rótulo dado para fazer referência. Uma vez definido um rótulo, você pode referenciá-lo usando (@nome_do_rotulo).\n#| fig-cap: adiciona uma legenda a gráficos gerados pelo código."
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código-2",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#blocos-de-código-2",
    "title": "Introdução ao Quarto",
    "section": "Blocos de código",
    "text": "Blocos de código\n```{r}\n#| echo: false\n#| eval: true\n#| fig-align: center\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) +\n  geom_point() +\n  geom_smooth(method = \"loess\") +\n  labs(x = \"Temperatura (°F)\", y = \"Ozônio (ppb)\") +\n  theme_minimal()\n```"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#formatação-de-texto",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#formatação-de-texto",
    "title": "Introdução ao Quarto",
    "section": "Formatação de texto",
    "text": "Formatação de texto\n\n\n\nSintaxe\nSaída\n\n\n\n\n*itálico*\nitálico\n\n\n**negrito**\nnegrito\n\n\n***itálico negrito***\nitálico negrito\n\n\nsobrescrito^2^\nsobrescrito2\n\n\nsubscrito~2~\nsubscrito2\n\n\n~~riscado~~\nriscado\n\n\n`código literal`\ncódigo literal"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#seções",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#seções",
    "title": "Introdução ao Quarto",
    "section": "Seções",
    "text": "Seções\nUma seção e as subseções são definidas pela quantidade de #. O limite são seis níveis. Exemplos:\n\n\n\n\n\n\n\nSintaxe\nSaída\n\n\n\n\n# Seção 1\nSeção 1\n\n\n## Subseção 1\nSubseção 1\n\n\n### Subsubseção 1\nSubsubseção 1"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#links-e-imagens",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#links-e-imagens",
    "title": "Introdução ao Quarto",
    "section": "Links e imagens",
    "text": "Links e imagens\n\n&lt;https://quarto.org&gt; produz: https://quarto.org\n[Quarto](https://quarto.org) produz: Quarto\n\n\n\n![](quarto.jpg) produz:"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#lista-sem-ordem",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#lista-sem-ordem",
    "title": "Introdução ao Quarto",
    "section": "Lista sem ordem",
    "text": "Lista sem ordem\n\n\nSintaxe\n\n* Item\n\n    + subitem 1\n\n    + subitem 2\n\n        - subsubitem 1\n\nSaída\n\nLista sem ordem\n\nsubitem 1\nsubitem 2\n\nsubsubitem 1"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#lista-ordenada",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#lista-ordenada",
    "title": "Introdução ao Quarto",
    "section": "Lista ordenada",
    "text": "Lista ordenada\n\n\nSintaxe\n\n1. Item 1\n\n2. Item 2\n\n    i) subitem 1\n    \n         A.  subsubitem 1\n\nSaída\n\nItem 1\nItem 2\n\nsubitem 1\n\nsubsubitem 1"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#tabelas",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#tabelas",
    "title": "Introdução ao Quarto",
    "section": "Tabelas",
    "text": "Tabelas\n| Direita | Esquerda | Padrão | Centralizada |\n|--------:|:---------|--------|:------------:|\n|     12  |      12  |   12   |          12  |\n|    123  |      123 |  123   |         123  |\n|      1  |        1 |    1   |           1  |\n\nproduz:\n\n\n\n\nDireita\nEsquerda\nPadrão\nCentralizada\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#equações",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#equações",
    "title": "Introdução ao Quarto",
    "section": "Equações",
    "text": "Equações\n\nPara fórmulas e símbolos matemáticos embutidos no texto use $.\nPara fórmulas e símbolos matemáticos destacados use $$.\n\n\n\n$X \\sim N(\\mu,\\sigma^2)$ \\(~\\) produz: \\(~~ X \\sim N(\\mu,\\sigma^2)\\)\n$$ f(x) = \\frac{a}{b} e^{-x} $$ \\(~\\) produz \\[ f(x) = \\frac{a}{b} e^{-x} \\]"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#citação",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#citação",
    "title": "Introdução ao Quarto",
    "section": "Citação",
    "text": "Citação\n\nInforme o arquivo com as referências no YAML:\n\n---\ntitle: Título\nbibliography: referencias.bib\ncsl: abnt.csl\n---\n\nFormato padrão: Chicago Manual of Style com autor e data.\nVocê pode especificar uma formatação personalizada usando o CSL (Citation Style Language) nos repositórios\n\nhttps://github.com/citation-style-language/styles ou\nhttps://www.zotero.org/styles"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#citação-1",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#citação-1",
    "title": "Introdução ao Quarto",
    "section": "Citação",
    "text": "Citação\n\n@Wickham2023 \\(~\\) produz \\(~\\) (autor, ano):\n\nWICKHAM; ÇETINKAYA-RUNDEL; GROLEMUND (2023)\n\n[@Wickham2023] \\(~\\) produz \\(~\\) autor (ano):\n\n(WICKHAM; ÇETINKAYA-RUNDEL; GROLEMUND, 2023)\n\n\n\n\nO arquivo csl com a formatação da ABNT pode ser encontrada em https://www.zotero.org/styles/universidade-federal-de-sergipe-departamento-de-engenharia-de-producao-abnt"
  },
  {
    "objectID": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#referências",
    "href": "slides/03-introducao_ao_quarto/03-introducao_ao_quarto.html#referências",
    "title": "Introdução ao Quarto",
    "section": "Referências",
    "text": "Referências\n\n\n\n\nWICKHAM, H.; ÇETINKAYA-RUNDEL, M.; GROLEMUND, G. R for data science: Import, tidy, transform, visualize, and model data. 2nd. ed. Sebastopol, CA: O’Reilly, 2023."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bem-vindo(a)!",
    "section": "",
    "text": "Bem-vindo(a)!\nEste espaço foi criado pelo Prof. Dr. Sadraque E. F. Lucena para centralizar todos os conteúdos, atividades e o cronograma da disciplina ESTAT0109 - Mineração de Dados em Estatística, ofertado pelo Departamento de Estatística e Ciências Atuariais da Universidade Federal de Sergipe.\nAo longo do semestre, vamos construir juntos uma base sólida nos fundamentos da Mineração de Dados, explorando o processo de descoberta de conhecimento em bases de dados, as principais técnicas de aprendizado supervisionado e não supervisionado, e as aplicações práticas de algoritmos estatísticos e computacionais para extrair padrões, prever resultados e transformar dados em conhecimento útil."
  },
  {
    "objectID": "info/conteudo.html",
    "href": "info/conteudo.html",
    "title": "Conteúdo",
    "section": "",
    "text": "O conteúdo programático detalhado da disciplina é apresentado a seguir. Ele está organizado em três grandes eixos que abordaremos ao longo do semestre.\n\nParte 1: Fundamentos   1.1. Fundamentos da Mineração de Dados   1.2. Pré-processamento de Dados      1.2.1. Exploração      1.2.2. Limpeza      1.2.3. Transformação      1.2.3. Redução\nParte 2: Aprendizado Não Supervisionado   2.1. Regras de Associação   2.2. \\(k\\)-means\nParte 3: Aprendizado Supervisionado   3.1. Regressão      3.1.1. Regressão linear      3.1.2. Regressão logística   3.2. \\(k\\)-Nearest Neighbors   3.3. Naive Bayes   3.4. Árvores de Decisão   3.5. Florestas aleatórias   3.6. Support Vector Machine   3.7. Avaliação de desempenho      3.7.1. Validação Cruzada      3.7.2. Amostragem bootstrap      3.7.3. Acurácia      3.7.4. Kappa      3.7.5. Precisão e revocação      3.7.6. Sensibilidade e especificidade   3.8. Ajuste de parâmetros   3.9. Métodos de conjunto (ensemble methods)      3.9.1. Bagging      3.9.2. Boosting      3.9.3. Stacking",
    "crumbs": [
      "Informações da disciplina",
      "Conteúdo"
    ]
  },
  {
    "objectID": "info/cronograma.html",
    "href": "info/cronograma.html",
    "title": "Cronograma de Aulas",
    "section": "",
    "text": "Confira abaixo o cronograma de aulas do semestre, baseado no calendário acadêmico do período 2025-2.\n\n\n\n\n\n\n\n\n\nData\nDia da Semana\nAula\nAssunto Previsto\n\n\n\n\n07/10/25\nTerça\n1\nVI Encontro de Estatística e Ciências Atuariais da UFS\n\n\n09/10/25\nQuinta\n2\nApresentação da disciplina. Introdução à mineração de dados.\n\n\n14/10/25\nTerça\n3\nIntrodução ao RStudio + GitHub.\n\n\n16/10/25\nQuinta\n4\nIntrodução ao Quarto.\n\n\n21/10/25\nTerça\n5\nPré-processamento de dados.\n\n\n23/10/25\nQuinta\n6\nAlgoritmos de agrupamento.\n\n\n28/10/25\nTerça\n7\nAlgoritmos de agrupamento.\n\n\n30/10/25\nQuinta\n8\nAlgoritmos de agrupamento.\n\n\n04/11/25\nTerça\n9\nIntrodução à Classificação de dados. Validação cruzada e avaliação de desempenho.\n\n\n06/11/25\nQuinta\n10\nRegressão Logística.\n\n\n11/11/25\nTerça\n11\nRegressão Logística.\n\n\n13/11/25\nQuinta\n12\nk-Nearest Neighbors (k-NN).\n\n\n18/11/25\nTerça\n13\nk-Nearest Neighbors (k-NN).\n\n\n20/11/25\nQuinta\n–\nDia Nacional de Zumbi e da Consciência Negra (feriado nacional)\n\n\n25/11/25\nTerça\n14\nXI SEMAC\n\n\n27/11/25\nQuinta\n15\nXI SEMAC\n\n\n02/12/25\nTerça\n16\nNaive Bayes.\n\n\n04/12/25\nQuinta\n17\nNaive Bayes.\n\n\n09/12/25\nTerça\n18\nÁrvores de decisão.\n\n\n11/12/25\nQuinta\n19\nÁrvores de decisão.\n\n\n16/12/25\nTerça\n20\nFloresta Aleatória (Random Forest).\n\n\n18/12/25\nQuinta\n21\nFloresta Aleatória (Random Forest).\n\n\n23/12/25\nTerça\n–\nRecesso acadêmico\n\n\n25/12/25\nQuinta\n–\nRecesso acadêmico\n\n\n30/12/25\nTerça\n–\nRecesso acadêmico\n\n\n01/01/26\nQuinta\n–\nConfraternização Universal (feriado nacional) e Aniversário de São Cristóvão (feriado municipal)\n\n\n06/01/26\nTerça\n–\nFérias coletivas para docentes\n\n\n08/01/26\nQuinta\n–\nFérias coletivas para docentes\n\n\n13/01/26\nTerça\n22\nSupport Vector Machine.\n\n\n15/01/26\nQuinta\n23\nSupport Vector Machine.\n\n\n20/01/26\nTerça\n24\nRegressão Linear.\n\n\n22/01/26\nQuinta\n25\nRegressão Linear.\n\n\n27/01/26\nTerça\n26\nRegras de Associação.\n\n\n29/01/26\nQuinta\n27\nRegras de Associação.\n\n\n03/02/26\nTerça\n28\nProjeto Final\n\n\n05/02/26\nQuinta\n29\nProjeto Final\n\n\n10/02/26\nTerça\n30\nApresentação do Projeto Final",
    "crumbs": [
      "Informações da disciplina",
      "Cronograma"
    ]
  },
  {
    "objectID": "info/dados_gerais.html",
    "href": "info/dados_gerais.html",
    "title": "Dados Gerais da Disciplina",
    "section": "",
    "text": "Esta seção centraliza todas as informações essenciais sobre nosso componente curricular, incluindo horários, avaliações e datas importantes.",
    "crumbs": [
      "Informações da disciplina",
      "Dados gerais"
    ]
  },
  {
    "objectID": "info/dados_gerais.html#informações",
    "href": "info/dados_gerais.html#informações",
    "title": "Dados Gerais da Disciplina",
    "section": "Informações",
    "text": "Informações\n\nComponente curricular: ESTAT0109 - Mineração de Dados em Estatística\nCarga Horária: 60 horas (4 créditos)\nUnidade Responsável: Departamento de Estatística e Ciências Atuariais (DECAT)\nDocente Responsável: Prof. Dr. Sadraque E. F. Lucena\nPeríodo Letivo: 2025-2\nPlano de Ensino da Disciplina: pdf\n\nDisciplina optativa para o curso de Estatística e de Ciências Atuariais da Universidade Federal de Sergipe.",
    "crumbs": [
      "Informações da disciplina",
      "Dados gerais"
    ]
  },
  {
    "objectID": "info/dados_gerais.html#horários-das-aulas",
    "href": "info/dados_gerais.html#horários-das-aulas",
    "title": "Dados Gerais da Disciplina",
    "section": "Horários das Aulas",
    "text": "Horários das Aulas\nAs aulas ocorrerão nos seguintes horários:\n\nTerças: 17h00 às 18h30 na DID 5 sala 017\nQuintas: 17h00 às 18h30 na DID 5 sala 107",
    "crumbs": [
      "Informações da disciplina",
      "Dados gerais"
    ]
  },
  {
    "objectID": "info/dados_gerais.html#avaliações",
    "href": "info/dados_gerais.html#avaliações",
    "title": "Dados Gerais da Disciplina",
    "section": "Avaliações",
    "text": "Avaliações\nSerá realizada uma avaliação contínua, com solicitação de atividades extraclasse e apresentações em sala de aula. Ao final da disciplina os alunos deverão apresentar um projeto final.",
    "crumbs": [
      "Informações da disciplina",
      "Dados gerais"
    ]
  },
  {
    "objectID": "info/dados_gerais.html#não-haverá-aula",
    "href": "info/dados_gerais.html#não-haverá-aula",
    "title": "Dados Gerais da Disciplina",
    "section": "Não haverá aula",
    "text": "Não haverá aula\n\n20/11/2025: Dia Nacional de Zumbi e da Consciência Negra (feriado nacional)\n25 e 27/11/2025: XI SEMAC (suspensão das atividades de aula para participação nos eventos da XI SEMAC)\n22 a 31/12/2025: Recesso de final de ano\n01/01/2026: Confraternização Universal (feriado nacional) e Aniversário de São Cristóvão (feriado municipal)\n02 a 10/01/2026: Férias coletivas para docentes",
    "crumbs": [
      "Informações da disciplina",
      "Dados gerais"
    ]
  }
]