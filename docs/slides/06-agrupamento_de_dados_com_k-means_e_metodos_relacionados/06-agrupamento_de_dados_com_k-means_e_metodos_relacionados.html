<!DOCTYPE html>
<html lang="pt-BR"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.24">

  <meta name="author" content="Prof.&nbsp;Dr.&nbsp;Sadraque E. F. Lucena  sadraquelucena@academico.ufs.br   http://sadraquelucena.github.io/mineracao">
  <title>Mineração de Dados – Agrupamento de Dados com k-means e Métodos Relacionados</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-d49434ba2564d3ffceac0dcf4da220e2.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Agrupamento de Dados com k-means e Métodos Relacionados</h1>
  <p class="subtitle">ESTAT0109 – Mineração de Dados em Estatística</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
<p>Prof.&nbsp;Dr.&nbsp;Sadraque E. F. Lucena<br> <span style="font-size:.8em;">sadraquelucena@academico.ufs.br</span> <br> <a href="http://sadraquelucena.github.io/mineracao" target="_blank" style="font-size:.8em;">http://sadraquelucena.github.io/mineracao</a></p> 
</div>
</div>
</div>

</section>
<section id="objetivo-da-aula" class="slide level2">
<h2>Objetivo da Aula</h2>
<ul>
<li>Compreender as lógicas centrais dos algoritmos de clusterização particionada, suas medidas de similaridade e robustez;</li>
<li>Decidir qual método usar diante de diferentes tipos de dados e problemas.</li>
</ul>
</section>
<section>
<section id="o-que-é-agrupamento" class="title-slide slide level1 center">
<h1>O que é Agrupamento?</h1>

</section>
<section id="conceito-central" class="slide level2">
<h2>Conceito Central</h2>
<ul>
<li>Agrupamento (<em>Clustering</em>) consiste em métodos usados para particionar dados <strong>não rotulados</strong> em <em>clusters</em> (subgrupos) baseados em <strong>similaridade</strong>.</li>
<li>É uma técnica <strong>não supervisionada</strong> que busca identificar padrões emergentes nos dados.</li>
</ul>

<img data-src="imagens/clustering.png" class="quarto-figure quarto-figure-center r-stretch" style="width:60.0%"><ul>
<li><strong>Objetivos Principais:</strong>
<ol type="1">
<li><strong>Alta similaridade intraclasse:</strong> Itens no <em>mesmo</em> cluster são muito semelhantes.</li>
<li><strong>Baixa similaridade interclasse:</strong> Itens em clusters <em>diferentes</em> são muito diferentes.</li>
</ol></li>
<li><strong>Observação:</strong> Na clusterização, após criados os grupos, o usuário deve analisá-los e criar rótulos que descrevam o agrupamento gerado.</li>
</ul>
</section>
<section id="exemplos-de-aplicação" class="slide level2">
<h2>Exemplos de Aplicação</h2>
<h4 id="saúde">Saúde:</h4>
<ul>
<li>Agrupar internações por idade, diagnóstico e tempo de permanência → revelar perfis clínicos de pacientes e apoiar políticas hospitalares regionais.</li>
</ul>
<h4 id="finanças">Finanças:</h4>
<ul>
<li>Agrupar clientes por renda, histórico de crédito e uso de produtos → identificar perfis de risco e consumo financeiro.</li>
</ul>
<h4 id="municípios">Municípios:</h4>
<ul>
<li>Agrupar cidades por indicadores socioeconômicos, educacionais e de infraestrutura → mapear padrões territoriais de vulnerabilidade.</li>
</ul>
<blockquote>
<p>Cada cluster representa um padrão real que surge dos dados — e a escolha do método define quão bem conseguimos enxergá-los.</p>
</blockquote>
</section>
<section id="tipos-de-agrupamento" class="slide level2">
<h2>Tipos de Agrupamento</h2>
<p>A clusterização pode ser classificada por sua estrutura e regras:</p>
<div class="columns">
<div class="column" style="width:33%;">
<p><strong>Hierárquica vs.&nbsp;Particionada</strong></p>
<ul>
<li><strong>Hierárquica:</strong> Os <em>clusters</em> podem estar contidos dentro de outros clusters.</li>
<li><strong>Particionada:</strong> O limite de cada cluster é independente do outro.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="imagens/hierarquico.png" class="quarto-figure quarto-figure-center" style="width:90.0%"></p>
</figure>
</div>
</div><div class="column" style="width:33%;">
<p><strong>Exclusiva vs.&nbsp;Sobreposta</strong></p>
<ul>
<li><strong>Exclusiva:</strong> Um item pertence apenas a um único <em>cluster</em>.</li>
<li><strong>Sobreposta:</strong> Cada item pode pertencer a um ou mais <em>clusters</em>.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="imagens/sobreposta.png" class="quarto-figure quarto-figure-center" style="width:90.0%"></p>
</figure>
</div>
</div><div class="column" style="width:33%;">
<p><strong>Completa vs.&nbsp;Parcial</strong></p>
<ul>
<li><strong>Completa:</strong> Todos os itens devem pertencer a pelo menos um <em>cluster</em>.</li>
<li><strong>Parcial:</strong> Itens atípicos (<em>outliers</em>) podem não ser atribuídos a nenhum <em>cluster</em>.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="imagens/completo.png" class="quarto-figure quarto-figure-center" style="width:90.0%"></p>
</figure>
</div>
</div></div>
</section>
<section id="problema-central-o-protótipo" class="slide level2">
<h2>Problema Central: O Protótipo</h2>
<p>Nosso foco será em agrupamento <strong>particionado</strong>. A lógica central desses métodos é:</p>
<ol type="1">
<li><strong>Escolher <span class="math inline">\(k\)</span> “centros”</strong> (chamados de <em>protótipos</em>).</li>
<li><strong>Atribuir</strong> cada ponto de dado ao protótipo mais próximo.</li>
<li><strong>Atualizar</strong> a posição de cada protótipo com base nos pontos que lhe foram atribuídos.</li>
<li><strong>Repetir</strong> os passos 2 e 3 até que os grupos não mudem mais (convergência).</li>
</ol>
<p><br> Cada método de clusterização particionada é uma combinação diferente da resposta a duas perguntas:</p>
<ul>
<li>O que é o “protótipo”? → definição do <em>centro</em> (média, mediana, medoide, moda…)</li>
<li>Como medir “proximidade”? → escolha da métrica de distância (Euclidiana, Manhattan, Gower…)</li>
</ul>
</section>
<section id="mapa-mental-que-tipo-de-dado-eu-tenho" class="slide level2">
<h2>Mapa Mental: Que tipo de dado eu tenho?</h2>
<ul>
<li><p>A escolha do algoritmo e da medida de distância depende da <strong>natureza dos seus dados</strong>.</p></li>
<li><p>A pergunta-chave é:</p>
<ul>
<li><strong>Caso 1:</strong> Meus dados são <strong>TODOS NUMÉRICOS</strong>? (Ex: Idade, Renda, Temperatura)</li>
<li><strong>Caso 2:</strong> Meus dados são <strong>TODOS CATEGÓRICOS</strong>? (Ex: Região, Sexo, Tipo Sanguíneo)</li>
<li><strong>Caso 3:</strong> Meus dados são <strong>MISTOS</strong>? (Ex: Idade, Renda, Região, Sexo)</li>
</ul></li>
</ul>
<p><br></p>
<ul>
<li>Vejamos como lidar com cada caso.</li>
</ul>
</section></section>
<section>
<section id="caso-1-dados-numéricos" class="title-slide slide level1 center">
<h1>Caso 1: Dados Numéricos</h1>

</section>
<section id="algoritmo-padrão-k-means-k-médias" class="slide level2">
<h2>Algoritmo Padrão: K-Means (K-Médias)</h2>
<p>O K-means é o ponto de partida clássico para dados numéricos.</p>
<ul>
<li><strong>Aplicação:</strong> Dados <strong>numéricos</strong>.</li>
<li><strong>Centro (Protótipo):</strong> A <strong>Média</strong> de todos os pontos do cluster.</li>
<li><strong>Métrica (Distância):</strong> <strong>Distância Euclidiana</strong>.</li>
</ul>
<p><br></p>
<ul>
<li>Esta abordagem é classificada como:
<ul>
<li><strong>Particionada</strong> (limites independentes)</li>
<li><strong>Exclusiva</strong> (um item, um cluster)</li>
<li><strong>Completa</strong> (todos os itens são atribuídos)</li>
</ul></li>
<li>O usuário define o número de <em>clusters</em> (<span class="math inline">\(k\)</span>) que o conjunto de dados terá.</li>
</ul>
</section>
<section id="k-means-métrica-de-distância-utilizada-euclidiana" class="slide level2">
<h2>K-Means: Métrica de Distância Utilizada (Euclidiana)</h2>
<ul>
<li>A distância Euclidiana (L2) é a métrica padrão do K-means.</li>
<li>Ela mede a “linha reta” entre dois pontos no espaço vetorial.</li>
<li>Sejam <span class="math inline">\(a=(a_1, \ldots, a_p)\)</span> e <span class="math inline">\(b=(b_1, \ldots, b_p)\)</span> duas observações, então</li>
</ul>
<p><span class="math display">\[
  \text{dist}_E(a,b) = \sqrt{(a_1-b_1)^2 +(a_2-b_2)^2 + \cdots + (a_p-b_p)^2}.
\]</span></p>
<h4 id="atenção">Atenção!</h4>
<ul>
<li><strong>Padronize variáveis</strong> antes do cálculo: isto evita que uma variável (ex: Salário) domine o resultado sobre outra (ex: Idade).</li>
<li>A elevação ao quadrado <span class="math inline">\((x^2)\)</span> torna esta medida <strong>muito sensível a outliers</strong>.</li>
</ul>
</section>
<section id="k-means-definição-do-centro-centróide" class="slide level2">
<h2>K-Means: Definição do Centro (Centróide)</h2>
<ul>
<li><p>O centróide de um <em>cluster</em> obtido via K-means é a <strong>média</strong> das coordenadas de todos os pontos do <em>cluster</em>. <span class="math display">\[
\text{centroide}(x,y,z) = \left( \frac{x_1+y_1+z_1}{3}, \frac{x_2+y_2+z_2}{3} \right)
\]</span></p></li>
<li><p><strong>Ponto Crítico:</strong> Como se baseia em médias, o centróide é <strong>altamente sensível a valores extremos (<em>outliers</em>)</strong>, que podem deslocar o centro de massa do cluster.</p></li>
</ul>
</section>
<section id="k-means-funcionamento" class="slide level2">
<h2>K-Means: Funcionamento</h2>
<p>Suponha <span class="math inline">\(k=3\)</span>.</p>
<ol type="1">
<li>O algoritmo escolhe <span class="math inline">\(k\)</span> pontos aleatórios que servem como <strong>centros dos <em>clusters</em> iniciais</strong>.</li>
<li>O algoritmo calcula a distância (Euclidiana) de cada item aos centros e <strong>atribui o item ao <em>cluster</em> cujo centro está mais próximo</strong>.</li>
</ol>

<img data-src="imagens/kmeans1.png" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"></section>
<section id="k-means-funcionamento-1" class="slide level2">
<h2>K-Means: Funcionamento</h2>
<ol start="3" type="1">
<li>Após atribuir cada item a um <em>cluster</em>, o algoritmo calcula o <strong>novo centróide</strong> (a média) de cada <em>cluster</em> formado.</li>
<li>O algoritmo <strong>recalcula a distância</strong> de cada item a cada <em>novo</em> centróide e o reatribui ao cluster mais próximo.</li>
</ol>

<img data-src="imagens/kmeans2.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"></section>
<section id="k-means-funcionamento-2" class="slide level2">
<h2>K-Means: Funcionamento</h2>
<ol start="5" type="1">
<li>O processo de atribuição e avaliação é repetido, com novos centróides calculados para cada <em>cluster</em> e cada item é reatribuído ao <em>cluster</em> mais próximo.</li>
</ol>

<img data-src="imagens/kmeans3.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"></section>
<section id="k-means-funcionamento-3" class="slide level2">
<h2>K-Means: Funcionamento</h2>
<ol start="6" type="1">
<li><p>Em algum momento, os centróides não mudarão mais de lugar e não resultarão em novas atribuições.</p>
<ul>
<li>Nesse ponto dizemos que o algoritmo <strong>convergiu</strong> e o processo é interrompido.</li>
</ul></li>
</ol>

<img data-src="imagens/kmeans4.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"></section>
<section id="ponto-fraco-do-k-means-outliers" class="slide level2">
<h2>Ponto Fraco do K-Means: Outliers</h2>
<ul>
<li>O K-Means minimiza a soma dos quadrados das distâncias (associado à Distância Euclidiana L2).</li>
<li>O centróide (baseado na <strong>média</strong>) é o ponto de equilíbrio.</li>
<li>Um único <em>outlier</em> age como um “peso” muito grande, <strong>“puxando” o centróide</strong> em sua direção, pois sua grande distância é elevada ao quadrado.</li>
<li>Precisamos então de alternativas <strong>robustas</strong> quando há <em>outliers</em> nos dados.</li>
</ul>
</section>
<section id="solução-robusta-1-k-medians-k-medianas" class="slide level2">
<h2>Solução Robusta 1: K-Medians (K-medianas)</h2>
<ul>
<li><strong>Aplicação:</strong> Dados numéricos com <em>outliers</em>.</li>
<li><strong>Centro (Protótipo):</strong> A <strong>Mediana</strong> de cada variável. O centro é <strong>calculado</strong>.</li>
<li><strong>Métrica (Distância):</strong> Distância de Manhattan (L1).</li>
<li><strong>Vantagem:</strong> A Mediana é muito mais robusta a <em>outliers</em> do que a Média.</li>
</ul>
</section>
<section id="k-medians-a-métrica-métrica-de-distância-utilizada-manhattan" class="slide level2">
<h2>K-Medians: A Métrica Métrica de Distância Utilizada (Manhattan)</h2>
<ul>
<li>A distância de Manhattan (L1) mede a distância como sendo a soma das diferenças absolutas (“caminho dos quarteirões”).</li>
<li>Sejam <span class="math inline">\(a=(a_1, \ldots, a_p)\)</span> e <span class="math inline">\(b=(b_1, \ldots, b_p)\)</span> duas observações, então</li>
</ul>
<p><span class="math display">\[
  \text{dist}_M(a,b) = |a_1-b_1| + |a_2-b_2| + \cdots + |a_p-b_p|.
\]</span></p>
<h4 id="por-que-é-robusta">Por que é robusta?</h4>
<ul>
<li><strong>Não eleva as diferenças ao quadrado.</strong></li>
<li>Diferenças grandes (causadas por <em>outliers</em>) têm um peso <strong>linear</strong>, e não quadrático.</li>
<li>O K-Medians, ao usar L1, é naturalmente menos afetado por pontos extremos.</li>
</ul>
</section>
<section id="solução-robusta-2-k-medoids-pam" class="slide level2">
<h2>Solução Robusta 2: K-Medoids (PAM)</h2>
<ul>
<li><strong>Aplicação:</strong> Dados numéricos com <em>outliers</em>.</li>
<li><strong>Centro (Protótipo):</strong> Um <strong>Ponto Real</strong> (o <em>medoide</em>). O centro é <strong>eleito</strong>.</li>
<li><strong>Métrica (Distância):</strong> <strong>Qualquer uma!</strong></li>
<li><strong>Como o centro é eleito?</strong> O medoide é o ponto <em>real</em> cuja <strong>distância total</strong> aos demais pontos do <em>seu</em> cluster é a <strong>mínima</strong>. <span class="math display">\[
\text{medoide} = \arg\min_{x_i \in C} \sum_{x_j \in C} d(x_i, x_j)
\]</span></li>
</ul>
<blockquote>
<p>O método também é chamado de PAM (Partitioning Around Medoids – Particionamento em Torno de Medoides)</p>
</blockquote>
</section>
<section id="k-medoids-vs.-k-medians-a-vantagem-interpretabilidade" class="slide level2">
<h2>K-Medoids vs.&nbsp;K-Medians: A Vantagem (Interpretabilidade)</h2>
<table class="caption-top">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>K-Medians (Centro Calculado)</th>
<th>K-Medoids (Centro Real)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>O centro é a <strong>mediana de cada variável</strong>.</td>
<td>O centro é <strong>um ponto real</strong> dos dados.</td>
</tr>
<tr class="even">
<td>O protótipo <code>(med_x, med_y)</code> pode <strong>não existir</strong> na sua base de dados.</td>
<td>O protótipo é, por exemplo, o <strong>Cliente B (ID 456)</strong>.</td>
</tr>
<tr class="odd">
<td><strong>Interpretação (Fraca):</strong> “O Cluster 1 representa clientes com idade mediana de 25 e salário mediano de R$ 1200.”</td>
<td><strong>Interpretação (Forte):</strong> “O Cluster 1 é representado pelo <strong>Cliente B</strong>, que tem 25 anos e salário de R$ 1200.”</td>
</tr>
</tbody>
</table>
</section>
<section id="k-medoids-vs.-k-medians-a-vantagem-flexibilidade" class="slide level2">
<h2>K-Medoids vs.&nbsp;K-Medians: A Vantagem (Flexibilidade)</h2>
<ul>
<li><p><strong>K-Medians</strong> está intrinsecamente ligado à otimização da <strong>Distância Manhattan (L1)</strong>. <br></p></li>
<li><p><strong>K-Medoids</strong> pode usar <strong>QUALQUER</strong> medida de distância:</p>
<ul>
<li>Distância Euclidiana (L2)</li>
<li>Distância Manhattan (L1)</li>
<li><strong>Distância de Gower</strong> (para dados mistos - <em>vamos ver adiante!</em>)</li>
</ul></li>
<li><p>Isso torna o K-Medoids a ferramenta mais poderosa e flexível para dados complexos.</p></li>
</ul>
</section>
<section id="resumo-clusterização-de-dados-numéricos" class="slide level2">
<h2>Resumo: Clusterização de Dados Numéricos</h2>
<p><br></p>
<table class="caption-top">
<colgroup>
<col style="width: 20%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th>Comparação&nbsp; &nbsp;</th>
<th>K-means&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</th>
<th>K-medians&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</th>
<th>K-medoids&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Centro&nbsp; &nbsp; &nbsp; &nbsp;</td>
<td>Média&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td>Mediana&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td>Ponto real (medoide)</td>
</tr>
<tr class="even">
<td>Distância&nbsp; &nbsp; &nbsp;</td>
<td>Euclidiana (L2)&nbsp; &nbsp;</td>
<td>Manhattan (L1)&nbsp; &nbsp;</td>
<td><strong>Qualquer</strong> (Gower!)&nbsp;</td>
</tr>
<tr class="odd">
<td>Robustez* a <em>outlier</em></td>
<td>Baixa&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td>Média&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td>Alta&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr class="even">
<td>Ponto real?&nbsp; &nbsp;</td>
<td>Não (calculado)&nbsp; &nbsp;</td>
<td>Não (calculado)&nbsp; &nbsp;</td>
<td><strong>Sim (eleito)</strong>&nbsp; &nbsp; &nbsp;</td>
</tr>
<tr class="odd">
<td>Quando usar&nbsp; &nbsp;</td>
<td>Dados numéricos limpos</td>
<td>Dados numéricos com <em>outliers</em></td>
<td><strong>Dados com <em>outliers</em> ou mistos</strong></td>
</tr>
</tbody>
</table>
</section></section>
<section>
<section id="caso-2-dados-categóricos" class="title-slide slide level1 center">
<h1>Caso 2: Dados Categóricos</h1>

</section>
<section id="o-problema-com-dados-categóricos" class="slide level2">
<h2>O Problema com Dados Categóricos</h2>
<ul>
<li><strong>Problema:</strong> Agrupar dados como (Sexo, Região, Plano de Saúde).</li>
<li>Métricas como a Distância Euclidiana ou de Manhattan não funcionam. Não podemos calcular algo como:</li>
</ul>
<p><span class="math display">\[
\sqrt{(\text{'Nordeste'} - \text{'Sul'})^2 + (\text{'Público'} - \text{'Privado'})^2}
\]</span></p>
<ul>
<li>Precisamos de uma métrica e um centro que funcionem para categorias.</li>
</ul>
</section>
<section id="a-métrica-distância-de-hamming-ou-dissimilaridade-simples" class="slide level2">
<h2>A Métrica: Distância de Hamming (ou Dissimilaridade Simples)</h2>
<ul>
<li>A Distância de Hamming é usada quando <strong>todas as variáveis são categóricas</strong> (nominais).</li>
<li>Ela mede <strong>quantas categorias diferem</strong> entre duas observações.</li>
<li>Sejam <span class="math inline">\(a=(a_1, a_2, \ldots, a_p)\)</span> e <span class="math inline">\(b=(b_1, b_2, \ldots, b_p)\)</span> duas observações, então <span class="math display">\[
\text{dist}_H(a,b) = I(a_1\neq b_1) + I(a_2\neq b_2) + \cdots + I(a_p\neq b_p)
\]</span> em que <span class="math inline">\(I(a_i\neq a_i) = 1\)</span> se as categorias forem diferentes, e 0 se forem iguais.</li>
</ul>
</section>
<section id="distância-de-hamming-exemplo" class="slide level2">
<h2>Distância de Hamming: Exemplo</h2>
<p><br></p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Atributo&nbsp; &nbsp; &nbsp;</th>
<th>Paciente A</th>
<th>Paciente B</th>
<th>Diferença</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sexo&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td>M&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td>F&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td>1&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr class="even">
<td>Região&nbsp; &nbsp; &nbsp; &nbsp;</td>
<td>Nordeste&nbsp; &nbsp;</td>
<td>Nordeste&nbsp; &nbsp;</td>
<td>0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr class="odd">
<td>Tipo de Plano</td>
<td>Público&nbsp; &nbsp;</td>
<td>Privado&nbsp; &nbsp;</td>
<td>1&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr class="even">
<td><strong>Total</strong>&nbsp; &nbsp; &nbsp;</td>
<td>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td><strong>2</strong>&nbsp; &nbsp; &nbsp;</td>
</tr>
</tbody>
</table>
<ul>
<li>Distância Hamming = 2 (duas categorias diferentes).</li>
</ul>
</section>
<section id="algoritmo-para-dados-categóricos-k-modes" class="slide level2">
<h2>Algoritmo para Dados Categóricos: K-Modes</h2>
<ul>
<li><p>O K-modes é uma extensão do K-means para dados puramente categóricos.</p></li>
<li><p><strong>Aplicação:</strong> Dados Categóricos (nominais).</p></li>
<li><p><strong>Centro (Protótipo):</strong> A <strong>Moda</strong> de cada variável (o <em>modo</em>).</p></li>
<li><p><strong>Métrica (Distância):</strong> Distância de Hamming.</p></li>
</ul>
</section>
<section id="k-modes-o-centro-modo" class="slide level2">
<h2>K-Modes: O Centro (Modo)</h2>
<ul>
<li><p>No K-modes, o protótipo (centro) do <em>cluster</em> não é uma média, mas sim o <strong>vetor das categorias mais frequentes</strong> (a moda) encontradas no cluster.</p></li>
<li><p>Exemplo de Cálculo do Modo (Protótipo) para um Cluster:</p></li>
</ul>
<table class="caption-top">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Variável</th>
<th>Membros do Cluster</th>
<th>Moda (Centro)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Região</td>
<td>Nordeste, Nordeste, Sul, Nordeste, Sudeste</td>
<td><strong>Nordeste</strong> (3/5)</td>
</tr>
<tr class="even">
<td>Plano</td>
<td>Público, Privado, Público, Público, Privado</td>
<td><strong>Público</strong> (3/5)</td>
</tr>
<tr class="odd">
<td>Sexo</td>
<td>M, F, F, M, F</td>
<td><strong>F</strong> (3/5)</td>
</tr>
</tbody>
</table>
<ul>
<li>O <strong>protótipo (modo)</strong> deste cluster é o vetor: <code>("Nordeste", "Público", "F")</code>.</li>
<li>O algoritmo atribui novos pontos com base em quantas categorias eles diferem deste protótipo (Distância de Hamming).</li>
</ul>
</section>
<section id="k-modes-vantagens-e-limitações" class="slide level2">
<h2>K-Modes: Vantagens e Limitações</h2>
<ul>
<li><strong>Uso:</strong>
<ul>
<li>Bases com <em>apenas</em> variáveis nominais (ex.: diagnóstico primário, modalidade de serviço, ocupação).</li>
</ul></li>
<li><strong>Vantagens:</strong>
<ul>
<li>Rápido e simples.</li>
<li>Interpretação direta (o “perfil modal” de cada cluster é muito claro).</li>
</ul></li>
<li><strong>Limitações:</strong>
<ul>
<li>Não trata variáveis <strong>numéricas</strong> (ex: Idade).</li>
<li>Não trata variáveis <strong>ordinais</strong> de forma natural (ex: Escolaridade).</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="caso-3-dados-mistos" class="title-slide slide level1 center">
<h1>Caso 3: Dados Mistos</h1>

</section>
<section id="o-problema-com-dados-mistos" class="slide level2">
<h2>O Problema com Dados Mistos</h2>
<ul>
<li><strong>Problema:</strong> Agrupar itens usando variáveis numéricas e categóricas como Idade, Renda, Gênero, Região.</li>
<li>Nesses casos K-Means e K-Modes falham. Precisamos de soluções híbridas.</li>
<li><strong>Temos duas estratégias principais:</strong>
<ol type="1">
<li><strong>Robusta (Gower + K-Medoids):</strong> Usa um algoritmo robusto com uma métrica de distância flexível.</li>
<li><strong>Rápida (K-Prototypes):</strong> Usa um algoritmo híbrido que combina K-Means e K-Modes.</li>
</ol></li>
</ul>
</section>
<section id="solução-1-robusta-gower-k-medoids" class="slide level2">
<h2>Solução 1 (Robusta): Gower + K-Medoids</h2>
<h3 id="usamos-como-métrica-a-distância-de-gower">Usamos como métrica a Distância de Gower</h3>
<ul>
<li><p>A Distância de Gower é usada quando os <strong>dados são mistos</strong>: variáveis numéricas, categóricas, binárias ou ordinais.</p></li>
<li><p>Resulta em valores entre 0 e 1 (<em>0 = iguais</em>, <em>1 = completamente diferentes</em>).</p></li>
<li><p>A dissimilaridade entre duas observações <span class="math inline">\(i\)</span> e <span class="math inline">\(j\)</span> com <span class="math inline">\(p\)</span> atributos é dada por: <span class="math display">\[
D_{ij} = \frac{w_{ij1} d_{ij1} + w_{ij2} d_{ij2} + \cdots + w_{ijp} d_{ijp}}{w_{ij1}+ w_{ij2} + \cdots + w_{ijp}},
\]</span> em que <span class="math inline">\(w_{ijk}\)</span> é o peso (geralmente 1) e <span class="math inline">\(d_{ijk}\)</span> é a dissimilaridade para o <span class="math inline">\(k\)</span>-ésimo atributo:</p>
<ul>
<li>se o atributo é <strong>categórico ou binário</strong>, <span class="math inline">\(d_{ijk} = I(x_{ik}\neq x_{jk})\)</span>;</li>
<li>se o atributo é <strong>numérico</strong>, <span class="math inline">\(d_{ijk} = 1 - \frac{|x_i-x_j|}{R_k}\)</span>, sendo <span class="math inline">\(R_k\)</span> a amplitude (max-min) da variável <span class="math inline">\(k\)</span>.</li>
</ul></li>
</ul>
</section>
<section id="solução-1-robusta-gower-k-medoids-1" class="slide level2">
<h2>Solução 1 (Robusta): Gower + K-Medoids</h2>
<ul>
<li><strong>Aplicação:</strong> Dados Mistos.</li>
<li><strong>Centro (Protótipo):</strong> Ponto Real (medoide).</li>
<li><strong>Métrica (Distância):</strong> Distância de Gower.</li>
</ul>
<p><br></p>
<ul>
<li><p>Como K-Medoids funciona com <strong>qualquer</strong> matriz de distância, fazemos o seguinte:</p>
<ol type="1">
<li>Calculamos a matriz de dissimilaridade <span class="math inline">\(N \times N\)</span> entre todos os pontos usando Gower.</li>
<li>Fornecemos essa matriz ao algoritmo K-Medoids (PAM).</li>
<li>O K-Medoids elegerá os pontos reais mais centrais com base nessa distância mista.</li>
</ol></li>
</ul>
</section>
<section id="gower-k-medoids-vantagens-e-limitações" class="slide level2">
<h2>Gower + K-Medoids: Vantagens e Limitações</h2>
<p><strong>Vantagens:</strong></p>
<ul>
<li><strong>A solução mais robusta e flexível.</strong></li>
<li>Trata todos os tipos de variáveis (numéricos, categóricos, ordinais) corretamente.</li>
<li>Robusto a <em>outliers</em> (medoide é ponto real).</li>
<li>Interpretação ótima (medoide = observação representativa).</li>
</ul>
<p><strong>Limitações:</strong></p>
<ul>
<li><strong>Custo Computacional:</strong> A matriz de Gower <span class="math inline">\(N \times N\)</span> pode ser custosa (memória e tempo) para datasets com N grande (ex: N &gt; 10.000).</li>
<li>Complexidade elevada (O(<span class="math inline">\(N^2\)</span>)): o tempo de execução ou o uso de memória cresce quadraticamente conforme o número de observações aumenta.</li>
</ul>
</section>
<section id="solução-2-rápida-k-prototypes" class="slide level2">
<h2>Solução 2 (Rápida): K-Prototypes</h2>
<ul>
<li>O K-prototypes une K-means (para variáveis numéricas) e K-modes (para variáveis categóricas).</li>
</ul>
<p><br></p>
<ul>
<li><strong>Aplicação :</strong> Dados Mistos.</li>
<li><strong>Centro (Protótipo):</strong> Híbrido!
<ul>
<li><strong>Média</strong> para variáveis numéricas.</li>
<li><strong>Moda</strong> para variáveis categóricas.</li>
</ul></li>
<li><strong>Métrica (Distância):</strong> Híbrida (Euclidiana + Hamming).</li>
</ul>
</section>
<section id="k-prototypes-a-métrica-híbrida" class="slide level2">
<h2>K-Prototypes: A Métrica Híbrida</h2>
<ul>
<li>A distância é uma soma ponderada das distâncias numéricas e categóricas.</li>
<li><span class="math inline">\(\text{dist}(a, b) = \sum (a_i - b_i)^2 + \gamma \sum I(a_j \neq b_j)\)</span>
<ul>
<li><span class="math inline">\(\sum (a_i - b_i)^2\)</span>: Parte Numérica (Dist. Euclidiana ao Quadrado)</li>
<li><span class="math inline">\(\sum I(a_j \neq b_j)\)</span>: Parte Categórica (Dist. Hamming)</li>
<li><span class="math inline">\(\gamma\)</span>: Um peso (parâmetro) que define a importância da parte categórica.</li>
</ul></li>
</ul>
<p><strong>Vantagens:</strong></p>
<ul>
<li><strong>Escala bem:</strong> Não precisa de matriz N×N. Excelente para grandes bases mistas.</li>
<li>Interpretação direta (protótipo = perfil de médias + modas).</li>
</ul>
<p><strong>Limitações:</strong></p>
<ul>
<li>A parte numérica (K-Means) ainda é <strong>sensível a outliers</strong>.</li>
<li>Variáveis ordinais são tratadas como categóricas (perda de ordem).</li>
<li>O parâmetro <span class="math inline">\(\gamma\)</span> exige ajuste/escolha.</li>
</ul>
</section></section>
<section>
<section id="módulo-5-escolhendo-o-número-de-k" class="title-slide slide level1 center">
<h1>Módulo 5: Escolhendo o número de <span class="math inline">\(k\)</span></h1>

</section>
<section id="como-definir-o-número-de-clusters-escolher-k" class="slide level2">
<h2>Como definir o número de <em>clusters</em> (escolher <span class="math inline">\(k\)</span>)?</h2>
<ul>
<li>Suponha que escolhemos o método (ex: K-Means). Mas quantos <em>clusters</em> (<span class="math inline">\(k\)</span>) devemos criar?</li>
<li><span class="math inline">\(k=2\)</span>? <span class="math inline">\(k=3\)</span>? <span class="math inline">\(k=10\)</span>?</li>
<li>Esta é a pergunta mais comum em agrupamento.</li>
<li>Não há uma resposta única “correta”, mas sim métodos que ajudam a encontrar um <span class="math inline">\(k\)</span> “ótimo”.</li>
<li>Veremos três dos mais usados:
<ul>
<li>Método do Cotovelo (<em>Elbow Method</em>)</li>
<li>Método da Silhueta Média (<em>Average Silhouette</em>)</li>
<li>Estatística Gap (<em>Gap Statistic</em>)</li>
</ul></li>
</ul>
</section>
<section id="método-1-cotovelo-elbow-method" class="slide level2">
<h2>Método 1: Cotovelo (<em>Elbow Method</em>)</h2>
<ul>
<li>A ideia é testar vários valores de <span class="math inline">\(k\)</span> e calcular a <strong>Soma dos Quadrados Intra-clusters</strong> (<em>Within-Cluster Sum of Squares</em>, <span class="math inline">\(WCSS\)</span>).</li>
<li><span class="math inline">\(WCSS\)</span> mede a <strong>compactação</strong> (homogeneidade) total dos <em>clusters</em>. <span class="math display">\[
WCSS_k = \sum_{\text{cluster } 1} \text{dist}(P_i, C_1)^2 + \sum_{\text{cluster } 2} \text{dist}(P_i, C_2)^2 + \cdots
\]</span></li>
<li>Quanto mais <span class="math inline">\(k\)</span>, menor o <span class="math inline">\(WCSS\)</span> (naturalmente, <span class="math inline">\(WCSS=0\)</span> se <span class="math inline">\(k=N\)</span>).</li>
<li>Procuramos o <span class="math inline">\(k\)</span> onde a redução do <span class="math inline">\(WCSS\)</span> começa a diminuir drasticamente: o <strong>“cotovelo”</strong> da curva.</li>
<li>É o ponto de equilíbrio: aumentar <span class="math inline">\(k\)</span> não traz melhora significativa.</li>
</ul>
</section>
<section id="método-1-cotovelo-elbow-method-1" class="slide level2">
<h2>Método 1: Cotovelo (<em>Elbow Method</em>)</h2>

<img data-src="imagens/wcss.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"></section>
<section id="método-2-silhueta-média-average-silhouette" class="slide level2">
<h2>Método 2: Silhueta Média (<em>Average Silhouette</em>)</h2>
<ul>
<li>Mede o <strong>grau de coesão e separação</strong> dos <em>clusters</em>. Avalia o quão bem cada item está posicionado.</li>
<li>Para cada observação <span class="math inline">\(i\)</span>, calcula-se <span class="math inline">\(S(i) = \frac{b(i) - a(i)}{\max\{ a(i), b(i) \}}\)</span>
<ul>
<li><span class="math inline">\(a(i)\)</span>: distância média de <span class="math inline">\(i\)</span> aos pontos do <strong>mesmo cluster</strong> (coesão).</li>
<li><span class="math inline">\(b(i)\)</span>: distância média de <span class="math inline">\(i\)</span> aos pontos do <strong>cluster vizinho mais próximo</strong> (separação).</li>
</ul></li>
<li><span class="math inline">\(S(i)\)</span> varia de -1 a 1:
<ul>
<li><span class="math inline">\(\approx 1\)</span>: Item bem ajustado (ideal).</li>
<li><span class="math inline">\(\approx 0\)</span>: Item na fronteira entre <em>clusters</em>.</li>
<li><span class="math inline">\(&lt; 0\)</span>: Item provavelmente no <em>cluster</em> errado.</li>
</ul></li>
<li><strong>O <span class="math inline">\(k\)</span> ótimo é aquele que maximiza a Silhueta Média de todas as observações.</strong></li>
</ul>
</section>
<section id="método-2-silhueta-média-average-silhouette-1" class="slide level2">
<h2>Método 2: Silhueta Média (<em>Average Silhouette</em>)</h2>

<img data-src="imagens/silhueta.png" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"></section>
<section id="método-3-estatística-gap" class="slide level2">
<h2>Método 3: Estatística Gap</h2>
<ul>
<li>Compara a <strong>dispersão observada</strong> (<span class="math inline">\(WCSS_k\)</span>) com a <strong>dispersão esperada</strong> sob uma distribuição de referência aleatória (sem <em>clusters</em>).</li>
<li>A ideia é: <span class="math inline">\(k\)</span> é bom se a compactação dos nossos <em>clusters</em> for muito melhor do que uma compactação aleatória.</li>
</ul>
<ol type="1">
<li>Para cada <span class="math inline">\(k\)</span>, calcule <span class="math inline">\(\log(WCSS_k)\)</span> dos dados originais.</li>
<li>Gere <span class="math inline">\(B\)</span> amostras aleatórias (uniformes) e calcule a média de <span class="math inline">\(\log(WCSS^{*b}_k)\)</span>.</li>
<li>A <strong>Estatística Gap</strong> é a diferença: <span class="math display">\[
&nbsp; Gap(k) = E[\log(WCSS^{*b}_k)] - \log(WCSS_k)
\]</span></li>
</ol>
<ul>
<li><strong>Procuramos o <span class="math inline">\(k\)</span> que maximiza o <span class="math inline">\(Gap(k)\)</span></strong>.</li>
</ul>
</section>
<section id="método-3-estatística-gap-1" class="slide level2">
<h2>Método 3: Estatística Gap</h2>

<img data-src="imagens/gap.png" class="quarto-figure quarto-figure-center r-stretch" style="width:40.0%"></section>
<section id="para-definir-o-algoritmo-de-agrupamento" class="slide level2">
<h2>Para definir o algoritmo de agrupamento</h2>

<img data-src="imagens/mapa-clusterizacao.png" class="quarto-figure quarto-figure-center r-stretch"><ul>
<li>E para <strong>encontrar <span class="math inline">\(k\)</span></strong>, use métodos de validação como <strong>Cotovelo (WCSS)</strong>, <strong>Silhueta</strong> ou <strong>Estatística Gap</strong>.</li>
</ul>
</section></section>
<section id="agora-vamos-fazer-no-r" class="title-slide slide level1 center">
<h1>Agora vamos fazer no R…</h1>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="imagens/ufs_horizontal_positiva.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'fast',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1600,

        height: 900,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // Bounds for smallest/largest possible scale to apply to content
        minScale: 0.2,

        maxScale: 2,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copiada");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copiada");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>